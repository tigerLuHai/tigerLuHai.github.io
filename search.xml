<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>JVM必须知道的基础</title>
      <link href="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/"/>
      <url>/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/</url>
      
        <content type="html"><![CDATA[<h2 id="运行时数据区域"><a href="#运行时数据区域" class="headerlink" title="运行时数据区域"></a>运行时数据区域</h2><p>网上有很多描述JVM内存区的图,我觉得这张能表述内容较多</p><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C1.png" alt="img"></p><h4 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h4><pre><code> 程序计数器(Program Counter Register)存储当前线程执行的字节码行号，占用内存较小。字节码解释器就是通过这个计数器的值来选择下一条需要执行的字节码指令。执行Java方法时计数器指向正在执行的虚拟字节码指令的地址，执行Native方法时指向空。</code></pre><h4 id="java虚拟机栈"><a href="#java虚拟机栈" class="headerlink" title="java虚拟机栈"></a>java虚拟机栈</h4><pre><code>java虚拟机栈（Java Virtual Machine Stack）与程序计数器一样，也是线程私有的，生命周期与线程相同。java虚拟机栈描述的是java方法执行的内存模型,每个方法执行的时候都会创建一个栈帧,用于存储局部变量表、操作数栈、动态链接、方法出口等信息。方法的调用和结束分别对应栈帧的入栈和出栈。</code></pre><h4 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h4><pre><code>本地方法栈（Native Method Stack）与java虚拟机栈作用相似,java虚拟机栈是为java方法服务,本地方法栈是为Native方法服务,甚至有些虚拟机实现时直接将两者合而为一(如:HotSpot).</code></pre><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><pre><code>Java堆(Java Heap)是虚拟机管理的内存中最大的一块，该内存区域的唯一目的就是存放对象实例。java堆是垃圾收集区域管理的主要区域。从回收的角度看，可以细分为新生代和老年代；再细致一点就是Eden空间、From Survivor空间、To Survivor空间。线程共享的java堆能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB）。</code></pre><h4 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h4><pre><code>方法区（Method Area）与java堆一样，是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码数据等。这个区域的垃圾回收主要是针对常量池的回收和对类型的卸载。</code></pre><h5 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h5><pre><code>运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件的常量池(Constant Pool Table)将在类加载后进入方法区的运行时常量池存放。除此之外，还会将翻译出来的直接引用也存放在运行时常量池。运行期间也可以将新的常量放入运行时常量池。</code></pre><h4 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h4><pre><code>直接内存(Direct Memory)并不是java虚拟机运行时数据区的一部分。在JDK1.4中新加入了NIO（New Input/Output）类,引入了一种基于通道(channel)和缓冲区(Buffer)的I/O方式.他可以使用Native函数库直接分配对外内存.然后通过一个内存在java堆中的DirectByteBuffer对象作为这块内存的引用进行操作.</code></pre><h2 id="垃圾收集"><a href="#垃圾收集" class="headerlink" title="垃圾收集"></a>垃圾收集</h2><h3 id="判断一个对象是否可被回收"><a href="#判断一个对象是否可被回收" class="headerlink" title="判断一个对象是否可被回收"></a>判断一个对象是否可被回收</h3><h4 id="引用计数算法"><a href="#引用计数算法" class="headerlink" title="引用计数算法"></a>引用计数算法</h4><p>为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。</p><p>在两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。正是因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。</p><h4 id="可达性分析算"><a href="#可达性分析算" class="headerlink" title="可达性分析算"></a>可达性分析算</h4><p>以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收。</p><p>Java 虚拟机使用该算法来判断对象是否可被回收，GC Roots 一般包含以下内容：</p><ul><li>虚拟机栈中局部变量表中引用的对象</li><li>本地方法栈中 JNI 中引用的对象</li><li>方法区中类静态属性引用的对象</li><li>方法区中的常量引用的对象</li></ul><h4 id="方法区的回收"><a href="#方法区的回收" class="headerlink" title="方法区的回收"></a>方法区的回收</h4><p>因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，所以在方法区上进行回收性价比不高。</p><p>主要是对常量池的回收和对类的卸载。</p><p>为了避免内存溢出，在大量使用反射和动态代理的场景都需要虚拟机具备类卸载功能。</p><p>类的卸载条件很多，需要满足以下三个条件，并且满足了条件也不一定会被卸载：</p><ul><li>该类所有的实例都已经被回收，此时堆中不存在该类的任何实例。</li><li>加载该类的 ClassLoader 已经被回收。</li><li>该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。</li></ul><h4 id="finalize"><a href="#finalize" class="headerlink" title="finalize()"></a>finalize()</h4><p>当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能在该方法中让对象重新被引用，从而实现自救。自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会再调用该方法。</p><h3 id="引用类型"><a href="#引用类型" class="headerlink" title="引用类型"></a>引用类型</h3><p>无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。</p><p>Java 提供了四种强度不同的引用类型。</p><h4 id="强引用"><a href="#强引用" class="headerlink" title="强引用"></a>强引用</h4><p>被强引用关联的对象不会被回收。</p><p>使用 new 一个新对象的方式来创建强引用。</p><pre><code>Object obj = new Object();</code></pre><h4 id="软引用"><a href="#软引用" class="headerlink" title="软引用"></a>软引用</h4><p>被软引用关联的对象只有在内存不够的情况下才会被回收。</p><p>使用 SoftReference 类来创建软引用。</p><pre><code>Object obj = new Object();SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null;  // 使对象只被软引用关联</code></pre><h4 id="弱引用"><a href="#弱引用" class="headerlink" title="弱引用"></a>弱引用</h4><p>被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。</p><p>使用 WeakReference 类来创建弱引用。</p><pre><code>Object obj = new Object();WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);obj = null;</code></pre><h4 id="虚引用"><a href="#虚引用" class="headerlink" title="虚引用"></a>虚引用</h4><p>又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。</p><p>为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。</p><p>使用 PhantomReference 来创建虚引用。</p><pre><code>Object obj = new Object();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj, null);obj = null;</code></pre><h3 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h3><h4 id="1-标记-清除"><a href="#1-标记-清除" class="headerlink" title="1. 标记 - 清除"></a>1. 标记 - 清除</h4><p>顾名思义，标记-清除算法分为两个阶段，标记(mark)和清除(sweep).</p><p>在标记阶段，collector从mutator根对象开始进行遍历，对从mutator根对象可以访问到的对象都打上一个标识，一般是在对象的header中，将其记录为可达对象。</p><p>而在清除阶段，collector对堆内存(heap memory)从头到尾进行线性的遍历，如果发现某个对象没有标记为可达对象-通过读取对象的header信息，则就将其回收。</p><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C2.png" alt="img"></p><p>从上图我们可以看到，在Mark阶段，从根对象1可以访问到B对象，从B对象又可以访问到E对象，所以B,E对象都是可达的。同理，F,G,J,K也都是可达对象。到了Sweep阶段，所有非可达对象都会被collector回收。同时，Collector在进行标记和清除阶段时会将整个应用程序暂停(mutator)，等待标记清除结束后才会恢复应用程序的运行。</p><ul><li><p><strong>优点</strong>：</p><p>实现简单，不需要进行对象进行移动。</p></li><li><p><strong>缺点</strong>：</p><p>标记、清除过程效率低，产生大量不连续的内存碎片，提高了垃圾回收的频率。</p></li></ul><h4 id="2-标记-整理"><a href="#2-标记-整理" class="headerlink" title="2. 标记 - 整理"></a>2. 标记 - 整理</h4><p>其中标记阶段跟标记-清除算法中的标记阶段是一样的，而对于整理阶段，它的工作就是移动所有的可达对象到堆内存的同一个区域中，使他们紧凑的排列在一起，从而将所有 <strong>非可达对象释放出来的空闲内存</strong> 都集中在一起，通过这样的方式来达到减少内存碎片的目的。</p><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C3.png" alt="3"></p><ul><li><p><strong>优点</strong>：</p><p>解决了标记-清理算法存在的内存碎片问题。</p></li><li><p><strong>缺点</strong>：</p><p>仍需要进行局部对象移动，一定程度上降低了效率。</p></li></ul><h4 id="3-复制"><a href="#3-复制" class="headerlink" title="3. 复制"></a>3. 复制</h4><p>这种收集算法解决了标记清除算法存在的效率问题。它将内存区域划分成相同的两个<strong>内存块</strong>。每次仅使用一半的空间，<code>JVM</code>生成的新对象放在一半空间中。当一半空间用完时进行<code>GC</code>，把可到达对象复制到另一半空间，然后把使用过的内存空间一次清理掉。</p><ul><li><p><strong>优点</strong>：</p><p>按顺序分配内存即可，实现简单、运行高效，不用考虑内存碎片。</p></li><li><p><strong>缺点</strong>：</p><p>可用的内存大小缩小为原来的一半，对象存活率高时会频繁进行复制。</p></li></ul><h4 id="4-分代收集"><a href="#4-分代收集" class="headerlink" title="4. 分代收集"></a>4. 分代收集</h4><p>现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。</p><p>一般将堆分为新生代和老年代。</p><ul><li>对于<strong>新生代</strong>，每次<code>GC</code>时都有<strong>大量</strong>的对象死亡，只有<strong>少量</strong>对象存活。考虑到复制成本低，适合采用<strong>复制算法</strong>。因此有了<code>From Survivor</code>和<code>To Survivor</code>区域。</li><li>对于<strong>老年代</strong>，因为对象<strong>存活率高</strong>，没有额外的内存空间对它进行担保。因而适合采用<strong>标记-清理算法</strong>和<strong>标记-整理算法</strong>进行回收。</li></ul><h3 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h3><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C4.png" alt="img"></p><p>以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。</p><ul><li>单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程；</li><li>串行与并行：串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并行指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。</li></ul><h4 id="1-Serial-收集器"><a href="#1-Serial-收集器" class="headerlink" title="1. Serial 收集器"></a>1. Serial 收集器</h4><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C5.png" alt="img"></p><p>Serial 翻译为串行，也就是说它以串行的方式执行。</p><p>它是单线程的收集器，只会使用一个线程进行垃圾收集工作。</p><p>它的优点是简单高效，在单个 CPU 环境下，由于没有线程交互的开销，因此拥有最高的单线程收集效率。</p><p>它是 Client 场景下的默认新生代收集器，因为在该场景下内存一般来说不会很大。它收集一两百兆垃圾的停顿时间可以控制在一百多毫秒以内，只要不是太频繁，这点停顿时间是可以接受的。</p><h4 id="2-ParNew-收集器"><a href="#2-ParNew-收集器" class="headerlink" title="2. ParNew 收集器"></a>2. ParNew 收集器</h4><p><a href="https://camo.githubusercontent.com/573a3abc71931daef42e0b42b1876cbe4f940cdc/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f38313533386364352d316263662d346533312d383665352d6531393864663165303133622e6a7067" target="_blank" rel="noopener"><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C7.png" alt="img"></a></p><p>它是 Serial 收集器的多线程版本。</p><p>它是 Server 场景下默认的新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合使用。</p><h4 id="3-Parallel-Scavenge-收集器"><a href="#3-Parallel-Scavenge-收集器" class="headerlink" title="3. Parallel Scavenge 收集器"></a>3. Parallel Scavenge 收集器</h4><p>与 ParNew 一样是多线程收集器。</p><p>其它收集器目标是尽可能缩短垃圾收集时用户线程的停顿时间，而它的目标是达到一个可控制的吞吐量，因此它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户程序的时间占总时间的比值。</p><p>停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。</p><p>缩短停顿时间是以牺牲吞吐量和新生代空间来换取的：新生代空间变小，垃圾回收变得频繁，导致吞吐量下降。</p><p>可以通过一个开关参数打开 GC 自适应的调节策略（GC Ergonomics），就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 区的比例、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。</p><h4 id="4-Serial-Old-收集器"><a href="#4-Serial-Old-收集器" class="headerlink" title="4. Serial Old 收集器"></a>4. Serial Old 收集器</h4><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C13.png" alt="13"></p><p>是 Serial 收集器的老年代版本，也是给 Client 场景下的虚拟机使用。如果用在 Server 场景下，它有两大用途：</p><ul><li>在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用。</li><li>作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。</li></ul><h4 id="5-Parallel-Old-收集器"><a href="#5-Parallel-Old-收集器" class="headerlink" title="5. Parallel Old 收集器"></a>5. Parallel Old 收集器<img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C8.png" alt="img"></h4><p>是 Parallel Scavenge 收集器的老年代版本。</p><p>在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。</p><h4 id="6-CMS-收集器"><a href="#6-CMS-收集器" class="headerlink" title="6. CMS 收集器"></a>6. CMS 收集器</h4><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C9.png" alt="img"></p><p>CMS（Concurrent Mark Sweep），Mark Sweep 指的是标记 - 清除算法。</p><p>分为以下四个流程：</p><ul><li>初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。</li><li>并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。</li><li>重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。</li><li>并发清除：不需要停顿。</li></ul><p>在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。</p><p>具有以下缺点：</p><ul><li>吞吐量低：低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。</li><li>无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。</li><li>标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。</li></ul><h4 id="7-G1-收集器"><a href="#7-G1-收集器" class="headerlink" title="7. G1 收集器"></a>7. G1 收集器</h4><p>G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。</p><p>堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。<img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C10.png" alt="img"></p><p>G1 把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。</p><p><a href="https://camo.githubusercontent.com/5049da1b34969b272be2bffc6c6de0206b33253c/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f39626264646565622d653933392d343166302d386538652d3262316130616137653061372e706e67" target="_blank" rel="noopener"><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C11.png" alt="img"></a></p><p>通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。</p><p>每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。</p><p><a href="https://camo.githubusercontent.com/5bd72d589ead80c22547e3288a9a406241a1fb6b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f66393965653737312d633536662d343766622d393134382d6330303336363935623566652e6a7067" target="_blank" rel="noopener"><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C12.png" alt="img"></a></p><p>如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤：</p><ul><li>初始标记</li><li>并发标记</li><li>最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。</li><li>筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。</li></ul><p>具备如下特点：</p><ul><li>空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。</li><li>可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。</li></ul><h2 id="内存分配与回收策略"><a href="#内存分配与回收策略" class="headerlink" title="内存分配与回收策略"></a>内存分配与回收策略</h2><h3 id="Minor-GC-和-Full-GC"><a href="#Minor-GC-和-Full-GC" class="headerlink" title="Minor GC 和 Full GC"></a>Minor GC 和 Full GC</h3><ul><li>Minor GC：回收新生代，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。</li><li>Full GC：回收老年代和新生代，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。</li></ul><h3 id="内存分配策略"><a href="#内存分配策略" class="headerlink" title="内存分配策略"></a>内存分配策略</h3><h4 id="1-对象优先在-Eden-分配"><a href="#1-对象优先在-Eden-分配" class="headerlink" title="1. 对象优先在 Eden 分配"></a>1. 对象优先在 Eden 分配</h4><p>大多数情况下，对象在新生代 Eden 上分配，当 Eden 空间不够时，发起 Minor GC。</p><h4 id="2-大对象直接进入老年代"><a href="#2-大对象直接进入老年代" class="headerlink" title="2. 大对象直接进入老年代"></a>2. 大对象直接进入老年代</h4><p>大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。</p><p>经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。</p><p>-XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 和 Survivor 之间的大量内存复制。</p><h4 id="3-长期存活的对象进入老年代"><a href="#3-长期存活的对象进入老年代" class="headerlink" title="3. 长期存活的对象进入老年代"></a>3. 长期存活的对象进入老年代</h4><p>为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。</p><p>-XX:MaxTenuringThreshold 用来定义年龄的阈值。</p><h4 id="4-动态对象年龄判定"><a href="#4-动态对象年龄判定" class="headerlink" title="4. 动态对象年龄判定"></a>4. 动态对象年龄判定</h4><p>虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。</p><h4 id="5-空间分配担保"><a href="#5-空间分配担保" class="headerlink" title="5. 空间分配担保"></a>5. 空间分配担保</h4><p>在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。</p><p>如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。</p><h3 id="Full-GC-的触发条件"><a href="#Full-GC-的触发条件" class="headerlink" title="Full GC 的触发条件"></a>Full GC 的触发条件</h3><p>对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件：</p><h4 id="1-调用-System-gc"><a href="#1-调用-System-gc" class="headerlink" title="1. 调用 System.gc()"></a>1. 调用 System.gc()</h4><p>只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。</p><h4 id="2-老年代空间不足"><a href="#2-老年代空间不足" class="headerlink" title="2. 老年代空间不足"></a>2. 老年代空间不足</h4><p>老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。</p><p>为了避免以上原因引起的 Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。</p><h4 id="3-空间分配担保失败"><a href="#3-空间分配担保失败" class="headerlink" title="3. 空间分配担保失败"></a>3. 空间分配担保失败</h4><p>使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。具体内容请参考上面的第 5 小节。</p><h4 id="4-JDK-1-7-及以前的永久代空间不足"><a href="#4-JDK-1-7-及以前的永久代空间不足" class="headerlink" title="4. JDK 1.7 及以前的永久代空间不足"></a>4. JDK 1.7 及以前的永久代空间不足</h4><p>在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据。</p><p>当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError。</p><p>为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。</p><h4 id="5-Concurrent-Mode-Failure"><a href="#5-Concurrent-Mode-Failure" class="headerlink" title="5. Concurrent Mode Failure"></a>5. Concurrent Mode Failure</h4><p>执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。</p><h2 id="类加载机制概念"><a href="#类加载机制概念" class="headerlink" title="类加载机制概念"></a>类加载机制概念</h2><ul><li>Java虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的加载机制。*Class文件由类装载器装载后，在JVM中将形成一份描述Class结构的元信息对象，通过该元信息对象可以获知Class的结构信息：如构造函数，属性和方法等，Java允许用户借由这个Class相关的元信息对象间接调用Class对象的功能,这里就是我们经常能见到的Class类。</li></ul><h3 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h3><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C6.png" alt="img"></p><p>工作机制</p><p>类装载器就是寻找类的字节码文件，并构造出类在JVM内部表示的对象组件。在Java中，类装载器把一个类装入JVM中，要经过以下步骤：</p><pre><code>  (1) 装载：查找和导入Class文件；  (2) 链接：把类的二进制数据合并到JRE中；     (a)校验：检查载入Class文件数据的正确性；     (b)准备：给类的静态变量分配存储空间；     (c)解析：将符号引用转成直接引用；  (3) 初始化：对类的静态变量，静态代码块执行初始化操作</code></pre><p>Java程序可以动态扩展是由运行期动态加载和动态链接实现的；比如：如果编写一个使用接口的应用程序，可以等到运行时再指定其实际的实现(多态)，解析过程有时候还可以在初始化之后执行；比如：动态绑定(多态)如上图所示，加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的，类的加载过程必须按照这个顺序来按部就班地开始，而解析阶段则不一定，它在某些情况下可以在初始化阶段后再开始。类的生命周期的每一个阶段通常都是互相交叉混合式进行的，通常会在一个阶段执行的过程中调用或激活另外一个阶段。</p><h4 id="装载-加载"><a href="#装载-加载" class="headerlink" title="装载(加载)"></a>装载(加载)</h4><p>类的装载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的<strong>方法区</strong>内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。</p><p>类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误）如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。</p><p>加载.class文件的方式有:</p><p>1). 从本地系统中直接加载2). 通过网络下载.class文件3). 从zip，jar等归档文件中加载.class文件4). 从专有数据库中提取.class文件5). 将Java源文件动态编译为.class文件</p><p>在了解了什么是类的加载后，回头来再看jvm进行类加载阶段都做了什么。虚拟机需要完成以下三件事情：</p><p>1).通过一个类的全限定名称来获取定义此类的二进制字节流。</p><p>2).将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</p><p>3).在java堆中生成一个代表这个类的java.lang.Class对象，作为方法区这些数据的访问入口。</p><p>相对于类加载过程的其他阶段，加载阶段是开发期相对来说可控性比较强，该阶段既可以使用系统提供的类加载器完成，也可以由用户自定义的类加载器来完成，开发人员可以通过定义自己的类加载器去控制字节流的获取方式。关于这个过程的更多细节，我会在下一节细说，类的加载。加载阶段完成后，虚拟机外部的 二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。</p><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a><strong>验证</strong></h4><p>验证的目的是为了确保Class文件中的字节流包含的信息符合当前虚拟机的要求，而且不会危害虚拟机自身的安全。不同的虚拟机对类验证的实现可能会有所不同，但大致都会完成以下四个阶段的验证：文件格式的验证、元数据的验证、字节码验证和符号引用验证。</p><p>1）文件格式的验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理，该验证的主要目的是保证输入的字节流能正确地解析并存储于方法区之内。经过该阶段的验证后，字节流才会进入内存的方法区中进行存储，后面的三个验证都是基于方法区的存储结构进行的。</p><p>2）元数据验证：对类的元数据信息进行语义校验（其实就是对类中的各数据类型进行语法校验），保证不存在不符合Java语法规范的元数据信息。</p><p>3）字节码验证：该阶段验证的主要工作是进行数据流和控制流分析，对类的方法体进行校验分析，以保证被校验的类的方法在运行时不会做出危害虚拟机安全的行为。</p><p>4）符号引用验证：这是最后一个阶段的验证，它发生在虚拟机将符号引用转化为直接引用的时候（解析阶段中发生该转化，后面会有讲解），主要是对类自身以外的信息（常量池中的各种符号引用）进行匹配性的校验。</p><h4 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h4><p>准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中进行分配。注：</p><p>1）这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。</p><p>2）这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。</p><h4 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h4><p>解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。</p><p>符号引用（Symbolic Reference）：符号引用以一组符号来描述所引用的目标，符号引用可以是任何形式的字面量，符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经在内存中。</p><p>直接引用（Direct Reference）：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机实现的内存布局相关的，同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般都不相同，如果有了直接引用，那引用的目标必定已经在内存中存在。</p><p>1)、类或接口的解析：判断所要转化成的直接引用是对数组类型，还是普通的对象类型的引用，从而进行不同的解析。</p><p>2)、字段解析：对字段进行解析时，会先在本类中查找是否包含有简单名称和字段描述符都与目标相匹配的字段，如果有，则查找结束；如果没有，则会按照继承关系从上往下递归搜索该类所实现的各个接口和它们的父接口，还没有，则按照继承关系从上往下递归搜索其父类，直至查找结束。</p><p>3)、类方法解析：对类方法的解析与对字段解析的搜索步骤差不多，只是多了判断该方法所处的是类还是接口的步骤，而且对类方法的匹配搜索，是先搜索父类，再搜索接口。</p><p>4)、接口方法解析：与类方法解析步骤类似，只是接口不会有父类，因此，只递归向上搜索父接口就行了。</p><p><strong>5. 初始化</strong></p><p>类初始化阶段是类加载过程的最后一步，前面的类加载过程中，除了加载（Loading）阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码。初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式：</p><p>①声明类变量时指定初始值</p><p>②使用静态代码块为类变量指定初始值</p><p>JVM初始化步骤</p><p>1)、假如这个类还没有被加载和连接，则程序先加载并连接该类</p><p>2)、假如该类的直接父类还没有被初始化，则先初始化其直接父类</p><p>3)、假如类中有初始化语句，则系统依次执行这些初始化语句</p><p>初始化阶段时执行类构造器方法()的过程。</p><p>1）类构造器方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序所决定。</p><p>2）类构造器方法与类的构造函数不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的类构造器方法执行之前，父类的类构造器方法已经执行完毕，因此在虚拟机中第一个执行的类构造器方法的类一定是java.lang.Object。</p><p>3）由于父类的类构造器方法方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作。</p><p>4）类构造器方法对于类或者接口来说并不是必需的，如果一个类中没有静态语句块也没有对变量的赋值操作，那么编译器可以不为这个类生成类构造器方法。</p><p>5）接口中可能会有变量赋值操作，因此接口也会生成类构造器方法。但是接口与类不同，执行接口的类构造器方法不需要先执行父接口的类构造器方法。只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也不会执行接口的类构造器方法。</p><p>6）虚拟机会保证一个类的类构造器方法在多线程环境中被正确地加锁和同步。如果有多个线程去同时初始化一个类，那么只会有一个线程去执行这个类的类构造器方法，其它线程都需要阻塞等待，直到活动线程执行类构造器方法完毕。如果在一个类的类构造器方法中有耗时很长的操作，那么就可能造成多个进程阻塞。</p><p><strong>6.结束生命周期</strong></p><p>在以下情况的时候，Java虚拟机会结束生命周期1). 执行了System.exit()方法2). 程序正常执行结束3). 程序在执行过程中遇到了异常或错误而异常终止4). 由于操作系统出现错误而导致Java虚拟机进程终止</p><h3 id="何时开始类的初始化"><a href="#何时开始类的初始化" class="headerlink" title="何时开始类的初始化"></a>何时开始类的初始化</h3><p>什么情况下需要开始类加载过程的第一个阶段:”加载”。虚拟机规范中并没强行约束，这点可以交给虚拟机的的具体实现自由把握，但是对于初始化阶段虚拟机规范是严格规定了如下几种情况，如果类未初始化会对类进行初始化。</p><p>1、创建类的实例</p><p>2、访问类的静态变量(除常量【被final修辞的静态变量】原因:常量一种特殊的变量，因为编译器把他们当作值(value)而不是域(field)来对待。如果你的代码中用到了常变量(constant variable)，编译器并不会生成字节码来从对象中载入域的值，而是直接把这个值插入到字节码中。这是一种很有用的优化，但是如果你需要改变final域的值那么每一块用到那个域的代码都需要重新编译。</p><p>3、访问类的静态方法</p><p>4、反射如(Class.forName(“my.xyz.Test”))</p><p>5、当初始化一个类时，发现其父类还未初始化，则先出发父类的初始化</p><p>6、虚拟机启动时，定义了main()方法的那个类先初始化</p><p>以上情况称为称对一个类进行“主动引用”，除此种情况之外，均不会触发类的初始化，称为“被动引用”接口的加载过程与类的加载过程稍有不同。接口中不能使用static{}块。当一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有真正在使用到父接口时（例如引用接口中定义的常量）才会初始化。</p><h4 id="被动引用例子"><a href="#被动引用例子" class="headerlink" title="被动引用例子"></a><strong>被动引用例子</strong></h4><p>1、子类调用父类的静态变量，子类不会被初始化。只有父类被初始化。。对于静态字段，只有直接定义这个字段的类才会被初始化.</p><p>2、通过数组定义来引用类，不会触发类的初始化</p><p>3、 访问类的常量，不会初始化类</p><pre><code>class SuperClass {      static {          System.out.println(&quot;superclass init&quot;);      }      public static int value = 123;  }  class SubClass extends SuperClass {      static {          System.out.println(&quot;subclass init&quot;);      }  }  public class Test {      public static void main(String[] args) {          System.out.println(SubClass.value);// 被动应用1          SubClass[] sca = new SubClass[10];// 被动引用2      }  }  复制代码</code></pre><p>程序运行输出    superclass init123从上面的输入结果证明了被动引用1与被动引用2</p><pre><code>class ConstClass {      static {          System.out.println(&quot;ConstClass init&quot;);      }      public static final String HELLOWORLD = &quot;hello world&quot;;  }  public class Test {      public static void main(String[] args) {          System.out.println(ConstClass.HELLOWORLD);// 调用类常量      }  }  复制代码</code></pre><p>程序输出结果hello world从上面的输出结果证明了被动引用3</p><p>** 题目分析**</p><p>上面很详细的介绍了类的加载时机和类的加载过程，通过上面的理论来分析本文开门见上的题目</p><pre><code>class SingleTon {      private static SingleTon singleTon = new SingleTon();      public static int count1;      public static int count2 = 0;      private SingleTon() {          count1++;          count2++;      }      public static SingleTon getInstance() {          return singleTon;      }  }  public class Test {      public static void main(String[] args) {          SingleTon singleTon = SingleTon.getInstance();          System.out.println(&quot;count1=&quot; + singleTon.count1);          System.out.println(&quot;count2=&quot; + singleTon.count2);      }  }  复制代码</code></pre><p>分析:</p><p>1:SingleTon singleTon = SingleTon.getInstance();调用了类的SingleTon调用了类的静态方法，触发类的初始化</p><p>2:类加载的时候在准备过程中为类的静态变量分配内存并初始化默认值 singleton=null count1=0,count2=0</p><p>3:类初始化化，为类的静态变量赋值和执行静态代码快。singleton赋值为new SingleTon()调用类的构造方法</p><p>4:调用类的构造方法后count=1;count2=1</p><p>5:继续为count1与count2赋值,此时count1没有赋值操作,所有count1为1,但是count2执行赋值操作就变为0</p><h3 id="类初始化顺序"><a href="#类初始化顺序" class="headerlink" title="类初始化顺序"></a>类初始化顺序</h3><p>现在我们知道什么时候触发类的初始化了，他精确地写在Java语言规范中。但了解清楚 域（fields，静态的还是非静态的）、块（block静态的还是非静态的）、不同类（子类和超类）和不同的接口（子接口，实现类和超接口）的初始化顺序也很重要类。事实上很多核心Java面试题和SCJP问题都是基于这些概念，下面是类初始化的一些规则：</p><pre><code>1.类从顶至底的顺序初始化，所以声明在顶部的字段的早于底部的字段初始化2.超类早于子类和衍生类的初始化3.如果类的初始化是由于访问静态域而触发，那么只有声明静态域的类才被初始化，而不会触发超类的初始化或者子类的4.初始化即使静态域被子类或子接口或者它的实现类所引用。5.接口初始化不会导致父接口的初始化。6.静态域的初始化是在类的静态初始化期间，非静态域的初始化时在类的实例创建期间。这意味这静态域初始化在非静态域之前。7.非静态域通过构造器初始化，子类在做任何初始化之前构造器会隐含地调用父类的构造器，他保证了非静态或实例变量（父类）初始化早于子类复制代码</code></pre><p>原文链接：</p><p>类加载举例：<a href="http://blog.csdn.net/mrzhoug/article/details/51581994" target="_blank" rel="noopener">http://blog.csdn.net/mrzhoug/article/details/51581994</a></p><h3 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h3><p>JVM设计者把类加载阶段中的“通过’类全名’来获取定义此类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块称为“类加载器”。</p><h4 id="类与类加载器"><a href="#类与类加载器" class="headerlink" title="类与类加载器"></a><strong>类与类加载器</strong></h4><p>对于任何一个类，都需要由加载它的类加载器和这个类来确立其在JVM中的唯一性。也就是说，两个类来源于同一个Class文件，并且被同一个类加载器加载，这两个类才相等。</p><h4 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a><strong>双亲委派模型</strong></h4><p>从虚拟机的角度来说，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），该类加载器使用C++语言实现，属于虚拟机自身的一部分。另外一种就是所有其它的类加载器，这些类加载器是由Java语言实现，独立于JVM外部，并且全部继承自抽象类java.lang.ClassLoader。</p><p>从Java开发人员的角度来看，大部分Java程序一般会使用到以下三种系统提供的类加载器：</p><p>1)启动类加载器（Bootstrap ClassLoader）：负责加载JAVA_HOME\lib目录中并且能被虚拟机识别的类库到JVM内存中，如果名称不符合的类库即使放在lib目录中也不会被加载。该类加载器无法被Java程序直接引用。</p><p>2)扩展类加载器（Extension ClassLoader）：该加载器主要是负责加载JAVA_HOME\lib\，该加载器可以被开发者直接使用。</p><p>3)应用程序类加载器（Application ClassLoader）：该类加载器也称为系统类加载器，它负责加载用户类路径（Classpath）上所指定的类库，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。</p><p>我们的应用程序都是由这三类加载器互相配合进行加载的，我们也可以加入自己定义的类加载器。这些类加载器之间的关系如下图所示：</p><p>如上图所示的类加载器之间的这种层次关系，就称为类加载器的双亲委派模型（Parent Delegation Model）。该模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。子类加载器和父类加载器不是以继承（Inheritance）的关系来实现，而是通过组合（Composition）关系来复用父加载器的代码。</p><p>双亲委派模型的工作过程为：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的加载器都是如此，因此所有的类加载请求都会传给顶层的启动类加载器，只有当父加载器反馈自己无法完成该加载请求（该加载器的搜索范围中没有找到对应的类）时，子加载器才会尝试自己去加载。</p><p>使用这种模型来组织类加载器之间的关系的好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如java.lang.Object类，无论哪个类加载器去加载该类，最终都是由启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。否则的话，如果不使用该模型的话，如果用户自定义一个java.lang.Object类且存放在classpath中，那么系统中将会出现多个Object类，应用程序也会变得很混乱。如果我们自定义一个rt.jar中已有类的同名Java类，会发现JVM可以正常编译，但该类永远无法被加载运行。在rt.jar包中的java.lang.ClassLoader类中，我们可以查看类加载实现过程的代码，具体源码如下：</p><pre><code>protected synchronized Class loadClass(String name, boolean resolve)          throws ClassNotFoundException {      // 首先检查该name指定的class是否有被加载      Class c = findLoadedClass(name);      if (c == null) {          try {              if (parent != null) {                  // 如果parent不为null，则调用parent的loadClass进行加载                  c = parent.loadClass(name, false);              } else {                  // parent为null，则调用BootstrapClassLoader进行加载                  c = findBootstrapClass0(name);              }          } catch (ClassNotFoundException e) {              // 如果仍然无法加载成功，则调用自身的findClass进行加载              c = findClass(name);          }      }      if (resolve) {          resolveClass(c);      }      return c;  }  复制代码</code></pre><p>通过上面代码可以看出，双亲委派模型是通过loadClass()方法来实现的，根据代码以及代码中的注释可以很清楚地了解整个过程其实非常简单：先检查是否已经被加载过，如果没有则调用父加载器的loadClass()方法，如果父加载器为空则默认使用启动类加载器作为父加载器。如果父类加载器加载失败，则先抛出ClassNotFoundException，然后再调用自己的findClass()方法进行加载。</p><h4 id="自定义类加载器"><a href="#自定义类加载器" class="headerlink" title="自定义类加载器"></a><strong>自定义类加载器</strong></h4><p>若要实现自定义类加载器，只需要继承java.lang.ClassLoader 类，并且重写其findClass()方法即可。java.lang.ClassLoader 类的基本职责就是根据一个指定的类的名称，找到或者生成其对应的字节代码，然后从这些字节代码中定义出一个 Java 类，即 java.lang.Class 类的一个实例。除此之外，ClassLoader 还负责加载 Java 应用所需的资源，如图像文件和配置文件等，ClassLoader 中与加载类相关的方法如下：</p><p>方法说明getParent()  返回该类加载器的父类加载器。</p><p>loadClass(String name) 加载名称为 二进制名称为name 的类，返回的结果是 java.lang.Class 类的实例。</p><p>findClass(String name) 查找名称为 name 的类，返回的结果是 java.lang.Class 类的实例。</p><p>findLoadedClass(String name) 查找名称为 name 的已经被加载过的类，返回的结果是 java.lang.Class 类的实例。</p><p>resolveClass(Class&lt;?&gt; c) 链接指定的 Java 类。</p><p>注意：在JDK1.2之前，类加载尚未引入双亲委派模式，因此实现自定义类加载器时常常重写loadClass方法，提供双亲委派逻辑，从JDK1.2之后，双亲委派模式已经被引入到类加载体系中，自定义类加载器时不需要在自己写双亲委派的逻辑，因此不鼓励重写loadClass方法，而推荐重写findClass方法。</p><p>在Java中，任意一个类都需要由加载它的类加载器和这个类本身一同确定其在java虚拟机中的唯一性，即比较两个类是否相等，只有在这两个类是由同一个类加载器加载的前提之下才有意义，否则，即使这两个类来源于同一个Class类文件，只要加载它的类加载器不相同，那么这两个类必定不相等(这里的相等包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法和instanceof关键字的结果)。例子代码如下：</p><pre><code>/**      * 一、ClassLoader加载类的顺序      *  1.调用 findLoadedClass(String) 来检查是否已经加载类。      *  2.在父类加载器上调用 loadClass 方法。如果父类加载器为 null，则使用虚拟机的内置类加载器。      *  3.调用 findClass(String) 方法查找类。      * 二、实现自己的类加载器      *  1.获取类的class文件的字节数组      *  2.将字节数组转换为Class类的实例      * @author lei 2011-9-1      */      public class ClassLoaderTest {          public static void main(String[] args) throws InstantiationException, IllegalAccessException, ClassNotFoundException {              //新建一个类加载器              MyClassLoader cl = new MyClassLoader(&quot;myClassLoader&quot;);              //加载类，得到Class对象              Class&lt;?&gt; clazz = cl.loadClass(&quot;classloader.Animal&quot;);              //得到类的实例              Animal animal=(Animal) clazz.newInstance();              animal.say();          }      }      class Animal{          public void say(){              System.out.println(&quot;hello world!&quot;);          }      }      class MyClassLoader extends ClassLoader {          //类加载器的名称          private String name;          //类存放的路径          private String path = &quot;E:\\workspace\\Algorithm\\src&quot;;          MyClassLoader(String name) {              this.name = name;          }          MyClassLoader(ClassLoader parent, String name) {              super(parent);              this.name = name;          }          /**          * 重写findClass方法          */          @Override          public Class&lt;?&gt; findClass(String name) {              byte[] data = loadClassData(name);              return this.defineClass(name, data, 0, data.length);          }          public byte[] loadClassData(String name) {              try {                  name = name.replace(&quot;.&quot;, &quot;//&quot;);                  FileInputStream is = new FileInputStream(new File(path + name + &quot;.class&quot;));                  ByteArrayOutputStream baos = new ByteArrayOutputStream();                  int b = 0;                  while ((b = is.read()) != -1) {                      baos.write(b);                  }                  return baos.toByteArray();              } catch (Exception e) {                  e.printStackTrace();              }              return null;          }      }  复制代码</code></pre><p>类加载器双亲委派模型是从JDK1.2以后引入的，并且只是一种推荐的模型，不是强制要求的，因此有一些没有遵循双亲委派模型的特例：(了解)</p><p>(1).在JDK1.2之前，自定义类加载器都要覆盖loadClass方法去实现加载类的功能，JDK1.2引入双亲委派模型之后，loadClass方法用于委派父类加载器进行类加载，只有父类加载器无法完成类加载请求时才调用自己的findClass方法进行类加载，因此在JDK1.2之前的类加载的loadClass方法没有遵循双亲委派模型，因此在JDK1.2之后，自定义类加载器不推荐覆盖loadClass方法，而只需要覆盖findClass方法即可。</p><p>(2).双亲委派模式很好地解决了各个类加载器的基础类统一问题，越基础的类由越上层的类加载器进行加载，但是这个基础类统一有一个不足，当基础类想要调用回下层的用户代码时无法委派子类加载器进行类加载。为了解决这个问题JDK引入了ThreadContext线程上下文，通过线程上下文的setContextClassLoader方法可以设置线程上下文类加载器。</p><p>JavaEE只是一个规范，sun公司只给出了接口规范，具体的实现由各个厂商进行实现，因此JNDI，JDBC,JAXB等这些第三方的实现库就可以被JDK的类库所调用。线程上下文类加载器也没有遵循双亲委派模型。</p><p>(3).近年来的热码替换，模块热部署等应用要求不用重启java虚拟机就可以实现代码模块的即插即用，催生了OSGi技术，在OSGi中类加载器体系被发展为网状结构。OSGi也没有完全遵循双亲委派模型。</p><h4 id="动态加载Jar-amp-amp-ClassLoader-隔离问题"><a href="#动态加载Jar-amp-amp-ClassLoader-隔离问题" class="headerlink" title="动态加载Jar &amp;&amp; ClassLoader 隔离问题"></a><strong>动态加载Jar &amp;&amp; ClassLoader 隔离问题</strong></h4><p>动态加载Jar：</p><p>Java 中动态加载 Jar 比较简单，如下：</p><pre><code>URL[] urls = new URL[] {new URL(&quot;file:libs/jar1.jar&quot;)};  URLClassLoader loader = new URLClassLoader(urls, parentLoader);  复制代码</code></pre><p>表示加载 libs 下面的 jar1.jar，其中 parentLoader 就是上面1中的 parent，可以为当前的 ClassLoader。</p><p>ClassLoader 隔离问题：</p><p>大家觉得一个运行程序中有没有可能同时存在两个包名和类名完全一致的类？JVM 及 Dalvik 对类唯一的识别是 ClassLoader id + PackageName + ClassName，所以一个运行程序中是有可能存在两个包名和类名完全一致的类的。并且如果这两个”类”不是由一个 ClassLoader 加载，是无法将一个类的示例强转为另外一个类的，这就是 ClassLoader 隔离。 如 Android 中碰到如下异常[java] view plain copy</p><pre><code>android.support.v4.view.ViewPager can not be cast to android.support.v4.view.ViewPager  复制代码</code></pre><p>当碰到这种问题时可以通过 instance.getClass().getClassLoader(); 得到 ClassLoader，看 ClassLoader 是否一样。</p><p>加载不同 Jar 包中公共类：</p><p>现在 Host 工程包含了 common.jar, jar1.jar, jar2.jar，并且 jar1.jar 和 jar2.jar 都包含了 common.jar，我们通过 ClassLoader 将 jar1, jar2 动态加载进来，这样在 Host 中实际是存在三份 common.jar，如下图：</p><p><a href="https://farm4.staticflickr.com/3872/14301963930_2f0f0fe8aa_o.png" target="_blank" rel="noopener">https://farm4.staticflickr.com/3872/14301963930_2f0f0fe8aa_o.png</a></p><p>我们怎么保证 common.jar 只有一份而不会造成上面3中提到的 ClassLoader 隔离的问题呢，其实很简单，在生成 jar1 和 jar2 时把 common.jar 去掉，只保留 host 中一份，以 host ClassLoader 为 parentClassLoader 即可。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>动态代理的实现方式与区别</title>
      <link href="/2020/01/06/dong-tai-dai-li-de-shi-xian-fang-shi-yu-qu-bie/"/>
      <url>/2020/01/06/dong-tai-dai-li-de-shi-xian-fang-shi-yu-qu-bie/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>java异常</title>
      <link href="/2020/01/05/java-yi-chang/"/>
      <url>/2020/01/05/java-yi-chang/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>javaWeb三大核心组件之servlet</title>
      <link href="/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/"/>
      <url>/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/</url>
      
        <content type="html"><![CDATA[<h1 id="javaWeb三大核心组件之Servlet"><a href="#javaWeb三大核心组件之Servlet" class="headerlink" title="javaWeb三大核心组件之Servlet"></a>javaWeb三大核心组件之Servlet</h1><h3 id="什么是Servlet"><a href="#什么是Servlet" class="headerlink" title="什么是Servlet"></a>什么是Servlet</h3><p>Java Servlet 是运行在 Web 服务器或应用服务器上的程序，它是作为来自 Web 浏览器或其他 HTTP 客户端的请求和 HTTP 服务器上的数据库或应用程序之间的中间层。</p><p>使用 Servlet，您可以收集来自网页表单的用户输入，呈现来自数据库或者其他源的记录，还可以动态创建网页。</p><p>Java Servlet 通常情况下与使用 CGI（Common Gateway Interface，公共网关接口）实现的程序可以达到异曲同工的效果。但是相比于 CGI，Servlet 有以下几点优势：</p><p>性能明显更好。</p><p>Servlet 在 Web 服务器的地址空间内执行。这样它就没有必要再创建一个单独的进程来处理每个客户端请求。</p><p>Servlet 是独立于平台的，因为它们是用 Java 编写的。</p><p>服务器上的 Java 安全管理器执行了一系列限制，以保护服务器计算机上的资源。因此，Servlet 是可信的。</p><p>Java 类库的全部功能对 Servlet 来说都是可用的。它可以通过 sockets 和 RMI 机制与 applets、数据库或其他软件进行交互。</p><h3 id="Tomcat与Servlet的关系"><a href="#Tomcat与Servlet的关系" class="headerlink" title="Tomcat与Servlet的关系"></a>Tomcat与Servlet的关系</h3><p>Tomcat 是Web应用服务器,是一个Servlet/JSP容器. Tomcat 作为Servlet容器,负责处理客户请求,把请求传送给Servlet,并将Servlet的响应传送回给客户.而Servlet是一种运行在支持Java语言的服务器上的组件.。</p><p>Servlet最常见的用途是扩展Java Web服务器功能,提供非常安全的,可移植的,易于使用的CGI替代品。从http协议中的请求和响应可以得知，浏览器发出的请求是一个请求文本，而浏览器接收到的也应该是一个响应文本。</p><p><img src="/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/javaWeb%E4%B8%89%E5%A4%A7%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E4%B9%8Bservlet%5C1" alt="image"></p><ol><li>Tomcat将http请求文本接收并解析，然后封装成HttpServletRequest类型的request对象，所有的HTTP头数据读可以通过request对象调用对应的方法查询到。</li><li>Tomcat同时会要响应的信息封装为HttpServletResponse类型的response对象，通过设置response属性就可以控制要输出到浏览器的内容，然后将response交给tomcat，tomcat就会将其变成响应文本的格式发送给浏览器。</li></ol><p>Java Servlet API 是Servlet容器(tomcat)和servlet之间的接口，它定义了serlvet的各种方法，还定义了Servlet容器传送给Servlet的对象类，其中最重要的就是ServletRequest和ServletResponse。所以说我们在编写servlet时，需要实现Servlet接口，按照其规范进行操作。</p><h3 id="Servlet执行过程"><a href="#Servlet执行过程" class="headerlink" title="Servlet执行过程"></a>Servlet执行过程</h3><p> 在浏览器的地址栏输入：<a href="http://ip" target="_blank" rel="noopener">http://ip</a>:port/appNames/servlet</p><p>  1）通过浏览器和ip：port和这个服务器建立连接。<br>  2） 浏览器会生成一个请求数据包（路径appNames/servlet）向服务器发送请求。<br>  3） 服务器收到请求数据包，分析请求资源路径做精准定位，通过请求的appName查找webapps文件下面的appName做匹配，匹配上了需要获取web.xml中的servlet(mapping)。 <br>  4） 服务器创建两个对象：<br>    第一个对象：请求对象，该对象实现了HttpServletRequest接口，服务器会将请求数据包中的数据解析出来,存储在该对象里。这样做的好处是没有必要理解http协议，只需要读取request。<br>    第二个对象：响应对象，实现了HttpServletResponse接口，作用是servlet处理完成后的结果可以存放到该对象上，然后服务器依据该对象的数据生成响应数据包。<br>  5） servlet在执行servlet()方法时，可以通过request获取请求数据，也可以将处理结果存放到response上。然后服务器与响应对象直接形成一个默契，生成一个响应数据包给浏览器。<br>  6）浏览器解析服务器返回的响应数据包，生成响应的结果。</p><p>  </p><p><img src="/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/javaWeb%E4%B8%89%E5%A4%A7%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E4%B9%8Bservlet%5C2.png" alt="image"></p><p>Servlet访问的过程：<br>Http请求—-&gt;web.xml——–&gt;  url -pattern—–&gt;servlet-name—–&gt;servlet-class—–&gt;   QuickStratServlet(对应的Class文件)</p><h3 id="Servlet生命周期"><a href="#Servlet生命周期" class="headerlink" title="Servlet生命周期"></a>Servlet生命周期</h3><p>SpringMVC是基于servlet，控制器基于方法级别的拦截，处理器设计为单实例，所以应该了解一下Servlet的生命周期。</p><p>Servlet 加载—&gt;实例化—&gt;服务—&gt;销毁。</p><p><strong>init</strong>（）：</p><p>在Servlet的生命周期中，仅执行一次init()方法。它是在服务器装入Servlet时执行的，负责初始化Servlet对象。可以配置服务器，以在启动服务器或客户机首次访问Servlet时装入Servlet。无论有多少客户机访问Servlet，都不会重复执行init（）。</p><p><strong>service</strong>（）：</p><p>它是Servlet的核心，负责响应客户的请求。每当一个客户请求一个HttpServlet对象，该对象的Service()方法就要调用，而且传递给这个方法一个“请求”（ServletRequest）对象和一个“响应”（ServletResponse）对象作为参数。在HttpServlet中已存在Service()方法。默认的服务功能是调用与HTTP请求的方法相应的do功能。</p><p><strong>destroy</strong>（）：</p><p>仅执行一次，在服务器端停止且卸载Servlet时执行该方法。当Servlet对象退出生命周期时，负责释放占用的资源。一个Servlet在运行service()方法时可能会产生其他的线程，因此需要确认在调用destroy()方法时，这些线程已经终止或完成。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>SpringMVC原理</title>
      <link href="/2020/01/04/springmvc-yuan-li/"/>
      <url>/2020/01/04/springmvc-yuan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><a href="http://lib.csdn.net/base/javaee" target="_blank" rel="noopener">spring</a> MVC主要由DispatcherServlet、处理器映射、处理器(控制器)、视图解析器、视图组成。他的两个核心是两个核心：</p><p><strong>处理器映射：</strong> 选择使用哪个控制器来处理请求。<br><strong>视图解析器：</strong> 选择结果应该如何渲染。</p><h2 id="运行原理"><a href="#运行原理" class="headerlink" title="运行原理"></a>运行原理</h2><p>下图是在Spring官网开发手册上找到的，它清晰的诠释了Spring MVC的运行原理</p><p><img src="/2020/01/04/springmvc-yuan-li/SpringMVC%E5%8E%9F%E7%90%86%5C16b5eb3870589ac4.png" alt="16b5eb3870589ac4"></p><p>①客户端的所有请求都交给前端控制器DispatcherServlet来处理，它会负责调用系统的其他模块来真正处理用户的请求。</p><p>② DispatcherServlet收到请求后，将根据请求的信息（包括URL、HTTP协议方法、请求头、请求参数、Cookie等）以及HandlerMapping的配置找到处理该请求的Handler（任何一个对象都可以作为请求的Handler）。</p><p>③在这个地方Spring会通过HandlerAdapter对该处理器进行封装。</p><p>④ HandlerAdapter是一个适配器，它用统一的接口对各种Handler中的方法进行调用。</p><p>⑤ Handler完成对用户请求的处理后，会返回一个ModelAndView对象给DispatcherServlet，ModelAndView顾名思义，包含了数据模型以及相应的视图的信息。</p><p>⑥ ModelAndView的视图是逻辑视图，DispatcherServlet还要借助ViewResolver完成从逻辑视图到真实视图对象的解析工作。⑦ 当得到真正的视图对象后，DispatcherServlet会利用视图对象对模型数据进行渲染。</p><p>⑧ 客户端得到响应，可能是一个普通的HTML页面，也可以是XML或JSON字符串，还可以是一张图片或者一个PDF文件。</p><p><img src="/2020/01/04/springmvc-yuan-li/SpringMVC%E5%8E%9F%E7%90%86%5C16b5eb3870589ac4.png" alt="16b5eb3870589ac4"></p><h2 id="接口的解释"><a href="#接口的解释" class="headerlink" title="接口的解释"></a>接口的解释</h2><table><thead><tr><th>接口名称</th><th>功能</th></tr></thead><tbody><tr><td>DispatcherServlet</td><td>Spring提供的前端控制器，客户端的所有请求都由DispatcherServlet负责分发，当然在DispatcherServlet分发之前，还需要一个匹配请求的过程，这个由HandlerMapping来完成。</td></tr><tr><td>HandlerMapping</td><td>完成客户端请求到Controller映射的工作</td></tr><tr><td>Controller</td><td>用于处理用户请求，返回处理结果</td></tr><tr><td>ViewResolver</td><td>Web应用中查找View对象，从而将相应结果渲染给客户端</td></tr></tbody></table><h2 id="DispatcherServlet："><a href="#DispatcherServlet：" class="headerlink" title="DispatcherServlet："></a>DispatcherServlet：</h2><p>是整个Spring MVC的核心。它负责接收HTTP请求组织协调Spring MVC的各个组成部分。</p><p>其主要工作有以下三项：</p><ol><li>截获符合特定格式的URL请求。</li><li>初始化DispatcherServlet上下文对应WebApplicationContext，并将其与业务层、持久化层的WebApplicationContext建立关联。</li><li>初始化Spring MVC的各个组成组件，并装配到DispatcherServlet中。</li></ol><h2 id="一个比较好理解的Spring-mvc原理图"><a href="#一个比较好理解的Spring-mvc原理图" class="headerlink" title="一个比较好理解的Spring mvc原理图"></a>一个比较好理解的Spring mvc原理图</h2><p><img src="/2020/01/04/springmvc-yuan-li/SpringMVC%E5%8E%9F%E7%90%86%5Cb856096cf065baaaabe5884deb4ecfa3.png" alt="b856096cf065baaaabe5884deb4ecfa3"></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>回头再看spring</title>
      <link href="/2020/01/04/hui-tou-zai-kan-spring/"/>
      <url>/2020/01/04/hui-tou-zai-kan-spring/</url>
      
        <content type="html"><![CDATA[<h2 id="回头再看Spring"><a href="#回头再看Spring" class="headerlink" title="回头再看Spring"></a>回头再看Spring</h2><h3 id="什么是Spring"><a href="#什么是Spring" class="headerlink" title="什么是Spring"></a>什么是Spring</h3><p>Spring是个包含一系列功能的合集，如快速构建微服务的Spring Boot，管理一系列微服务的Spring Cloud，支持认证与鉴权的Spring Security，基于MVC的Web框架Spring MVC。但IOC与AOP依然是核心。</p><h3 id="Spring-Bean"><a href="#Spring-Bean" class="headerlink" title="Spring Bean"></a>Spring Bean</h3><p><strong>IOC的底层原理：文档解析xml文件，反射动态创建对象，然后保存name和Object，然后对每个对象属性进行属性注入</strong></p><h5 id="加载Bean的主要逻辑"><a href="#加载Bean的主要逻辑" class="headerlink" title="加载Bean的主要逻辑"></a>加载Bean的主要逻辑</h5><p>​    1.获取配置文件资源</p><p>​    2.对获取的xml资源进行一定的处理检验</p><p>​    3.处理包装资源</p><p>​    4.解析处理包装过后的资源</p><p>​    5.加载提取bean并注册(添加到beanDefinitionMap中</p><h5 id="Bean的生命周期"><a href="#Bean的生命周期" class="headerlink" title="Bean的生命周期"></a>Bean的生命周期</h5><ul><li>Bean的建立，由BeanFactory读取Bean定义文件，并创建Bean实例；</li><li>执行Bean的属性注入,Setter注入；</li><li>如果Bean类实现了org.springframework.beans.factory.BeanNameAware接口,则执行其setBeanName方法；</li><li>如果Bean类实现了org.springframework.beans.factory.BeanFactoryAware接口,则执行其setBeanFactory方法；</li><li>如果容器中有实现org.springframework.beans.factory.BeanPostProcessors接口的实例，则任何Bean在初始化之前都会执行这个实例的processBeforeInitialization()方法；</li><li>如果Bean类实现了org.springframework.beans.factory.InitializingBean接口，则执行其afterPropertiesSet()方法；</li><li>调用Bean的初始化方法”init-method” (！！注意，init-method方法没有参数)；</li><li>如果容器中有实现org.springframework.beans.factory.BeanPostProcessors接口的实例，则任何Bean在初始化之后都会执行这个实例的processAfterInitialization()方法；</li><li>使用Bean做一些业务逻辑….</li><li>使用完，容器关闭，如果Bean类实现了org.springframework.beans.factory.DisposableBean接口，则执行它的destroy()方法；</li><li>在容器关闭时，可以在Bean定义文件中使用“destory-method”定义的方法，销毁Bean (！！注意，destory-method方法没有参数)；</li></ul><h5 id="Bean的作用域"><a href="#Bean的作用域" class="headerlink" title="Bean的作用域"></a>Bean的作用域</h5><ul><li>Singleton: 这是默认的作用域，这种范围确保不管接受多少个请求，每个容器中只有一个bean的实例，单例模式有BeanFactory自身维护；</li><li>Prototype: 原形范围与单例范围相反，为每一个bean请求提供一个实例；</li></ul><ul><li>Request: 在请求bean范围内会为每一个来自客户端的网络请求创建一个实例，在请求完成以后，bean会失效并被垃圾回收器回收；</li><li>Session: 与请求范围类似，确保每个session中有一个bean的实例，在session过期后，bean会随之失效；</li><li>global-session: global-session和Portlet应用相关。当你的应用部署在Portlet容器中工作时，它包含很多portlet。如果你想要声明让所有的portlet共用全局的存储变量的话，那么这全局变量需要存储在global-session中。</li></ul><h3 id="Spring-IOC"><a href="#Spring-IOC" class="headerlink" title="Spring IOC"></a>Spring IOC</h3><p>IOC(控制反转):本质就是自己的信息(全类名等)配置在文件中或者加上注解,让容器可以通过反射的方式来创建对象,从而接管对象,代替了自己通过new创建对象.其实就是讲对象的管理创建交给了容器来做.</p><p>依赖注入:在运行过程中,会在需要这个对象的位置坐上一个标记,容器会负责创建对象实例并注入其中;</p><h4 id="Spring-IOC容器的初始化过程"><a href="#Spring-IOC容器的初始化过程" class="headerlink" title="Spring IOC容器的初始化过程"></a>Spring IOC容器的初始化过程</h4><p>IoC容器的初始化就是含有BeanDefinition信息的Resource的定位、载入、解析、注册四个过程，最终我们配置的bean，以beanDefinition的数据结构存在于IoC容器即内存中。</p><h5 id="Resource定位过程"><a href="#Resource定位过程" class="headerlink" title="Resource定位过程"></a>Resource定位过程</h5><p>这个Resource定位指的是BeanDefinition的资源定位，它由ResourceLoader通过统一的Resource接口来完成，这个Resource对各种形式的BeanDefinition的使用提供了统一接口。</p><h5 id="BeanDefinition的载入"><a href="#BeanDefinition的载入" class="headerlink" title="BeanDefinition的载入"></a>BeanDefinition的载入</h5><p>该载入过程把用户定义好的Bean表示成IoC容器内部的数据结构，而这个容器内部的数据结构就BeanDefinition.</p><h5 id="向IoC容器注册这些BeanDefinition"><a href="#向IoC容器注册这些BeanDefinition" class="headerlink" title="向IoC容器注册这些BeanDefinition"></a>向IoC容器注册这些BeanDefinition</h5><p>这个过程是通过调用BeanDefinitionRegistry接口的实现来完成的，这个注册过程把载入过程中解析得到的BeanDefinition向IoC容器进行注册,在IoC容器内部将BeanDefinition注入到一个HashMap中去，Ioc容器是通过这个HashMap来持有这些BeanDefinition数据的。</p><p>容器的初始化是通过AbstractApplicationContext的refresh()实现的。</p><pre><code></code></pre><p>整个过程如下图:</p><p><img src="/2020/01/04/hui-tou-zai-kan-spring/%E5%9B%9E%E5%A4%B4%E5%86%8D%E7%9C%8Bspring%5C1.png" alt="img"></p><h3 id="Spring-AOP"><a href="#Spring-AOP" class="headerlink" title="Spring AOP"></a>Spring AOP</h3><p>面向切面的编程，是一种编程技术，<strong>是OOP（面向对象编程）的补充和完善</strong>。OOP的执行是一种从上往下的流程，并没有从左到右的关系。因此在OOP编程中，会有大量的重复代码。而<strong>AOP则是将这些与业务无关的重复代码抽取出来，然后再嵌入到业务代码当中</strong>。常见的应用有：权限管理、日志、事务管理等。</p><p>AOP有三种植入切面的方法：其一是编译期织入，这要求使用特殊的Java编译器，AspectJ是其中的代表者；其二是类装载期织入，而这要求使用特殊的类装载器，AspectJ和AspectWerkz是其中的代表者；其三为动态代理织入，在运行期为目标类添加增强生成子类的方式，<strong>Spring AOP采用动态代理织入切面</strong>。</p><p>AspectJ是静态代理的增强，所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强。</p><p>它会在<strong>编译阶段</strong>将Aspect织入Java字节码中， 运行的时候就是经过增强之后的AOP对象。</p><p>AspectJ在编译时就增强了目标对象，Spring AOP的动态代理则是在每次运行时动态的增强，生成AOP代理对象，区别在于生成AOP代理对象的时机不同，相对来说<strong>AspectJ的静态代理方式具有更好的性能</strong>，但是AspectJ<strong>需要特定的编译器</strong>进行处理，而Spring AOP则无需特定的编译器处理。</p><p>Spring AOP中的动态代理主要有两种方式，<strong>JDK动态代理</strong>和<strong>CGLIB动态代理</strong>。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。<strong>JDK动态代理的核心是InvocationHandler接口和Proxy类</strong>。</p><p>如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态地生成某个类的子类，注意，<strong>CGLIB是通过继承的方式做的动态代理</strong>，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的</p><h4 id="jDK代理"><a href="#jDK代理" class="headerlink" title="jDK代理"></a>jDK代理</h4><p> JDK的动态代理主要涉及到java.lang.reflect包中的两个类：Proxy和InvocationHandler。其中 InvocationHandler是一个接口就是拦截器的接口。，可以通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态将横切逻辑和业务逻辑编织在一起。</p><h5 id="InvocationHandler的作用"><a href="#InvocationHandler的作用" class="headerlink" title="InvocationHandler的作用"></a>InvocationHandler的作用</h5><p>在动态代理中InvocationHandler是核心，每个代理实例都具有一个关联的调用处理程序(InvocationHandler)。对代理实例调用方法时，将对方法调用进行编码并将其指派到它的调用处理程序(InvocationHandler)的 invoke 方法。所以对代理方法的调用都是通InvocationHadler的invoke来实现中，而invoke方法根据传入的代理对象，方法和参数来决定调用代理的哪个方法</p><h5 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h5><p>使用代理模式必须要让代理类和目标类实现相同的接口，客户端通过代理类来调用目标方法，代理类会将所有的方法调用分派到目标对象上反射执行，还可以在分派过程中添加”前置通知”和后置处理（如在调用目标方法前校验权限，在调用完目标方法后打印日志等）等功能。</p><p>具体有如下四步骤：</p><p>1.通过实现 InvocationHandler 接口创建自己的调用处理器；</p><p>2.通过为 Proxy 类指定 ClassLoader 对象和一组 interface 来创建动态代理类；</p><p>3.通过反射机制获得动态代理类的构造函数，其唯一参数类型是调用处理器接口类型；</p><p>4.通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数被传入。</p><p><img src="/2020/01/04/hui-tou-zai-kan-spring/%E5%9B%9E%E5%A4%B4%E5%86%8D%E7%9C%8Bspring%5Cclipboard.png" alt="clipboard"></p><h4 id="利用cglib代理实现AOP"><a href="#利用cglib代理实现AOP" class="headerlink" title="利用cglib代理实现AOP"></a>利用cglib代理实现AOP</h4><p>CGlib是一个强大的,高性能,高质量的Code生成类库。cglib封装了asm，可以在运行期动态生成新的class，它可以在运行期扩展Java类与实现Java接口。 CGLIB是<strong>针对类实现代理</strong>的，主要对指定的类生成一个子类，并覆盖其中的方法， 因为是继承，所以不能使用final来修饰类或方法。和jdk代理实现不同的是，cglib不要求类实现接口。</p><p>JDK动态代理和CGLIB字节码生成的区别？</p><p>CGLib所创建的动态代理对象的性能比JDK的高大概10倍，但CGLib在创建代理对象的时间比JDK大概多8倍，所以对于singleton的代理对象或者具有实例池的代理，因为无需重复的创建代理对象，所以比较适合CGLib动态代理技术，反之选择JDK代理</p><ul><li><p>JDK动态代理只能对实现了接口的类生成代理，而不能针对类</p></li><li><p>CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法</p><p>因为是继承，所以该类或方法最好不要声明成final </p></li></ul><p>1、如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP</p><p>2、如果目标对象实现了接口，可以强制使用CGLIB实现AOP</p><p>3、如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>理解KMP回溯</title>
      <link href="/2020/01/03/li-jie-kmp-hui-su/"/>
      <url>/2020/01/03/li-jie-kmp-hui-su/</url>
      
        <content type="html"><![CDATA[<h4 id="理解KMP回溯"><a href="#理解KMP回溯" class="headerlink" title="理解KMP回溯"></a>理解KMP回溯</h4><p>相信大家都看过KMP算法，但是对于它的回溯确是难以理解。我们先来看一下KMP中的next数组生成代码：</p><pre><code>    //用于生成next数组    private static int[] get_next(String target){        int[] next = new int[target.length()];        next[0] = -1;        int i = 0, j = -1;        while(i &lt; target.length() - 1){            if (j == -1 || target.charAt(i) == target.charAt(j)) {                ++i;                ++j;                next[i] = j;            } else {                j = next[j];            }        }        return next;    }</code></pre><ul><li>其中数组的next中的值计算方式是：</li></ul><p>next[j] = Max{k | 1&lt;k&lt;j,且‘p1p2…pk’=‘p(j-k)…p(j - 1)’}</p><ul><li><h5 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h5></li></ul><p><em>简单来说next[j]表示的就是两个相等的字符串的长度，这两个字符串分别是从头开始记的长度为next[j]的和以next[j]的前一个字符结尾的长度为next[j]。</em></p><ul><li><h5 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h5></li></ul><p>例如：字符串”ababaaaba” next = [-1,0,0,1,2,3,1,1,2]<br>其中的回溯环节就是从next[5] = 3 到 next[6] = 1;</p><p>其中next[5]时：是”ababa”中前缀”aba”与后缀”aba”的长度，当i = 6时，”ababaa”中”a”不等于”b”,所以回溯到j = next[j],其中j为现在next[5]的值。</p><ul><li><h5 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h5></li></ul><p><strong>我开始也是很不明白为什么就可以直接回到j = next[next[5]] = 0处开始向后比较，后来仔细研究发现原因是，通过前面的比较它已经排除了所有的前缀字符串等于后缀字符串的长度大于回溯到当前j的可能 。</strong><br>就拿上面的“ababa”到“ababaa”举例：<br>其实我们想不通的无非就是它是怎么排除“aba”!=”baa”转而直接去判断前缀“ab”是否等于后缀“aa”,后来我仔细分析才发现因为如果前面的“aba” = “baa”要成立，必须有“前缀ab”等于后缀“ba”,而得到next[5]=3的时候已经隐式的得到的第一个“ba”等于第二个“ba”(当时是“aba” = “aba”)<br>从而有“aba”中三个值都应该相等，与前面矛盾。可能你早就看不懂我在说什么了，来一点数学表达式比较实际：</p><ul><li><h5 id="数学证明"><a href="#数学证明" class="headerlink" title="数学证明"></a>数学证明</h5></li></ul><p>②开始有p1p2….pj = pi - j ….pi-1，可以得出pj = pj-1  j = 1,2,…<br>假设 next[j] = k 就有 p1p2…pk = pj-k …pj-1    k = 1,2…<br>若加入pi != pj + 1,则需要回溯到判断pk 是否等于pj;<br>首先证明：pi-j+1…pi ！= p1p2…pj,反证：假设：pi-j+1…pi = p1p2…p，又p1p2….pj = pi - j ….pi-1<br>所以有pi - j ….pi-1 =pi-j+1…pi ,得到pi-j=pi-j+1=…=pi;与前面矛盾，所以有pi-j+1…pi ！= p1p2…pj<br>同理可以得出pi-j+2…pi ！= p1p2…pj-1  。。。。。pi-j+k…pi ！= p1p2…pj-k+1  。。。。。<br>所以可以直接回溯到j = next[j]继续向后判断</p><p>KMP完整代码</p><pre><code>    private static int[] get_next(String target){        int[] next = new int[target.length()];        next[0] = -1;        int i = 0, j = -1;        while(i &lt; target.length() - 1){            if (j == -1 || target.charAt(i) == target.charAt(j)) {                ++i;                ++j;                next[i] = j;            } else {                j = next[j];            }        }        return next;    }    int kmp(String s, String pattern) {        int i = 0,j = 0;        int slen = s.length(), plen = pattern.length();        int[] next = get_next(pattern);        while (i &lt; slen &amp;&amp; j &lt; plen) {            if (s.charAt(i) == pattern.charAt(j)) {                i++;                j++;            } else {                if (next[j] == -1) {                    i++;                    j = 0;                } else {                    j = next[j];                }            }            if (j == plen) {                return i - j;            }        }        return -1;    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>使用VMware安装linux虚拟机</title>
      <link href="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/"/>
      <url>/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=552192975&auto=0&height=66"></iframe></div><h1 id="使用VMware安装linux虚拟机"><a href="#使用VMware安装linux虚拟机" class="headerlink" title="使用VMware安装linux虚拟机"></a>使用VMware安装linux虚拟机</h1><h3 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h3><p><em>Linux是一种自由和开放源码的操作系统，存在着许多不同的Linux发行版本，但它们都使用了Linux内核。现在的服务器基本都是使用linux,其中CentOS使用广泛,还有ubuntu也是linux中的佼佼者.业内也说,凡是<strong>java开发,不懂linux均是扯淡.</strong>本文主要为后面搭建基于Hadoop集群的大数据大数据平台打下基础。</em></p><h4 id="linux具有如下优点"><a href="#linux具有如下优点" class="headerlink" title="linux具有如下优点"></a>linux具有如下优点</h4><ul><li>开源</li><li>多用户，多任务，丰富的网络功能，可靠的系统安全，良好的可移植性，具有标准兼容性</li><li>良好的用户界面，出色的速度性能</li><li>服务器不使用图形化界面(图形界面占用资源)</li><li>机房部署方便，无需配置操作界面</li></ul><p><strong>下载地址</strong><a href="http://www.centos.org/" target="_blank" rel="noopener">:http://www.centos.org/</a></p><h3 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h3><ul><li>Windows10</li><li>VMware Workstation12</li><li>CentOS7</li></ul><h4 id="VMware-Workstation12安装"><a href="#VMware-Workstation12安装" class="headerlink" title="VMware Workstation12安装"></a>VMware Workstation12安装</h4><p>①双击VMware-workstation-full-版本号.exe</p><p>②点击next</p><p>③选择Typical(你要是想自己配置也可以选custom 不推荐)</p><p>④选择安装目录</p><p>⑤想检查升级就勾上(check for product updates on startup),否则直接下一步</p><p>⑥选择创建快捷方式的位置,然后下一步</p><p>⑦点击continue完成</p><p>⑧Finish完成</p><p><strong>注意:如果你不熟悉就按部就班来,不要有什么骚操作,我记得我开始安装的时候禁用了哪两个网卡,后来哪两个网卡找不到了,我就把这个卸载了重新装,还是不行,这个问题的解决还是因为我一个月后重装了电脑</strong></p><h4 id="CentOS7安装"><a href="#CentOS7安装" class="headerlink" title="CentOS7安装"></a>CentOS7安装</h4><p>①安装VMware Workstation</p><p>②打开VM,点击创建新的虚拟机</p><p>③选择 典型（推荐）→ 下一步 </p><p>④选择稍后安装操作系统再点击下一步</p><p>⑤选择操作系统和版本(linux 64)</p><p>⑥输入虚拟机名称和安装路径</p><p>⑦设置磁盘大小并选中将虚拟磁盘拆成多个文件</p><p>⑧自定义硬件</p><p>⑨选择CentOS安装镜像文件</p><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577631145598.png" alt="1577631145598"></p><p>⑩开机启动后选择Install CentOS 7并enter</p><ul><li>弹出如下图形化的安装界面：</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat.png" alt="img"></p><ul><li>日期和时间：</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat1.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat2.png" alt="img"></p><ul><li>如果你安装的是英文版，需要将时区改为上海。</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat3.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat4.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126014938900.png" alt="img"></p><ul><li><strong>网络和主机名</strong></li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126015037602.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126015051216.png" alt="img"></p><ul><li>然后选择开始安装**</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat7.png" alt="img">基本的系统就安装好了</p><h3 id="配置网络"><a href="#配置网络" class="headerlink" title="配置网络"></a>配置网络</h3><ul><li>linu有三种网络模式,分别是Host-Only、NAT、桥接。一般安装好以后会默认选择NAT。</li></ul><ul><li>进入之后修改ip地址信息</li></ul><pre><code>vi /etc/ sysconfig/network-scripts/ifcfg-eth0DEVICE=eth0 #网卡名称HWADDR=08:00:27:8E:9D:25 #MAC地址TYPE=Ethernet #网络类型,这里是以太网UUID=5f2d815e-bd3b-4995-9009-823542e77304ONBOOT=yes NM_CONTROLLED=yesBOOTPROTO=staticSTATIC=trueIPADDR=192.168.1.21 #ip地址NETMASK=255.255.255.0 #子网掩码GATEWAY=192.168.1.1 #网管DNS1=202.202.0.33 #域名解析地址DNS2=114.114.114.114DNS3=8.8.8.8</code></pre><ul><li>配置好以后重启网络服务</li></ul><pre><code>services network restart</code></pre><ul><li>ifconfig查看IP地址</li></ul><pre><code>ifconfigeth0      Link encap:Ethernet  HWaddr 08:00:27:8E:9D:25            inet addr:192.168.1.21  Bcast:192.168.1.255  Mask:255.255.255.0          inet6 addr: fe80::a00:27ff:fe8e:9d25/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:1756623 errors:0 dropped:0 overruns:0 frame:0          TX packets:1952463 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000           RX bytes:1445482120 (1.3 GiB)  TX bytes:1626059931 (1.5 GiB)lo        Link encap:Local Loopback            inet addr:127.0.0.1  Mask:255.0.0.0          inet6 addr: ::1/128 Scope:Host          UP LOOPBACK RUNNING  MTU:65536  Metric:1          RX packets:2258 errors:0 dropped:0 overruns:0 frame:0          TX packets:2258 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0           RX bytes:590708 (576.8 KiB)  TX bytes:590708 (576.8 KiB)</code></pre><ul><li>ping ip地址测试网络是否配置好</li></ul><pre><code>ping www.baidu.com</code></pre><p><strong>按照以上操作完成安装以后可以直接克隆改虚拟机，然后修改配置就可以生成多台</strong></p><p><strong>在每个主机的/etc/hosts文件设置上每个主机的ip和名字的映射关系</strong></p><pre><code>vi /etc/hosts192.168.1.21 master192.168.1.23 slave1192.168.1.24 slave2192.168.1.25 slave3</code></pre><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577691474359.png" alt="1577691474359"></p><h4 id="配置免密登录"><a href="#配置免密登录" class="headerlink" title="配置免密登录"></a>配置免密登录</h4><ul><li>主要用于两个机器之间相互登录不需要验证</li></ul><p>①在第一台机器使用命令ssh-keygen -t rsa生成私钥和秘钥</p><pre><code>ssh-keygen -t rsa</code></pre><p>②复制到另一台机器</p><pre><code>ssh-copy-id root@slave1</code></pre><p><strong>如此就可以实现slave登录master免密,按照这个做法,每两台机器都配置上。</strong></p><h5 id="科普：免密登录原理"><a href="#科普：免密登录原理" class="headerlink" title="科普：免密登录原理"></a>科普：免密登录原理</h5><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577692561419.png" alt="1577692561419"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>hexo博文包含图片的坑</title>
      <link href="/2019/12/29/hexo-bo-wen-bao-han-tu-pian-de-keng/"/>
      <url>/2019/12/29/hexo-bo-wen-bao-han-tu-pian-de-keng/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=414414&auto=0&height=66"></iframe></div><h1 id="hexo博文包含图片的坑"><a href="#hexo博文包含图片的坑" class="headerlink" title="hexo博文包含图片的坑"></a>hexo博文包含图片的坑</h1><h3 id="网上有很多关于这个的教程-主要的总结如下"><a href="#网上有很多关于这个的教程-主要的总结如下" class="headerlink" title="网上有很多关于这个的教程,主要的总结如下"></a>网上有很多关于这个的教程,主要的总结如下</h3><ul><li>①修改博客目录下的_config_yml的post_asset_folder为true</li></ul><pre class="line-numbers language-java"><code class="language-java">post_asset_folder<span class="token operator">:</span> <span class="token boolean">true</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>②安装hexo-asset-image插件</li></ul><pre><code>npm install hexo-asset-image --save</code></pre><ul><li>③hexo new  file_name 时会在source/_post/下生成file_name的文件夹,将需要使用的图片放置在里面,然后使用相对路径引入</li></ul><pre><code>![用于图片加载失败时显示的内容](/file_name/image_name)</code></pre><ul><li>如此博客中的图片最后会和.md文件一起生成到public\2019\12\27\file_name中,这样在hexe g 时,可以看到命令窗口会打印修改后的路径,如下</li></ul><pre><code>Start processingupdate link as:--&gt;/2019/12/27/first/1577523021175.pngupdate link as:--&gt;/2019/12/27/first/1577523021175.png</code></pre><h3 id="我遇到的问题"><a href="#我遇到的问题" class="headerlink" title="我遇到的问题"></a>我遇到的问题</h3><pre><code>Start processingupdate link as:--&gt;.io//2019/12/27/first/1577523021175.pngupdate link as:--&gt;.io//2019/12/27/first/1577523021175.png</code></pre><ul><li>经过一番搜寻,发现hexo-asset-image会将图片的地址修改,具体的源码信息可见\node_modules\hexo-asset-image\index.js,打开后内容如下:</li></ul><pre><code>&#39;use strict&#39;;var cheerio = require(&#39;cheerio&#39;);function getPosition(str, m, i) {  return str.split(m, i).join(m).length;}hexo.extend.filter.register(&#39;after_post_render&#39;, function(data){  var config = hexo.config;  if(config.post_asset_folder){    var link = data.permalink;    var beginPos = getPosition(link, &#39;/&#39;, 3) + 1;    var appendLink = &#39;&#39;;    // In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;.    // if not with index.html endpos = link.lastIndexOf(&#39;.&#39;) + 1 support hexo-abbrlink    if(/.*\/index\.html$/.test(link)) {      // when permalink is end with index.html, for example 2019/02/20/xxtitle/index.html      // image in xxtitle/ will go to xxtitle/index/      appendLink = &#39;index/&#39;;      var endPos = link.lastIndexOf(&#39;/&#39;);    }    else {      var endPos = link.lastIndexOf(&#39;.&#39;) ;    }    link = link.substring(beginPos, endPos) + &#39;/&#39; + appendLink;    var toprocess = [&#39;excerpt&#39;, &#39;more&#39;, &#39;content&#39;];    for(var i = 0; i &lt; toprocess.length; i++){      var key = toprocess[i];      var $ = cheerio.load(data[key], {        ignoreWhitespace: false,        xmlMode: false,        lowerCaseTags: false,        decodeEntities: false      });      $(&#39;img&#39;).each(function(){        if ($(this).attr(&#39;src&#39;)){          // For windows style path, we replace &#39;\&#39; to &#39;/&#39;.          var src = $(this).attr(&#39;src&#39;).replace(&#39;\\&#39;, &#39;/&#39;);          if(!(/http[s]*.*|\/\/.*/.test(src)            || /^\s+\//.test(src)            || /^\s*\/uploads|images\//.test(src))) {            // For &quot;about&quot; page, the first part of &quot;src&quot; can&#39;t be removed.            // In addition, to support multi-level local directory.            var linkArray = link.split(&#39;/&#39;).filter(function(elem){              return elem != &#39;&#39;;            });            var srcArray = src.split(&#39;/&#39;).filter(function(elem){              return elem != &#39;&#39; &amp;&amp; elem != &#39;.&#39;;            });            if(srcArray.length &gt; 1)            srcArray.shift();            src = srcArray.join(&#39;/&#39;);            $(this).attr(&#39;src&#39;, config.root + link + src);            console.info&amp;&amp;console.info(&quot;update link as:--&gt;&quot;+config.root + link + src);          }        }else{          console.info&amp;&amp;console.info(&quot;no src attr, skipped...&quot;);          console.info&amp;&amp;console.info($(this));        }      });      data[key] = $.html();    }  }});</code></pre><ul><li>通过查看源码发现里面有对生成博客图片的地址修改:</li></ul><pre><code>link = link.substring(beginPos, endPos) + &#39;/&#39; + appendLink;</code></pre><ul><li>通过排查发现图片的路径的endPos为:</li></ul><pre><code>var endPos = link.lastIndexOf(&#39;.&#39;) ;</code></pre><ul><li>我打印data.permalink得到</li></ul><pre><code>http://tigerLuHai.github.io/2019/12/27/first/</code></pre><p>如此在截取字符串的时候就会多出四个字符  <strong>.io/</strong></p><p>最后发现这段代码的作用就是要将data.permalink中路径的<a href="https://tigerLuhai.gituhub.io/去掉,因为在后面部署到github时使用相对路径访问会重新加上这个前缀,如果这里有就会重复,导致地址为https://tigerLuhai.gituhub.io/http://tigerLuHai.github.io/2019/12/27/first/的现象" target="_blank" rel="noopener">https://tigerLuhai.gituhub.io/去掉,因为在后面部署到github时使用相对路径访问会重新加上这个前缀,如果这里有就会重复,导致地址为https://tigerLuhai.gituhub.io/http://tigerLuHai.github.io/2019/12/27/first/的现象</a>.</p><p>明白了需求就可以修改代码为</p><pre><code>var endPos = link.lastIndexOf(&#39;/&#39;) ;</code></pre><p>这样就可以正常部署了.</p>]]></content>
      
      
      <categories>
          
          <category> tool </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>FastDFS分布式文件系统安装使用教程</title>
      <link href="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/"/>
      <url>/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=479553545&auto=1&height=66"></iframe></div><h1 id="FastDFS分布式文件系统安装使用教程"><a href="#FastDFS分布式文件系统安装使用教程" class="headerlink" title="FastDFS分布式文件系统安装使用教程"></a>FastDFS分布式文件系统安装使用教程</h1><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><p>分布式文件系统用于<strong>海量</strong>文件存储及传输访问的瓶颈问题，对海量视频的管理、对<strong>海量</strong>图片的管理等,FastDFS与其他分布式文件系统相比的一个显著优点就是特别<strong>适合大量小文件(图片等)的存储,因为它在存储时没有对文件切片分割.</strong></p><h3 id="主流的分布式文件系统"><a href="#主流的分布式文件系统" class="headerlink" title="主流的分布式文件系统"></a>主流的分布式文件系统</h3><h4 id="①NFS"><a href="#①NFS" class="headerlink" title="①NFS"></a>①NFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523021175.png" alt="1577523021175"></p><h4 id="②GFS"><a href="#②GFS" class="headerlink" title="②GFS"></a>②GFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523108700.png" alt="1577523108700"></p><h4 id="③HDFS"><a href="#③HDFS" class="headerlink" title="③HDFS"></a>③HDFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523192987.png" alt="1577523192987"></p><h4 id="④FastDFS"><a href="#④FastDFS" class="headerlink" title="④FastDFS"></a>④FastDFS</h4><p>FastDFS是用c语言编写的一款开源的分布式文件系统，它是由淘宝资深架构师余庆编写并开源。FastDFS专为互联 网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很 容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。</p><p><strong>FastDFS架构包括 Tracker server和Storageserver。客户端请求Tracker server进行文件上传、下载，通过Tracker server调度最终由Storage server完成文件上传和下载。</strong> </p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="服务器环境"><a href="#服务器环境" class="headerlink" title="服务器环境"></a>服务器环境</h4><ul><li>CentOS6.9(CenttOS安装过程一致)</li></ul><ul><li>IP: 192.168.1.21,192.168.1.23,192.168.1.24,192.168.1.25</li></ul><h4 id="安装Linux基本环境"><a href="#安装Linux基本环境" class="headerlink" title="安装Linux基本环境"></a>安装Linux基本环境</h4><p>参见Hadoop的安装使用教程中Linux环境搭建</p><h4 id="安装gcc环境-FastDFS是由c语言编写"><a href="#安装gcc环境-FastDFS是由c语言编写" class="headerlink" title="安装gcc环境(FastDFS是由c语言编写)"></a>安装gcc环境(FastDFS是由c语言编写)</h4><pre class="line-numbers language-linux"><code class="language-linux">yum install gcc-c++<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="安装-libevent"><a href="#安装-libevent" class="headerlink" title="安装 libevent"></a>安装 libevent</h4><pre class="line-numbers language-yum"><code class="language-yum">yum -y install libevent<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="安装-libfastcommon"><a href="#安装-libfastcommon" class="headerlink" title="安装 libfastcommon"></a>安装 libfastcommon</h4><pre><code>将 libfastcommonV1.0.7.tar.gz 拷贝至/usr/local/下cd /usr/localtar -zxvf libfastcommonV1.0.7.tar.gzcd libfastcommon-1.0.7./make.sh./make.sh install</code></pre><p>注意：<strong>libfastcommon 安装好后会自动将库文件拷贝至/usr/lib64 下，由于 FastDFS 程序引用 usr/lib 目录所以需要将/usr/lib64 下的库文件拷贝至/usr/lib 下。</strong></p><p>需要拷贝的文件</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577524769079.png" alt="1577524769079"></p><h4 id="tracker-编译安装"><a href="#tracker-编译安装" class="headerlink" title="tracker 编译安装"></a>tracker 编译安装</h4><pre class="line-numbers language-将"><code class="language-将">将 FastDFS_v5.05.tar.gz 拷贝至/usr/local/下tar -zxvf FastDFS_v5.05.tar.gzcd FastDFS./make.sh 编译./make.sh install 安装<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>安装成功将安装目录下的 conf 下的文件拷贝到/etc/fdfs/下。</p><pre><code>cp -r /usr/local/FastDFS/conf/ /etc/fdfs/</code></pre><h5 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h5><p>安装成功后进入/etc/fdfs目录</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577525471795.png" alt="1577525471795"></p><p>拷贝一份新的 tracker 配置文件：</p><pre><code>cp tracker.conf.sample tracker.conf</code></pre><p>修改 tracker.conf</p><pre><code>vi tracker.confbase_path=/home/yuqing/FastDFS #数据(日志等)存储路径,自己设置http.server_port=80 #配置 http 端口：</code></pre><h5 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h5><pre><code>/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</code></pre><p>查看端口</p><pre><code>netstat -nltp</code></pre><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577535905825.png" alt="1577535905825"></p><h4 id="storage-安装"><a href="#storage-安装" class="headerlink" title="storage 安装"></a>storage 安装</h4><ul><li>安装 libevent</li><li>安装 libfastcommon</li><li>编译安装(与tracker相同)</li></ul><h5 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h5><pre><code>vi storage.confgroup_name=group1 #分组,同一分组为设置冗余防止宕机不可用base_path=/home/yuqing/FastDFS #数据存储路径,自己设置store_path0=/home/yuqing/FastDFS #文件存储路径,自己设置tracker_server=192.168.101.3:22122 #配置 tracker 服务器:IPtracker_server=192.168.1.21:22122 #如果有多个则配置多个 trackerhttp.server_port=80</code></pre><h5 id="启动-1"><a href="#启动-1" class="headerlink" title="启动"></a>启动</h5><pre><code>/usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</code></pre><h5 id="分发配置"><a href="#分发配置" class="headerlink" title="分发配置"></a>分发配置</h5><p>将FastDFS分发到各个节点,并修改配置,分发脚本如下</p><pre><code>#!/bin/bashpcount=$#if((pcount=0));thenecho no args;exit;fip1=$1fname=`basename $p1`echo fname=$fnamepdir=`cd -P $(dirname $p1);pwd`echo pdir=$pdiruser=`whoami`echo user=$userfor((host=1;host&lt;4;host++));doecho ------------salve$host-------------rsync -rvl $pdir/$fname $user@slave$host:$pdirdone</code></pre><h3 id="利用可通过-usr-bin-fdfs-test-程序测试"><a href="#利用可通过-usr-bin-fdfs-test-程序测试" class="headerlink" title="利用可通过/usr/bin/fdfs_test 程序测试"></a>利用可通过/usr/bin/fdfs_test 程序测试</h3><p>修改/etc/fdfs/client.conf</p><p>tracker_server 根据自己部署虚拟机的情况配置</p><pre><code>base_path = /home/yuqing/fastdfstracker-server=192.168.1.21:22122</code></pre><p>使用格式：</p><pre><code>/usr/bin/fdfs_test 客户端配置文件地址 upload 上传文件</code></pre><p>比如将/home 下的图片上传到 FastDFS 中：</p><pre><code>/usr/bin/fdfs_test /etc/fdfs/client.conf upload /home/tomcat.png</code></pre><p>打印日志如下:</p><pre><code>This is FastDFS client test program v5.05Copyright (C) 2008, Happy Fish / YuQingFastDFS may be copied only under the terms of the GNU GeneralPublic License V3, which may be found in the FastDFS source kit.Please visit the FastDFS Home Page http://www.csource.org/ for more detail.[2019-12-28 20:13:02] DEBUG - base_path=/home/fastdfs, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0tracker_query_storage_store_list_without_group:         server 1. group_name=, ip_addr=192.168.1.24, port=23000group_name=group1, ip_addr=192.168.1.24, port=23000storage_upload_by_filenamegroup_name=group1, remote_filename=M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.pngsource ip address: 192.168.1.24file timestamp=2019-12-28 20:13:02file size=138735file crc32=2977689730example file url: http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.pngstorage_upload_slave_by_filenamegroup_name=group1, remote_filename=M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587_big.pngsource ip address: 192.168.1.24file timestamp=2019-12-28 20:13:02file size=138735file crc32=2977689730</code></pre><p><a href="http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png" target="_blank" rel="noopener">http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png</a><br>就是文件的下载路径。对应服务器的base_path/fdfs_storage/data/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png文件</p><p>现在还没有和 nginx 整合无法使用 http 下载。</p><h3 id="Nginx整合FastDFS"><a href="#Nginx整合FastDFS" class="headerlink" title="Nginx整合FastDFS"></a>Nginx整合FastDFS</h3><h4 id="FastDFS-nginx-module"><a href="#FastDFS-nginx-module" class="headerlink" title="FastDFS-nginx-module"></a>FastDFS-nginx-module</h4><p>将 FastDFS-nginx-module_v1.16.tar.gz 传 至 fastDFS 的 storage 服 务 器 的</p><p>/usr/local/下，执行如下命令：</p><pre><code>cd /usr/localtar -zxvf FastDFS-nginx-module_v1.16.tar.gzcd FastDFS-nginx-module/srcvi config</code></pre><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577536510714.png" alt="1577536510714"></p><p>将/usr/local修改为/usr，注意这里有三场，不要改漏了。</p><p>将 FastDFS-nginx-module/src 下的 mod_FastDFS.conf 拷贝至/etc/fdfs/下</p><pre><code>cp mod_FastDFS.conf /etc/fdfs/vi /etc/fdfs/mod_FastDFS.confbase_path=/home/FastDFS # 保持和之前安装时一致tracker_server=192.168.1.21:22122url_have_group_name=true #url 中包含 group 名称store_path0=/home/fastdfs/fdfs_storage #指定文件存储路径,和之前一致</code></pre><p>将 libfdfsclient.so 拷贝至/usr/lib 下</p><pre><code>cp /usr/lib64/libfdfsclient.so /usr/lib/</code></pre><p>创建 nginx/client 目录</p><pre><code>mkdir -p /var/temp/nginx/client</code></pre><h4 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h4><p>详细教程可见nginx使用感悟</p><p>将 nginx-1.8.0.tar.gz 拷贝到/usr/local 下</p><p>解压 nginx-1.8.0.tar.gz</p><p>进入 nginx-1.8.0 目录，执行如下配置命令：</p><pre><code>./configure --add-module=/usr/local/FastDFS-nginx-module/srcmake make install</code></pre><p>在nginx中增加如下虚拟机配置:</p><p>storage配置:</p><pre><code>server { listen 80; server_name 192.168.1.23; 本机ip location /group1/M00/{ root /home/FastDFS/fdfs_storage/data;  #以自己配置的地址为准 ngx_FastDFS_module; } }</code></pre><p>tracker配置:</p><pre><code>#storage 群 group1 组upstream storage_server_group1{ server 192.168.1.23:80 weight=10;server 192.168.1.24:80 weight=10; } #storage 群 group2 组upstream storage_server_group2{ server 192.168.1.25:80 weight=10; } server {listen 80;server_name ccc.test.com;location /group1{proxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://storage_server_group1;}location /group2{proxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://storage_server_group2; } }</code></pre><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>使用浏览器 http 访问文件，这里访问上传图片测试的文件：</p><p>访问 storage：<a href="http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png" target="_blank" rel="noopener">http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png</a></p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577537632508.png" alt="1577537632508"></p><p>ip 地址改为 192.168.1.24也可以访问到文件，因为同一个分组的 storage 文件互相同步。</p><h3 id="编写java代码上传下载文件"><a href="#编写java代码上传下载文件" class="headerlink" title="编写java代码上传下载文件"></a>编写java代码上传下载文件</h3><p><strong>SpringBoot测试方案</strong></p><p>引入依赖</p><pre><code>        &lt;dependency&gt;            &lt;groupId&gt;net.oschina.zcx7878&lt;/groupId&gt;            &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt;            &lt;version&gt;1.27.0.0&lt;/version&gt;        &lt;/dependency&gt;</code></pre><pre><code>@SpringBootTest@RunWith(SpringRunner.class)public class TestFastDFS {    @Test    public void upload() throws IOException, MyException {        //加载fastdfs-client.properties配置文件        ClientGlobal.initByProperties(&quot;config/fastdfs-client.properties&quot;);        //定义TrackerClient,用于请求TrackerClient        TrackerClient trackerClient = new TrackerClient();        //创建TrackerServer        TrackerServer trackerServer = trackerClient.getConnection();        //通过TrackerServer获取storeServer        StorageServer storeServer = trackerClient.getStoreStorage(trackerServer);        //通过TrackerServer and storeServer 创建storageClient1        StorageClient1 storageClient1 = new StorageClient1(trackerServer, storeServer);        //fileId group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log        String fileId = storageClient1.upload_file1(&quot;C:\\Users\\tiger\\Pictures\\Feedback\\{A687785D-19C3-4B2E-A00A-2667141271EB}\\Capture001.png&quot;, &quot;.png&quot;, null);        System.out.println(fileId);        //获取tracker客户端    }    @Test    public void download() throws IOException, MyException {        //加载fastdfs-client.properties配置文件        ClientGlobal.initByProperties(&quot;config/fastdfs-client.properties&quot;);        //定义TrackerClient,用于请求TrackerClient        TrackerClient trackerClient = new TrackerClient();        //创建TrackerServer        TrackerServer trackerServer = trackerClient.getConnection();        //通过TrackerServer获取storeServer        StorageServer storeServer = trackerClient.getStoreStorage(trackerServer);        //通过TrackerServer and storeServer 创建storageClient1        StorageClient1 storageClient1 = new StorageClient1(trackerServer, storeServer);        //fileId group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log        byte[] bytes = storageClient1.download_file1(&quot;group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log&quot;);        FileOutputStream fos = new FileOutputStream(new File(&quot;hello&quot;));        fos.write(bytes);    }}</code></pre><p>config/fastdfs-client.properties</p><pre><code>fastdfs.connect_timeout_in_seconds = 5fastdfs.network_timeout_in_seconds = 30fastdfs.charset = UTF-8fastdfs.tracker_servers = 192.168.1.21:22122</code></pre><p>运行upload得到路径</p><pre><code>group1/M00/00/00/wKgBGF4HUZiAOKLgAB7xNcvo_Vw00..png根据自己配置的路径可以得到访问的http协议路径为:http://192.168.1.21/group1/M00/00/00/wKgBGF4HUZiAOKLgAB7xNcvo_Vw00..png</code></pre><p>效果如下</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577538377340.png" alt="1577538377340"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>FastDFS相对于HDFS等分布式文件的优势在于它不切分文件,所以下载文件的时候没有拼装文件的过程,而且可以锁定一台机器进行网络I/O,所以速度很快.不过正所谓这也是它的缺点,这导致它不能用于存储大文件.所以FastDFS适合存储大量图片小视频之类的文件.</strong></p><h3 id="安装过程遇到的一些问题"><a href="#安装过程遇到的一些问题" class="headerlink" title="安装过程遇到的一些问题"></a>安装过程遇到的一些问题</h3><p>①安装nginx No rule to make target “/usr/local/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c”, needed by objs/addon/src/ngx_http_fastdfs_module.o . Stop. 修改fastdfs-nginx-module/src/config文件中的路径,删除local(注意一共有三个)</p><p>②nginx安装cp: <code>conf/koi-win&#39; and</code>/usr/local/nginx/conf/koi-win’ are the same file 解决 将./configure –prefix=/usr/local/nginx 改为 ./configure –prefix=/usr/local/nginx –conf-path=/usr/local/nginx/nginx.conf</p><p>③nginx编码严格.直接复制会出现nginx: [emerg] unknown directive “ “ in /usr/local/nginx-1.12.0-storage/conf/nginx.conf:49）：所以需要手动输入nginx.conf</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>first</title>
      <link href="/2019/12/27/first/"/>
      <url>/2019/12/27/first/</url>
      
        <content type="html"><![CDATA[<p><img src="/2019/12/27/first/1577523021175.png" alt="1577523021175"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop集群搭建与简单使用</title>
      <link href="/2019/12/01/hadoop-ji-qun-da-jian-yu-jian-dan-shi-yong/"/>
      <url>/2019/12/01/hadoop-ji-qun-da-jian-yu-jian-dan-shi-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop集群搭建与简单使用"><a href="#Hadoop集群搭建与简单使用" class="headerlink" title="Hadoop集群搭建与简单使用"></a>Hadoop集群搭建与简单使用</h1><p>首先需要搭建一个linux的集群,可以参见我的博客<a href="https://tigerluhai.github.io/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/">linux集群搭建</a></p><blockquote><p>Hadoop的运行是基于java的,所以需要先安装JDK,而且JDK版本必须高于1.7</p></blockquote><h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><p>（1）查询是否安装Java软件：</p><pre><code> rpm -qa | grep java</code></pre><p>（2）如果安装的版本低于1.7，卸载该JDK：</p><pre><code>sudo rpm -e 软件包</code></pre><p>（3）查看JDK安装路径：</p><pre><code> which(or whereis) java</code></pre><p>（4）解压JDK：</p><pre><code>tar -zxvf 安装包名 -C 目标路径</code></pre><p>（5）配置JDK环境：</p><pre><code>vi /etc/profile在文件末尾加上#JAVA_HOMEexport JAVA_HOME=/opt/module/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/bin</code></pre><p><strong>修改后需要立即生效需要运行如下命令:</strong></p><pre><code>source /etc/profile</code></pre><p>（6）测试JDK安装是否成功：</p><pre><code>java -version</code></pre><h3 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h3><p>（1）解压hadoop安装包到指定位置</p><pre><code>tar -zxvf 安装包 -C 指定目录</code></pre><p>（2）添加环境变量</p><pre><code>vi /etc/profile在文件末尾加上#HADOOP_HOMEexport HADOOP_HOME=/opt/module/hadoop-3.1.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin</code></pre><p>(3)修改配置文件</p><ul><li>集群部署规划</li></ul><table><thead><tr><th></th><th>master</th><th>slave1</th><th>slave2</th><th>slave3</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNodeDataNode</td><td>SecondaryNameNode DataNode</td><td>DataNode</td><td>DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager</td><td>NodeManager</td><td>NodeManager</td></tr></tbody></table><ul><li>核心配置文件</li></ul><p>配置core-site.xml</p><pre><code>vi core-site.xml# 在该文件中编写如下配置&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;&lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/opt/module/hadoop-3.1.2/data/tmp&lt;/value&gt;&lt;/property&gt;</code></pre><ul><li>HDFS配置文件</li></ul><p>配置hadoop-env.sh</p><pre><code> vi hadoop-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>配置hdfs-site.xml</p><pre><code>vi hdfs-site.xml&lt;!--配置副本数量--&gt;&lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;3&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;&lt;property&gt;      &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;      &lt;value&gt;slave1:50090&lt;/value&gt;&lt;/property&gt;</code></pre><p>注意:文件副本数量不只是dfs.replication决定,而是min(datanode节点数,dfs.replication)</p><ul><li>YARN配置文件</li></ul><p>配置yarn-env.sh</p><pre><code> vi yarn-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><ul><li>配置yarn-site.xml</li></ul><pre><code> vi yarn-site.xml&lt;!-- Reducer获取数据的方式 --&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定YARN的ResourceManager的地址 --&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;    &lt;value&gt;slave2&lt;/value&gt;&lt;/property&gt;</code></pre><ul><li>MapReduce配置文件</li></ul><pre><code>vi mapred-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p><strong>注意：hadoop3之前的版本,mapreduce会继承hadoop的配置,所以可以不用配置这一项,但是3以后的版本必须配置,否则运行mapreduce时会报环境出错。</strong></p><ul><li>配置mapred-site.xml</li></ul><pre><code>cp mapred-site.xml.template mapred-site.xmlvi mapred-site.xml&lt;!-- 指定MR运行在Yarn上 --&gt;&lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;</code></pre><p>（4）在集群上分发配置好的Hadoop配置文件</p><p>编写分发脚本</p><pre><code>vi /usr/local/bin/xsync#!/bin/bashpcount=$#if((pcount=0));thenecho no args;exit;fip1=$1fname=`basename $p1`echo fname=$fnamepdir=`cd -P $(dirname $p1);pwd`echo pdir=$pdiruser=`whoami`echo user=$userfor((host=1;host&lt;4;host++));doecho ------------salve$host-------------rsync -rvl $pdir/$fname $user@slave$host:$pdirdone</code></pre><pre><code>xsync /opt/module/hadoop-3.1.2/</code></pre><h3 id="集群单节点启动"><a href="#集群单节点启动" class="headerlink" title="集群单节点启动"></a>集群单节点启动</h3><p>（1）如果集群是第一次启动，需要<strong>格式化NameNode</strong></p><pre><code>hadoop namenode -format</code></pre><p>（2）在master上启动NameNode</p><pre><code>hadoop-daemon.sh start namenode</code></pre><p>查看节点启动状态</p><pre><code> jps</code></pre><p><strong>注意:jps用于查看java进程,namenode和datanode都是java进程</strong></p><p>（3）在master,slave1,slave2以及slave3上分别启动DataNode</p><pre><code>hadoop-daemon.sh start datanode</code></pre><pre><code> jps3461 NameNode3608 Jps3561 DataNode</code></pre><p>思考：每次都一个一个节点启动，如果节点数太多怎么办？</p><h3 id="群起集群"><a href="#群起集群" class="headerlink" title="群起集群"></a>群起集群</h3><ol><li>配置slaves</li></ol><pre><code>vi /opt/module/hadoop-3.1.2/etc/hadoop/slaves在该文件中增加如下内容：masterslave1slave2slave3</code></pre><p><strong>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</strong></p><p>同步所有节点配置文件</p><pre><code> xsync slaves</code></pre><ol start="2"><li>启动集群</li></ol><p>（1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）</p><pre><code>hdfs namenode -format</code></pre><p>（2）启动HDFS</p><pre><code>start-dfs.sh</code></pre><p>（3）启动YARN</p><pre><code>start-yarn.sh</code></pre><p><strong>注意：NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。</strong></p><h3 id="集群基本操作"><a href="#集群基本操作" class="headerlink" title="集群基本操作"></a>集群基本操作</h3><ul><li>-ls: 显示目录信息</li></ul><pre><code>hadoop fs -ls /</code></pre><ul><li>mkdir：在HDFS上创建目录</li></ul><pre><code> hadoop fs -mkdir -p /parent/test</code></pre><ul><li>moveFromLocal：从本地剪切粘贴到HDFS</li></ul><pre><code>hadoop fs  -moveFromLocal  ./kongming.txt  /parent/test</code></pre><ul><li>appendToFile：追加一个文件到已经存在的文件末尾</li></ul><pre><code> hadoop fs -appendToFile liubei.txt /parent/test/kongming.txt</code></pre><ul><li>cat：显示文件内容</li></ul><pre><code>hadoop fs -cat /parent/test/kongming.txt</code></pre><ul><li>chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</li><li>copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</li></ul><pre><code> hadoop fs -copyFromLocal README.txt /</code></pre><ul><li>copyToLocal：从HDFS拷贝到本地</li></ul><pre><code> hadoop fs -copyToLocal /parent/test/kongming.txt ./</code></pre><ul><li>cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</li></ul><pre><code>hadoop fs -cp /parent/test/kongming.txt  /zhuge.txt</code></pre><ul><li>mv：在HDFS目录中移动文件</li></ul><pre><code>hadoop fs -mv /zhuge.txt /parent/test/</code></pre><ul><li>get：等同于copyToLocal，就是从HDFS下载文件到本地</li></ul><pre><code>hadoop fs -get /parent/test/kongming.txt ./</code></pre><ul><li>getmerge：合并下载多个文件，比如HDFS的目录 /parent/test//test下有多个文件:log.1, log.2,log.3,…</li></ul><pre><code>hadoop fs -getmerge /parent/test/test/* ./zaiyiqi.txt</code></pre><ul><li>put：等同于copyFromLocal</li></ul><pre><code> hadoop fs -put ./zaiyiqi.txt /</code></pre><ul><li>tail：显示一个文件的末尾</li></ul><ul><li>rm：删除文件或文件夹</li></ul><ul><li>rmdir：删除空目录</li></ul><ul><li>du统计文件夹的大小信息</li></ul><h3 id="JAVA代码操作HDFS"><a href="#JAVA代码操作HDFS" class="headerlink" title="JAVA代码操作HDFS"></a>JAVA代码操作HDFS</h3><pre><code>    Logger logger = LoggerFactory.getLogger(HdfsClient.class);    FileSystem fileSystem;    Configuration configuration;    @Test    /**     * 测试环境正常     */    public void HDFS_ENV() throws IOException {        Logger logger = LoggerFactory.getLogger(HdfsClient.class);        //1.获取hdfs客户端对象        Configuration configuration = new Configuration();        configuration.set(&quot;fs.defaultFS&quot;,&quot;hdfs://master:9000&quot;);        FileSystem fileSystem = FileSystem.get(configuration);        //2.在hdfs上执行相关操作        boolean mkdirs = fileSystem.mkdirs(new Path(&quot;/client_test_environment&quot;));        //3.关闭资源        fileSystem.close();        System.out.println(mkdirs);    }    @Before    /**     * 创建fileSystem对象     */    public void createFileSystem() throws URISyntaxException, IOException, InterruptedException {        //1.获取fs对象        configuration = new Configuration();        fileSystem = FileSystem.get(new URI(&quot;hdfs://master:9000&quot;), configuration, &quot;root&quot;);    }    @Test    public void copyFromLocalFile() throws IOException{        //执行上传操作        fileSystem.copyFromLocalFile(new Path(&quot;D:\\logs\\xc.2019-04-29.log&quot;),new Path(&quot;/client_test_environment/&quot;));        //关闭资源        fileSystem.close();    }    @Test    public void copyToLocalFile() throws IOException{        //执行上传操作        fileSystem.copyToLocalFile(true,new Path(&quot;/client_test_environment/xc.2019-04-29.log&quot;),new Path(&quot;D:\\logs\\xc.2019-04-29-back.log&quot;),false);        //关闭资源        fileSystem.close();    }    @Test    public void listFiles() throws IOException {        //查看文件信息        RemoteIterator&lt;LocatedFileStatus&gt; iterator = fileSystem.listFiles(new Path(&quot;/&quot;), true);        while (iterator.hasNext()){            LocatedFileStatus fileStatus = iterator.next();            //获取文件名称，文件权限，文件长度，块信息            logger.info(fileStatus.getPath().getName());            logger.info(fileStatus.getLen()+&quot;&quot;);            logger.info(fileStatus.getPermission()+&quot;&quot;);            BlockLocation[] blockLocations = fileStatus.getBlockLocations();            for (BlockLocation blockLocation : blockLocations) {                logger.info(blockLocation.toString());            }            logger.info(&quot;----------------                    ----------------------&quot;);        }    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
