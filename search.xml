<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>javaWeb三大核心组件之servlet</title>
      <link href="/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/"/>
      <url>/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/</url>
      
        <content type="html"><![CDATA[<h1 id="javaWeb三大核心组件之Servlet"><a href="#javaWeb三大核心组件之Servlet" class="headerlink" title="javaWeb三大核心组件之Servlet"></a>javaWeb三大核心组件之Servlet</h1><h3 id="什么是Servlet"><a href="#什么是Servlet" class="headerlink" title="什么是Servlet"></a>什么是Servlet</h3><p>Java Servlet 是运行在 Web 服务器或应用服务器上的程序，它是作为来自 Web 浏览器或其他 HTTP 客户端的请求和 HTTP 服务器上的数据库或应用程序之间的中间层。</p><p>使用 Servlet，您可以收集来自网页表单的用户输入，呈现来自数据库或者其他源的记录，还可以动态创建网页。</p><p>Java Servlet 通常情况下与使用 CGI（Common Gateway Interface，公共网关接口）实现的程序可以达到异曲同工的效果。但是相比于 CGI，Servlet 有以下几点优势：</p><p>性能明显更好。</p><p>Servlet 在 Web 服务器的地址空间内执行。这样它就没有必要再创建一个单独的进程来处理每个客户端请求。</p><p>Servlet 是独立于平台的，因为它们是用 Java 编写的。</p><p>服务器上的 Java 安全管理器执行了一系列限制，以保护服务器计算机上的资源。因此，Servlet 是可信的。</p><p>Java 类库的全部功能对 Servlet 来说都是可用的。它可以通过 sockets 和 RMI 机制与 applets、数据库或其他软件进行交互。</p><h3 id="Tomcat与Servlet的关系"><a href="#Tomcat与Servlet的关系" class="headerlink" title="Tomcat与Servlet的关系"></a>Tomcat与Servlet的关系</h3><p>Tomcat 是Web应用服务器,是一个Servlet/JSP容器. Tomcat 作为Servlet容器,负责处理客户请求,把请求传送给Servlet,并将Servlet的响应传送回给客户.而Servlet是一种运行在支持Java语言的服务器上的组件.。</p><p>Servlet最常见的用途是扩展Java Web服务器功能,提供非常安全的,可移植的,易于使用的CGI替代品。从http协议中的请求和响应可以得知，浏览器发出的请求是一个请求文本，而浏览器接收到的也应该是一个响应文本。</p><p><img src="/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/D:%5CMyBlot%5Cbolt%5Csource_posts%5CjavaWeb%E4%B8%89%E5%A4%A7%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E4%B9%8Bservlet%5C1" alt="image"></p><ol><li>Tomcat将http请求文本接收并解析，然后封装成HttpServletRequest类型的request对象，所有的HTTP头数据读可以通过request对象调用对应的方法查询到。</li><li>Tomcat同时会要响应的信息封装为HttpServletResponse类型的response对象，通过设置response属性就可以控制要输出到浏览器的内容，然后将response交给tomcat，tomcat就会将其变成响应文本的格式发送给浏览器。</li></ol><p>Java Servlet API 是Servlet容器(tomcat)和servlet之间的接口，它定义了serlvet的各种方法，还定义了Servlet容器传送给Servlet的对象类，其中最重要的就是ServletRequest和ServletResponse。所以说我们在编写servlet时，需要实现Servlet接口，按照其规范进行操作。</p><h3 id="Servlet执行过程"><a href="#Servlet执行过程" class="headerlink" title="Servlet执行过程"></a>Servlet执行过程</h3><p> 在浏览器的地址栏输入：<a href="http://ip" target="_blank" rel="noopener">http://ip</a>:port/appNames/servlet</p><p>  1）通过浏览器和ip：port和这个服务器建立连接。<br>  2） 浏览器会生成一个请求数据包（路径appNames/servlet）向服务器发送请求。<br>  3） 服务器收到请求数据包，分析请求资源路径做精准定位，通过请求的appName查找webapps文件下面的appName做匹配，匹配上了需要获取web.xml中的servlet(mapping)。 <br>  4） 服务器创建两个对象：<br>    第一个对象：请求对象，该对象实现了HttpServletRequest接口，服务器会将请求数据包中的数据解析出来,存储在该对象里。这样做的好处是没有必要理解http协议，只需要读取request。<br>    第二个对象：响应对象，实现了HttpServletResponse接口，作用是servlet处理完成后的结果可以存放到该对象上，然后服务器依据该对象的数据生成响应数据包。<br>  5） servlet在执行servlet()方法时，可以通过request获取请求数据，也可以将处理结果存放到response上。然后服务器与响应对象直接形成一个默契，生成一个响应数据包给浏览器。<br>  6）浏览器解析服务器返回的响应数据包，生成响应的结果。</p><p>  </p><p><img src="/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/D:%5CMyBlot%5Cbolt%5Csource_posts%5CjavaWeb%E4%B8%89%E5%A4%A7%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E4%B9%8Bservlet%5C2.png" alt="image"></p><p>Servlet访问的过程：<br>Http请求—-&gt;web.xml——–&gt;  url -pattern—–&gt;servlet-name—–&gt;servlet-class—–&gt;   QuickStratServlet(对应的Class文件)</p><h3 id="Servlet生命周期"><a href="#Servlet生命周期" class="headerlink" title="Servlet生命周期"></a>Servlet生命周期</h3><p>SpringMVC是基于servlet，控制器基于方法级别的拦截，处理器设计为单实例，所以应该了解一下Servlet的生命周期。</p><p>Servlet 加载—&gt;实例化—&gt;服务—&gt;销毁。</p><p><strong>init</strong>（）：</p><p>在Servlet的生命周期中，仅执行一次init()方法。它是在服务器装入Servlet时执行的，负责初始化Servlet对象。可以配置服务器，以在启动服务器或客户机首次访问Servlet时装入Servlet。无论有多少客户机访问Servlet，都不会重复执行init（）。</p><p><strong>service</strong>（）：</p><p>它是Servlet的核心，负责响应客户的请求。每当一个客户请求一个HttpServlet对象，该对象的Service()方法就要调用，而且传递给这个方法一个“请求”（ServletRequest）对象和一个“响应”（ServletResponse）对象作为参数。在HttpServlet中已存在Service()方法。默认的服务功能是调用与HTTP请求的方法相应的do功能。</p><p><strong>destroy</strong>（）：</p><p>仅执行一次，在服务器端停止且卸载Servlet时执行该方法。当Servlet对象退出生命周期时，负责释放占用的资源。一个Servlet在运行service()方法时可能会产生其他的线程，因此需要确认在调用destroy()方法时，这些线程已经终止或完成。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>SpringMVC原理</title>
      <link href="/2020/01/04/springmvc-yuan-li/"/>
      <url>/2020/01/04/springmvc-yuan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><a href="http://lib.csdn.net/base/javaee" target="_blank" rel="noopener">spring</a> MVC主要由DispatcherServlet、处理器映射、处理器(控制器)、视图解析器、视图组成。他的两个核心是两个核心：</p><p><strong>处理器映射：</strong> 选择使用哪个控制器来处理请求。<br><strong>视图解析器：</strong> 选择结果应该如何渲染。</p><h2 id="运行原理"><a href="#运行原理" class="headerlink" title="运行原理"></a>运行原理</h2><p>下图是在Spring官网开发手册上找到的，它清晰的诠释了Spring MVC的运行原理</p><p><img src="/2020/01/04/springmvc-yuan-li/D:%5CMyBlot%5Cbolt%5Csource_posts%5CSpringMVC%E5%8E%9F%E7%90%86%5C16b5eb3870589ac4.png" alt="16b5eb3870589ac4"></p><p>①客户端的所有请求都交给前端控制器DispatcherServlet来处理，它会负责调用系统的其他模块来真正处理用户的请求。</p><p>② DispatcherServlet收到请求后，将根据请求的信息（包括URL、HTTP协议方法、请求头、请求参数、Cookie等）以及HandlerMapping的配置找到处理该请求的Handler（任何一个对象都可以作为请求的Handler）。</p><p>③在这个地方Spring会通过HandlerAdapter对该处理器进行封装。</p><p>④ HandlerAdapter是一个适配器，它用统一的接口对各种Handler中的方法进行调用。</p><p>⑤ Handler完成对用户请求的处理后，会返回一个ModelAndView对象给DispatcherServlet，ModelAndView顾名思义，包含了数据模型以及相应的视图的信息。</p><p>⑥ ModelAndView的视图是逻辑视图，DispatcherServlet还要借助ViewResolver完成从逻辑视图到真实视图对象的解析工作。⑦ 当得到真正的视图对象后，DispatcherServlet会利用视图对象对模型数据进行渲染。</p><p>⑧ 客户端得到响应，可能是一个普通的HTML页面，也可以是XML或JSON字符串，还可以是一张图片或者一个PDF文件。</p><p><img src="/2020/01/04/springmvc-yuan-li/D:%5CMyBlot%5Cbolt%5Csource_posts%5CSpringMVC%E5%8E%9F%E7%90%86%5C16b5eb3870589ac4.png" alt="16b5eb3870589ac4"></p><h2 id="接口的解释"><a href="#接口的解释" class="headerlink" title="接口的解释"></a>接口的解释</h2><table><thead><tr><th>接口名称</th><th>功能</th></tr></thead><tbody><tr><td>DispatcherServlet</td><td>Spring提供的前端控制器，客户端的所有请求都由DispatcherServlet负责分发，当然在DispatcherServlet分发之前，还需要一个匹配请求的过程，这个由HandlerMapping来完成。</td></tr><tr><td>HandlerMapping</td><td>完成客户端请求到Controller映射的工作</td></tr><tr><td>Controller</td><td>用于处理用户请求，返回处理结果</td></tr><tr><td>ViewResolver</td><td>Web应用中查找View对象，从而将相应结果渲染给客户端</td></tr></tbody></table><h2 id="DispatcherServlet："><a href="#DispatcherServlet：" class="headerlink" title="DispatcherServlet："></a>DispatcherServlet：</h2><p>是整个Spring MVC的核心。它负责接收HTTP请求组织协调Spring MVC的各个组成部分。</p><p>其主要工作有以下三项：</p><ol><li>截获符合特定格式的URL请求。</li><li>初始化DispatcherServlet上下文对应WebApplicationContext，并将其与业务层、持久化层的WebApplicationContext建立关联。</li><li>初始化Spring MVC的各个组成组件，并装配到DispatcherServlet中。</li></ol><h2 id="一个比较好理解的Spring-mvc原理图"><a href="#一个比较好理解的Spring-mvc原理图" class="headerlink" title="一个比较好理解的Spring mvc原理图"></a>一个比较好理解的Spring mvc原理图</h2><p><img src="/2020/01/04/springmvc-yuan-li/D:%5CMyBlot%5Cbolt%5Csource_posts%5CSpringMVC%E5%8E%9F%E7%90%86%5Cb856096cf065baaaabe5884deb4ecfa3.png" alt="b856096cf065baaaabe5884deb4ecfa3"></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>回头再看spring</title>
      <link href="/2020/01/04/hui-tou-zai-kan-spring/"/>
      <url>/2020/01/04/hui-tou-zai-kan-spring/</url>
      
        <content type="html"><![CDATA[<h2 id="回头再看Spring"><a href="#回头再看Spring" class="headerlink" title="回头再看Spring"></a>回头再看Spring</h2><h3 id="什么是Spring"><a href="#什么是Spring" class="headerlink" title="什么是Spring"></a>什么是Spring</h3><p>Spring是个包含一系列功能的合集，如快速构建微服务的Spring Boot，管理一系列微服务的Spring Cloud，支持认证与鉴权的Spring Security，基于MVC的Web框架Spring MVC。但IOC与AOP依然是核心。</p><h3 id="Spring-Bean"><a href="#Spring-Bean" class="headerlink" title="Spring Bean"></a>Spring Bean</h3><p><strong>IOC的底层原理：文档解析xml文件，反射动态创建对象，然后保存name和Object，然后对每个对象属性进行属性注入</strong></p><h5 id="加载Bean的主要逻辑"><a href="#加载Bean的主要逻辑" class="headerlink" title="加载Bean的主要逻辑"></a>加载Bean的主要逻辑</h5><p>​    1.获取配置文件资源</p><p>​    2.对获取的xml资源进行一定的处理检验</p><p>​    3.处理包装资源</p><p>​    4.解析处理包装过后的资源</p><p>​    5.加载提取bean并注册(添加到beanDefinitionMap中</p><h5 id="Bean的生命周期"><a href="#Bean的生命周期" class="headerlink" title="Bean的生命周期"></a>Bean的生命周期</h5><ul><li>Bean的建立，由BeanFactory读取Bean定义文件，并创建Bean实例；</li><li>执行Bean的属性注入,Setter注入；</li><li>如果Bean类实现了org.springframework.beans.factory.BeanNameAware接口,则执行其setBeanName方法；</li><li>如果Bean类实现了org.springframework.beans.factory.BeanFactoryAware接口,则执行其setBeanFactory方法；</li><li>如果容器中有实现org.springframework.beans.factory.BeanPostProcessors接口的实例，则任何Bean在初始化之前都会执行这个实例的processBeforeInitialization()方法；</li><li>如果Bean类实现了org.springframework.beans.factory.InitializingBean接口，则执行其afterPropertiesSet()方法；</li><li>调用Bean的初始化方法”init-method” (！！注意，init-method方法没有参数)；</li><li>如果容器中有实现org.springframework.beans.factory.BeanPostProcessors接口的实例，则任何Bean在初始化之后都会执行这个实例的processAfterInitialization()方法；</li><li>使用Bean做一些业务逻辑….</li><li>使用完，容器关闭，如果Bean类实现了org.springframework.beans.factory.DisposableBean接口，则执行它的destroy()方法；</li><li>在容器关闭时，可以在Bean定义文件中使用“destory-method”定义的方法，销毁Bean (！！注意，destory-method方法没有参数)；</li></ul><h5 id="Bean的作用域"><a href="#Bean的作用域" class="headerlink" title="Bean的作用域"></a>Bean的作用域</h5><ul><li>Singleton: 这是默认的作用域，这种范围确保不管接受多少个请求，每个容器中只有一个bean的实例，单例模式有BeanFactory自身维护；</li><li>Prototype: 原形范围与单例范围相反，为每一个bean请求提供一个实例；</li></ul><ul><li>Request: 在请求bean范围内会为每一个来自客户端的网络请求创建一个实例，在请求完成以后，bean会失效并被垃圾回收器回收；</li><li>Session: 与请求范围类似，确保每个session中有一个bean的实例，在session过期后，bean会随之失效；</li><li>global-session: global-session和Portlet应用相关。当你的应用部署在Portlet容器中工作时，它包含很多portlet。如果你想要声明让所有的portlet共用全局的存储变量的话，那么这全局变量需要存储在global-session中。</li></ul><h3 id="Spring-IOC"><a href="#Spring-IOC" class="headerlink" title="Spring IOC"></a>Spring IOC</h3><p>IOC(控制反转):本质就是自己的信息(全类名等)配置在文件中或者加上注解,让容器可以通过反射的方式来创建对象,从而接管对象,代替了自己通过new创建对象.其实就是讲对象的管理创建交给了容器来做.</p><p>依赖注入:在运行过程中,会在需要这个对象的位置坐上一个标记,容器会负责创建对象实例并注入其中;</p><h4 id="Spring-IOC容器的初始化过程"><a href="#Spring-IOC容器的初始化过程" class="headerlink" title="Spring IOC容器的初始化过程"></a>Spring IOC容器的初始化过程</h4><p>IoC容器的初始化就是含有BeanDefinition信息的Resource的定位、载入、解析、注册四个过程，最终我们配置的bean，以beanDefinition的数据结构存在于IoC容器即内存中。</p><h5 id="Resource定位过程"><a href="#Resource定位过程" class="headerlink" title="Resource定位过程"></a>Resource定位过程</h5><p>这个Resource定位指的是BeanDefinition的资源定位，它由ResourceLoader通过统一的Resource接口来完成，这个Resource对各种形式的BeanDefinition的使用提供了统一接口。</p><h5 id="BeanDefinition的载入"><a href="#BeanDefinition的载入" class="headerlink" title="BeanDefinition的载入"></a>BeanDefinition的载入</h5><p>该载入过程把用户定义好的Bean表示成IoC容器内部的数据结构，而这个容器内部的数据结构就BeanDefinition.</p><h5 id="向IoC容器注册这些BeanDefinition"><a href="#向IoC容器注册这些BeanDefinition" class="headerlink" title="向IoC容器注册这些BeanDefinition"></a>向IoC容器注册这些BeanDefinition</h5><p>这个过程是通过调用BeanDefinitionRegistry接口的实现来完成的，这个注册过程把载入过程中解析得到的BeanDefinition向IoC容器进行注册,在IoC容器内部将BeanDefinition注入到一个HashMap中去，Ioc容器是通过这个HashMap来持有这些BeanDefinition数据的。</p><p>容器的初始化是通过AbstractApplicationContext的refresh()实现的。</p><pre><code></code></pre><p>整个过程如下图:</p><p><img src="/2020/01/04/hui-tou-zai-kan-spring/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E5%9B%9E%E5%A4%B4%E5%86%8D%E7%9C%8Bspring%5C1.png" alt="img"></p><h3 id="Spring-AOP"><a href="#Spring-AOP" class="headerlink" title="Spring AOP"></a>Spring AOP</h3><p>面向切面的编程，是一种编程技术，<strong>是OOP（面向对象编程）的补充和完善</strong>。OOP的执行是一种从上往下的流程，并没有从左到右的关系。因此在OOP编程中，会有大量的重复代码。而<strong>AOP则是将这些与业务无关的重复代码抽取出来，然后再嵌入到业务代码当中</strong>。常见的应用有：权限管理、日志、事务管理等。</p><p>AOP有三种植入切面的方法：其一是编译期织入，这要求使用特殊的Java编译器，AspectJ是其中的代表者；其二是类装载期织入，而这要求使用特殊的类装载器，AspectJ和AspectWerkz是其中的代表者；其三为动态代理织入，在运行期为目标类添加增强生成子类的方式，<strong>Spring AOP采用动态代理织入切面</strong>。</p><p>AspectJ是静态代理的增强，所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强。</p><p>它会在<strong>编译阶段</strong>将Aspect织入Java字节码中， 运行的时候就是经过增强之后的AOP对象。</p><p>AspectJ在编译时就增强了目标对象，Spring AOP的动态代理则是在每次运行时动态的增强，生成AOP代理对象，区别在于生成AOP代理对象的时机不同，相对来说<strong>AspectJ的静态代理方式具有更好的性能</strong>，但是AspectJ<strong>需要特定的编译器</strong>进行处理，而Spring AOP则无需特定的编译器处理。</p><p>Spring AOP中的动态代理主要有两种方式，<strong>JDK动态代理</strong>和<strong>CGLIB动态代理</strong>。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。<strong>JDK动态代理的核心是InvocationHandler接口和Proxy类</strong>。</p><p>如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态地生成某个类的子类，注意，<strong>CGLIB是通过继承的方式做的动态代理</strong>，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的</p><h4 id="jDK代理"><a href="#jDK代理" class="headerlink" title="jDK代理"></a>jDK代理</h4><p> JDK的动态代理主要涉及到java.lang.reflect包中的两个类：Proxy和InvocationHandler。其中 InvocationHandler是一个接口就是拦截器的接口。，可以通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态将横切逻辑和业务逻辑编织在一起。</p><h5 id="InvocationHandler的作用"><a href="#InvocationHandler的作用" class="headerlink" title="InvocationHandler的作用"></a>InvocationHandler的作用</h5><p>在动态代理中InvocationHandler是核心，每个代理实例都具有一个关联的调用处理程序(InvocationHandler)。对代理实例调用方法时，将对方法调用进行编码并将其指派到它的调用处理程序(InvocationHandler)的 invoke 方法。所以对代理方法的调用都是通InvocationHadler的invoke来实现中，而invoke方法根据传入的代理对象，方法和参数来决定调用代理的哪个方法</p><h5 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h5><p>使用代理模式必须要让代理类和目标类实现相同的接口，客户端通过代理类来调用目标方法，代理类会将所有的方法调用分派到目标对象上反射执行，还可以在分派过程中添加”前置通知”和后置处理（如在调用目标方法前校验权限，在调用完目标方法后打印日志等）等功能。</p><p>具体有如下四步骤：</p><p>1.通过实现 InvocationHandler 接口创建自己的调用处理器；</p><p>2.通过为 Proxy 类指定 ClassLoader 对象和一组 interface 来创建动态代理类；</p><p>3.通过反射机制获得动态代理类的构造函数，其唯一参数类型是调用处理器接口类型；</p><p>4.通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数被传入。</p><p><img src="/2020/01/04/hui-tou-zai-kan-spring/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E5%9B%9E%E5%A4%B4%E5%86%8D%E7%9C%8Bspring%5Cclipboard.png" alt="clipboard"></p><h4 id="利用cglib代理实现AOP"><a href="#利用cglib代理实现AOP" class="headerlink" title="利用cglib代理实现AOP"></a>利用cglib代理实现AOP</h4><p>CGlib是一个强大的,高性能,高质量的Code生成类库。cglib封装了asm，可以在运行期动态生成新的class，它可以在运行期扩展Java类与实现Java接口。 CGLIB是<strong>针对类实现代理</strong>的，主要对指定的类生成一个子类，并覆盖其中的方法， 因为是继承，所以不能使用final来修饰类或方法。和jdk代理实现不同的是，cglib不要求类实现接口。</p><p>JDK动态代理和CGLIB字节码生成的区别？</p><p>CGLib所创建的动态代理对象的性能比JDK的高大概10倍，但CGLib在创建代理对象的时间比JDK大概多8倍，所以对于singleton的代理对象或者具有实例池的代理，因为无需重复的创建代理对象，所以比较适合CGLib动态代理技术，反之选择JDK代理</p><ul><li><p>JDK动态代理只能对实现了接口的类生成代理，而不能针对类</p></li><li><p>CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法</p><p>因为是继承，所以该类或方法最好不要声明成final </p></li></ul><p>1、如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP</p><p>2、如果目标对象实现了接口，可以强制使用CGLIB实现AOP</p><p>3、如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>理解KMP回溯</title>
      <link href="/2020/01/03/li-jie-kmp-hui-su/"/>
      <url>/2020/01/03/li-jie-kmp-hui-su/</url>
      
        <content type="html"><![CDATA[<h4 id="理解KMP回溯"><a href="#理解KMP回溯" class="headerlink" title="理解KMP回溯"></a>理解KMP回溯</h4><p>相信大家都看过KMP算法，但是对于它的回溯确是难以理解。我们先来看一下KMP中的next数组生成代码：</p><pre><code>    //用于生成next数组    private static int[] get_next(String target){        int[] next = new int[target.length()];        next[0] = -1;        int i = 0, j = -1;        while(i &lt; target.length() - 1){            if (j == -1 || target.charAt(i) == target.charAt(j)) {                ++i;                ++j;                next[i] = j;            } else {                j = next[j];            }        }        return next;    }</code></pre><ul><li>其中数组的next中的值计算方式是：</li></ul><p>next[j] = Max{k | 1&lt;k&lt;j,且‘p1p2…pk’=‘p(j-k)…p(j - 1)’}</p><ul><li><h5 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h5></li></ul><p><em>简单来说next[j]表示的就是两个相等的字符串的长度，这两个字符串分别是从头开始记的长度为next[j]的和以next[j]的前一个字符结尾的长度为next[j]。</em></p><ul><li><h5 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h5></li></ul><p>例如：字符串”ababaaaba” next = [-1,0,0,1,2,3,1,1,2]<br>其中的回溯环节就是从next[5] = 3 到 next[6] = 1;</p><p>其中next[5]时：是”ababa”中前缀”aba”与后缀”aba”的长度，当i = 6时，”ababaa”中”a”不等于”b”,所以回溯到j = next[j],其中j为现在next[5]的值。</p><ul><li><h5 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h5></li></ul><p><strong>我开始也是很不明白为什么就可以直接回到j = next[next[5]] = 0处开始向后比较，后来仔细研究发现原因是，通过前面的比较它已经排除了所有的前缀字符串等于后缀字符串的长度大于回溯到当前j的可能 。</strong><br>就拿上面的“ababa”到“ababaa”举例：<br>其实我们想不通的无非就是它是怎么排除“aba”!=”baa”转而直接去判断前缀“ab”是否等于后缀“aa”,后来我仔细分析才发现因为如果前面的“aba” = “baa”要成立，必须有“前缀ab”等于后缀“ba”,而得到next[5]=3的时候已经隐式的得到的第一个“ba”等于第二个“ba”(当时是“aba” = “aba”)<br>从而有“aba”中三个值都应该相等，与前面矛盾。可能你早就看不懂我在说什么了，来一点数学表达式比较实际：</p><ul><li><h5 id="数学证明"><a href="#数学证明" class="headerlink" title="数学证明"></a>数学证明</h5></li></ul><p>②开始有p1p2….pj = pi - j ….pi-1，可以得出pj = pj-1  j = 1,2,…<br>假设 next[j] = k 就有 p1p2…pk = pj-k …pj-1    k = 1,2…<br>若加入pi != pj + 1,则需要回溯到判断pk 是否等于pj;<br>首先证明：pi-j+1…pi ！= p1p2…pj,反证：假设：pi-j+1…pi = p1p2…p，又p1p2….pj = pi - j ….pi-1<br>所以有pi - j ….pi-1 =pi-j+1…pi ,得到pi-j=pi-j+1=…=pi;与前面矛盾，所以有pi-j+1…pi ！= p1p2…pj<br>同理可以得出pi-j+2…pi ！= p1p2…pj-1  。。。。。pi-j+k…pi ！= p1p2…pj-k+1  。。。。。<br>所以可以直接回溯到j = next[j]继续向后判断</p><p>KMP完整代码</p><pre><code>    private static int[] get_next(String target){        int[] next = new int[target.length()];        next[0] = -1;        int i = 0, j = -1;        while(i &lt; target.length() - 1){            if (j == -1 || target.charAt(i) == target.charAt(j)) {                ++i;                ++j;                next[i] = j;            } else {                j = next[j];            }        }        return next;    }    int kmp(String s, String pattern) {        int i = 0,j = 0;        int slen = s.length(), plen = pattern.length();        int[] next = get_next(pattern);        while (i &lt; slen &amp;&amp; j &lt; plen) {            if (s.charAt(i) == pattern.charAt(j)) {                i++;                j++;            } else {                if (next[j] == -1) {                    i++;                    j = 0;                } else {                    j = next[j];                }            }            if (j == plen) {                return i - j;            }        }        return -1;    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>使用VMware安装linux虚拟机</title>
      <link href="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/"/>
      <url>/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=552192975&auto=0&height=66"></iframe></div><h1 id="使用VMware安装linux虚拟机"><a href="#使用VMware安装linux虚拟机" class="headerlink" title="使用VMware安装linux虚拟机"></a>使用VMware安装linux虚拟机</h1><h3 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h3><p><em>Linux是一种自由和开放源码的操作系统，存在着许多不同的Linux发行版本，但它们都使用了Linux内核。现在的服务器基本都是使用linux,其中CentOS使用广泛,还有ubuntu也是linux中的佼佼者.业内也说,凡是<strong>java开发,不懂linux均是扯淡.</strong>本文主要为后面搭建基于Hadoop集群的大数据大数据平台打下基础。</em></p><h4 id="linux具有如下优点"><a href="#linux具有如下优点" class="headerlink" title="linux具有如下优点"></a>linux具有如下优点</h4><ul><li>开源</li><li>多用户，多任务，丰富的网络功能，可靠的系统安全，良好的可移植性，具有标准兼容性</li><li>良好的用户界面，出色的速度性能</li><li>服务器不使用图形化界面(图形界面占用资源)</li><li>机房部署方便，无需配置操作界面</li></ul><p><strong>下载地址</strong><a href="http://www.centos.org/" target="_blank" rel="noopener">:http://www.centos.org/</a></p><h3 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h3><ul><li>Windows10</li><li>VMware Workstation12</li><li>CentOS7</li></ul><h4 id="VMware-Workstation12安装"><a href="#VMware-Workstation12安装" class="headerlink" title="VMware Workstation12安装"></a>VMware Workstation12安装</h4><p>①双击VMware-workstation-full-版本号.exe</p><p>②点击next</p><p>③选择Typical(你要是想自己配置也可以选custom 不推荐)</p><p>④选择安装目录</p><p>⑤想检查升级就勾上(check for product updates on startup),否则直接下一步</p><p>⑥选择创建快捷方式的位置,然后下一步</p><p>⑦点击continue完成</p><p>⑧Finish完成</p><p><strong>注意:如果你不熟悉就按部就班来,不要有什么骚操作,我记得我开始安装的时候禁用了哪两个网卡,后来哪两个网卡找不到了,我就把这个卸载了重新装,还是不行,这个问题的解决还是因为我一个月后重装了电脑</strong></p><h4 id="CentOS7安装"><a href="#CentOS7安装" class="headerlink" title="CentOS7安装"></a>CentOS7安装</h4><p>①安装VMware Workstation</p><p>②打开VM,点击创建新的虚拟机</p><p>③选择 典型（推荐）→ 下一步 </p><p>④选择稍后安装操作系统再点击下一步</p><p>⑤选择操作系统和版本(linux 64)</p><p>⑥输入虚拟机名称和安装路径</p><p>⑦设置磁盘大小并选中将虚拟磁盘拆成多个文件</p><p>⑧自定义硬件</p><p>⑨选择CentOS安装镜像文件</p><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577631145598.png" alt="1577631145598"></p><p>⑩开机启动后选择Install CentOS 7并enter</p><ul><li>弹出如下图形化的安装界面：</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat.png" alt="img"></p><ul><li>日期和时间：</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat1.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat2.png" alt="img"></p><ul><li>如果你安装的是英文版，需要将时区改为上海。</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat3.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat4.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126014938900.png" alt="img"></p><ul><li><strong>网络和主机名</strong></li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126015037602.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126015051216.png" alt="img"></p><ul><li>然后选择开始安装**</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat7.png" alt="img">基本的系统就安装好了</p><h3 id="配置网络"><a href="#配置网络" class="headerlink" title="配置网络"></a>配置网络</h3><ul><li>linu有三种网络模式,分别是Host-Only、NAT、桥接。一般安装好以后会默认选择NAT。</li></ul><ul><li>进入之后修改ip地址信息</li></ul><pre><code>vi /etc/ sysconfig/network-scripts/ifcfg-eth0DEVICE=eth0 #网卡名称HWADDR=08:00:27:8E:9D:25 #MAC地址TYPE=Ethernet #网络类型,这里是以太网UUID=5f2d815e-bd3b-4995-9009-823542e77304ONBOOT=yes NM_CONTROLLED=yesBOOTPROTO=staticSTATIC=trueIPADDR=192.168.1.21 #ip地址NETMASK=255.255.255.0 #子网掩码GATEWAY=192.168.1.1 #网管DNS1=202.202.0.33 #域名解析地址DNS2=114.114.114.114DNS3=8.8.8.8</code></pre><ul><li>配置好以后重启网络服务</li></ul><pre><code>services network restart</code></pre><ul><li>ifconfig查看IP地址</li></ul><pre><code>ifconfigeth0      Link encap:Ethernet  HWaddr 08:00:27:8E:9D:25            inet addr:192.168.1.21  Bcast:192.168.1.255  Mask:255.255.255.0          inet6 addr: fe80::a00:27ff:fe8e:9d25/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:1756623 errors:0 dropped:0 overruns:0 frame:0          TX packets:1952463 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000           RX bytes:1445482120 (1.3 GiB)  TX bytes:1626059931 (1.5 GiB)lo        Link encap:Local Loopback            inet addr:127.0.0.1  Mask:255.0.0.0          inet6 addr: ::1/128 Scope:Host          UP LOOPBACK RUNNING  MTU:65536  Metric:1          RX packets:2258 errors:0 dropped:0 overruns:0 frame:0          TX packets:2258 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0           RX bytes:590708 (576.8 KiB)  TX bytes:590708 (576.8 KiB)</code></pre><ul><li>ping ip地址测试网络是否配置好</li></ul><pre><code>ping www.baidu.com</code></pre><p><strong>按照以上操作完成安装以后可以直接克隆改虚拟机，然后修改配置就可以生成多台</strong></p><p><strong>在每个主机的/etc/hosts文件设置上每个主机的ip和名字的映射关系</strong></p><pre><code>vi /etc/hosts192.168.1.21 master192.168.1.23 slave1192.168.1.24 slave2192.168.1.25 slave3</code></pre><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577691474359.png" alt="1577691474359"></p><h4 id="配置免密登录"><a href="#配置免密登录" class="headerlink" title="配置免密登录"></a>配置免密登录</h4><ul><li>主要用于两个机器之间相互登录不需要验证</li></ul><p>①在第一台机器使用命令ssh-keygen -t rsa生成私钥和秘钥</p><pre><code>ssh-keygen -t rsa</code></pre><p>②复制到另一台机器</p><pre><code>ssh-copy-id root@slave1</code></pre><p><strong>如此就可以实现slave登录master免密,按照这个做法,每两台机器都配置上。</strong></p><h5 id="科普：免密登录原理"><a href="#科普：免密登录原理" class="headerlink" title="科普：免密登录原理"></a>科普：免密登录原理</h5><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577692561419.png" alt="1577692561419"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>hexo博文包含图片的坑</title>
      <link href="/2019/12/29/hexo-bo-wen-bao-han-tu-pian-de-keng/"/>
      <url>/2019/12/29/hexo-bo-wen-bao-han-tu-pian-de-keng/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=414414&auto=0&height=66"></iframe></div><h1 id="hexo博文包含图片的坑"><a href="#hexo博文包含图片的坑" class="headerlink" title="hexo博文包含图片的坑"></a>hexo博文包含图片的坑</h1><h3 id="网上有很多关于这个的教程-主要的总结如下"><a href="#网上有很多关于这个的教程-主要的总结如下" class="headerlink" title="网上有很多关于这个的教程,主要的总结如下"></a>网上有很多关于这个的教程,主要的总结如下</h3><ul><li>①修改博客目录下的_config_yml的post_asset_folder为true</li></ul><pre class="line-numbers language-java"><code class="language-java">post_asset_folder<span class="token operator">:</span> <span class="token boolean">true</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>②安装hexo-asset-image插件</li></ul><pre><code>npm install hexo-asset-image --save</code></pre><ul><li>③hexo new  file_name 时会在source/_post/下生成file_name的文件夹,将需要使用的图片放置在里面,然后使用相对路径引入</li></ul><pre><code>![用于图片加载失败时显示的内容](/file_name/image_name)</code></pre><ul><li>如此博客中的图片最后会和.md文件一起生成到public\2019\12\27\file_name中,这样在hexe g 时,可以看到命令窗口会打印修改后的路径,如下</li></ul><pre><code>Start processingupdate link as:--&gt;/2019/12/27/first/1577523021175.pngupdate link as:--&gt;/2019/12/27/first/1577523021175.png</code></pre><h3 id="我遇到的问题"><a href="#我遇到的问题" class="headerlink" title="我遇到的问题"></a>我遇到的问题</h3><pre><code>Start processingupdate link as:--&gt;.io//2019/12/27/first/1577523021175.pngupdate link as:--&gt;.io//2019/12/27/first/1577523021175.png</code></pre><ul><li>经过一番搜寻,发现hexo-asset-image会将图片的地址修改,具体的源码信息可见\node_modules\hexo-asset-image\index.js,打开后内容如下:</li></ul><pre><code>&#39;use strict&#39;;var cheerio = require(&#39;cheerio&#39;);function getPosition(str, m, i) {  return str.split(m, i).join(m).length;}hexo.extend.filter.register(&#39;after_post_render&#39;, function(data){  var config = hexo.config;  if(config.post_asset_folder){    var link = data.permalink;    var beginPos = getPosition(link, &#39;/&#39;, 3) + 1;    var appendLink = &#39;&#39;;    // In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;.    // if not with index.html endpos = link.lastIndexOf(&#39;.&#39;) + 1 support hexo-abbrlink    if(/.*\/index\.html$/.test(link)) {      // when permalink is end with index.html, for example 2019/02/20/xxtitle/index.html      // image in xxtitle/ will go to xxtitle/index/      appendLink = &#39;index/&#39;;      var endPos = link.lastIndexOf(&#39;/&#39;);    }    else {      var endPos = link.lastIndexOf(&#39;.&#39;) ;    }    link = link.substring(beginPos, endPos) + &#39;/&#39; + appendLink;    var toprocess = [&#39;excerpt&#39;, &#39;more&#39;, &#39;content&#39;];    for(var i = 0; i &lt; toprocess.length; i++){      var key = toprocess[i];      var $ = cheerio.load(data[key], {        ignoreWhitespace: false,        xmlMode: false,        lowerCaseTags: false,        decodeEntities: false      });      $(&#39;img&#39;).each(function(){        if ($(this).attr(&#39;src&#39;)){          // For windows style path, we replace &#39;\&#39; to &#39;/&#39;.          var src = $(this).attr(&#39;src&#39;).replace(&#39;\\&#39;, &#39;/&#39;);          if(!(/http[s]*.*|\/\/.*/.test(src)            || /^\s+\//.test(src)            || /^\s*\/uploads|images\//.test(src))) {            // For &quot;about&quot; page, the first part of &quot;src&quot; can&#39;t be removed.            // In addition, to support multi-level local directory.            var linkArray = link.split(&#39;/&#39;).filter(function(elem){              return elem != &#39;&#39;;            });            var srcArray = src.split(&#39;/&#39;).filter(function(elem){              return elem != &#39;&#39; &amp;&amp; elem != &#39;.&#39;;            });            if(srcArray.length &gt; 1)            srcArray.shift();            src = srcArray.join(&#39;/&#39;);            $(this).attr(&#39;src&#39;, config.root + link + src);            console.info&amp;&amp;console.info(&quot;update link as:--&gt;&quot;+config.root + link + src);          }        }else{          console.info&amp;&amp;console.info(&quot;no src attr, skipped...&quot;);          console.info&amp;&amp;console.info($(this));        }      });      data[key] = $.html();    }  }});</code></pre><ul><li>通过查看源码发现里面有对生成博客图片的地址修改:</li></ul><pre><code>link = link.substring(beginPos, endPos) + &#39;/&#39; + appendLink;</code></pre><ul><li>通过排查发现图片的路径的endPos为:</li></ul><pre><code>var endPos = link.lastIndexOf(&#39;.&#39;) ;</code></pre><ul><li>我打印data.permalink得到</li></ul><pre><code>http://tigerLuHai.github.io/2019/12/27/first/</code></pre><p>如此在截取字符串的时候就会多出四个字符  <strong>.io/</strong></p><p>最后发现这段代码的作用就是要将data.permalink中路径的<a href="https://tigerLuhai.gituhub.io/去掉,因为在后面部署到github时使用相对路径访问会重新加上这个前缀,如果这里有就会重复,导致地址为https://tigerLuhai.gituhub.io/http://tigerLuHai.github.io/2019/12/27/first/的现象" target="_blank" rel="noopener">https://tigerLuhai.gituhub.io/去掉,因为在后面部署到github时使用相对路径访问会重新加上这个前缀,如果这里有就会重复,导致地址为https://tigerLuhai.gituhub.io/http://tigerLuHai.github.io/2019/12/27/first/的现象</a>.</p><p>明白了需求就可以修改代码为</p><pre><code>var endPos = link.lastIndexOf(&#39;/&#39;) ;</code></pre><p>这样就可以正常部署了.</p>]]></content>
      
      
      <categories>
          
          <category> tool </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>FastDFS分布式文件系统安装使用教程</title>
      <link href="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/"/>
      <url>/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=479553545&auto=1&height=66"></iframe></div><h1 id="FastDFS分布式文件系统安装使用教程"><a href="#FastDFS分布式文件系统安装使用教程" class="headerlink" title="FastDFS分布式文件系统安装使用教程"></a>FastDFS分布式文件系统安装使用教程</h1><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><p>分布式文件系统用于<strong>海量</strong>文件存储及传输访问的瓶颈问题，对海量视频的管理、对<strong>海量</strong>图片的管理等,FastDFS与其他分布式文件系统相比的一个显著优点就是特别<strong>适合大量小文件(图片等)的存储,因为它在存储时没有对文件切片分割.</strong></p><h3 id="主流的分布式文件系统"><a href="#主流的分布式文件系统" class="headerlink" title="主流的分布式文件系统"></a>主流的分布式文件系统</h3><h4 id="①NFS"><a href="#①NFS" class="headerlink" title="①NFS"></a>①NFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523021175.png" alt="1577523021175"></p><h4 id="②GFS"><a href="#②GFS" class="headerlink" title="②GFS"></a>②GFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523108700.png" alt="1577523108700"></p><h4 id="③HDFS"><a href="#③HDFS" class="headerlink" title="③HDFS"></a>③HDFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523192987.png" alt="1577523192987"></p><h4 id="④FastDFS"><a href="#④FastDFS" class="headerlink" title="④FastDFS"></a>④FastDFS</h4><p>FastDFS是用c语言编写的一款开源的分布式文件系统，它是由淘宝资深架构师余庆编写并开源。FastDFS专为互联 网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很 容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。</p><p><strong>FastDFS架构包括 Tracker server和Storageserver。客户端请求Tracker server进行文件上传、下载，通过Tracker server调度最终由Storage server完成文件上传和下载。</strong> </p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="服务器环境"><a href="#服务器环境" class="headerlink" title="服务器环境"></a>服务器环境</h4><ul><li>CentOS6.9(CenttOS安装过程一致)</li></ul><ul><li>IP: 192.168.1.21,192.168.1.23,192.168.1.24,192.168.1.25</li></ul><h4 id="安装Linux基本环境"><a href="#安装Linux基本环境" class="headerlink" title="安装Linux基本环境"></a>安装Linux基本环境</h4><p>参见Hadoop的安装使用教程中Linux环境搭建</p><h4 id="安装gcc环境-FastDFS是由c语言编写"><a href="#安装gcc环境-FastDFS是由c语言编写" class="headerlink" title="安装gcc环境(FastDFS是由c语言编写)"></a>安装gcc环境(FastDFS是由c语言编写)</h4><pre class="line-numbers language-linux"><code class="language-linux">yum install gcc-c++<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="安装-libevent"><a href="#安装-libevent" class="headerlink" title="安装 libevent"></a>安装 libevent</h4><pre class="line-numbers language-yum"><code class="language-yum">yum -y install libevent<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="安装-libfastcommon"><a href="#安装-libfastcommon" class="headerlink" title="安装 libfastcommon"></a>安装 libfastcommon</h4><pre><code>将 libfastcommonV1.0.7.tar.gz 拷贝至/usr/local/下cd /usr/localtar -zxvf libfastcommonV1.0.7.tar.gzcd libfastcommon-1.0.7./make.sh./make.sh install</code></pre><p>注意：<strong>libfastcommon 安装好后会自动将库文件拷贝至/usr/lib64 下，由于 FastDFS 程序引用 usr/lib 目录所以需要将/usr/lib64 下的库文件拷贝至/usr/lib 下。</strong></p><p>需要拷贝的文件</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577524769079.png" alt="1577524769079"></p><h4 id="tracker-编译安装"><a href="#tracker-编译安装" class="headerlink" title="tracker 编译安装"></a>tracker 编译安装</h4><pre class="line-numbers language-将"><code class="language-将">将 FastDFS_v5.05.tar.gz 拷贝至/usr/local/下tar -zxvf FastDFS_v5.05.tar.gzcd FastDFS./make.sh 编译./make.sh install 安装<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>安装成功将安装目录下的 conf 下的文件拷贝到/etc/fdfs/下。</p><pre><code>cp -r /usr/local/FastDFS/conf/ /etc/fdfs/</code></pre><h5 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h5><p>安装成功后进入/etc/fdfs目录</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577525471795.png" alt="1577525471795"></p><p>拷贝一份新的 tracker 配置文件：</p><pre><code>cp tracker.conf.sample tracker.conf</code></pre><p>修改 tracker.conf</p><pre><code>vi tracker.confbase_path=/home/yuqing/FastDFS #数据(日志等)存储路径,自己设置http.server_port=80 #配置 http 端口：</code></pre><h5 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h5><pre><code>/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</code></pre><p>查看端口</p><pre><code>netstat -nltp</code></pre><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577535905825.png" alt="1577535905825"></p><h4 id="storage-安装"><a href="#storage-安装" class="headerlink" title="storage 安装"></a>storage 安装</h4><ul><li>安装 libevent</li><li>安装 libfastcommon</li><li>编译安装(与tracker相同)</li></ul><h5 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h5><pre><code>vi storage.confgroup_name=group1 #分组,同一分组为设置冗余防止宕机不可用base_path=/home/yuqing/FastDFS #数据存储路径,自己设置store_path0=/home/yuqing/FastDFS #文件存储路径,自己设置tracker_server=192.168.101.3:22122 #配置 tracker 服务器:IPtracker_server=192.168.1.21:22122 #如果有多个则配置多个 trackerhttp.server_port=80</code></pre><h5 id="启动-1"><a href="#启动-1" class="headerlink" title="启动"></a>启动</h5><pre><code>/usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</code></pre><h5 id="分发配置"><a href="#分发配置" class="headerlink" title="分发配置"></a>分发配置</h5><p>将FastDFS分发到各个节点,并修改配置,分发脚本如下</p><pre><code>#!/bin/bashpcount=$#if((pcount=0));thenecho no args;exit;fip1=$1fname=`basename $p1`echo fname=$fnamepdir=`cd -P $(dirname $p1);pwd`echo pdir=$pdiruser=`whoami`echo user=$userfor((host=1;host&lt;4;host++));doecho ------------salve$host-------------rsync -rvl $pdir/$fname $user@slave$host:$pdirdone</code></pre><h3 id="利用可通过-usr-bin-fdfs-test-程序测试"><a href="#利用可通过-usr-bin-fdfs-test-程序测试" class="headerlink" title="利用可通过/usr/bin/fdfs_test 程序测试"></a>利用可通过/usr/bin/fdfs_test 程序测试</h3><p>修改/etc/fdfs/client.conf</p><p>tracker_server 根据自己部署虚拟机的情况配置</p><pre><code>base_path = /home/yuqing/fastdfstracker-server=192.168.1.21:22122</code></pre><p>使用格式：</p><pre><code>/usr/bin/fdfs_test 客户端配置文件地址 upload 上传文件</code></pre><p>比如将/home 下的图片上传到 FastDFS 中：</p><pre><code>/usr/bin/fdfs_test /etc/fdfs/client.conf upload /home/tomcat.png</code></pre><p>打印日志如下:</p><pre><code>This is FastDFS client test program v5.05Copyright (C) 2008, Happy Fish / YuQingFastDFS may be copied only under the terms of the GNU GeneralPublic License V3, which may be found in the FastDFS source kit.Please visit the FastDFS Home Page http://www.csource.org/ for more detail.[2019-12-28 20:13:02] DEBUG - base_path=/home/fastdfs, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0tracker_query_storage_store_list_without_group:         server 1. group_name=, ip_addr=192.168.1.24, port=23000group_name=group1, ip_addr=192.168.1.24, port=23000storage_upload_by_filenamegroup_name=group1, remote_filename=M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.pngsource ip address: 192.168.1.24file timestamp=2019-12-28 20:13:02file size=138735file crc32=2977689730example file url: http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.pngstorage_upload_slave_by_filenamegroup_name=group1, remote_filename=M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587_big.pngsource ip address: 192.168.1.24file timestamp=2019-12-28 20:13:02file size=138735file crc32=2977689730</code></pre><p><a href="http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png" target="_blank" rel="noopener">http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png</a><br>就是文件的下载路径。对应服务器的base_path/fdfs_storage/data/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png文件</p><p>现在还没有和 nginx 整合无法使用 http 下载。</p><h3 id="Nginx整合FastDFS"><a href="#Nginx整合FastDFS" class="headerlink" title="Nginx整合FastDFS"></a>Nginx整合FastDFS</h3><h4 id="FastDFS-nginx-module"><a href="#FastDFS-nginx-module" class="headerlink" title="FastDFS-nginx-module"></a>FastDFS-nginx-module</h4><p>将 FastDFS-nginx-module_v1.16.tar.gz 传 至 fastDFS 的 storage 服 务 器 的</p><p>/usr/local/下，执行如下命令：</p><pre><code>cd /usr/localtar -zxvf FastDFS-nginx-module_v1.16.tar.gzcd FastDFS-nginx-module/srcvi config</code></pre><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577536510714.png" alt="1577536510714"></p><p>将/usr/local修改为/usr，注意这里有三场，不要改漏了。</p><p>将 FastDFS-nginx-module/src 下的 mod_FastDFS.conf 拷贝至/etc/fdfs/下</p><pre><code>cp mod_FastDFS.conf /etc/fdfs/vi /etc/fdfs/mod_FastDFS.confbase_path=/home/FastDFS # 保持和之前安装时一致tracker_server=192.168.1.21:22122url_have_group_name=true #url 中包含 group 名称store_path0=/home/fastdfs/fdfs_storage #指定文件存储路径,和之前一致</code></pre><p>将 libfdfsclient.so 拷贝至/usr/lib 下</p><pre><code>cp /usr/lib64/libfdfsclient.so /usr/lib/</code></pre><p>创建 nginx/client 目录</p><pre><code>mkdir -p /var/temp/nginx/client</code></pre><h4 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h4><p>详细教程可见nginx使用感悟</p><p>将 nginx-1.8.0.tar.gz 拷贝到/usr/local 下</p><p>解压 nginx-1.8.0.tar.gz</p><p>进入 nginx-1.8.0 目录，执行如下配置命令：</p><pre><code>./configure --add-module=/usr/local/FastDFS-nginx-module/srcmake make install</code></pre><p>在nginx中增加如下虚拟机配置:</p><p>storage配置:</p><pre><code>server { listen 80; server_name 192.168.1.23; 本机ip location /group1/M00/{ root /home/FastDFS/fdfs_storage/data;  #以自己配置的地址为准 ngx_FastDFS_module; } }</code></pre><p>tracker配置:</p><pre><code>#storage 群 group1 组upstream storage_server_group1{ server 192.168.1.23:80 weight=10;server 192.168.1.24:80 weight=10; } #storage 群 group2 组upstream storage_server_group2{ server 192.168.1.25:80 weight=10; } server {listen 80;server_name ccc.test.com;location /group1{proxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://storage_server_group1;}location /group2{proxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://storage_server_group2; } }</code></pre><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>使用浏览器 http 访问文件，这里访问上传图片测试的文件：</p><p>访问 storage：<a href="http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png" target="_blank" rel="noopener">http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png</a></p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577537632508.png" alt="1577537632508"></p><p>ip 地址改为 192.168.1.24也可以访问到文件，因为同一个分组的 storage 文件互相同步。</p><h3 id="编写java代码上传下载文件"><a href="#编写java代码上传下载文件" class="headerlink" title="编写java代码上传下载文件"></a>编写java代码上传下载文件</h3><p><strong>SpringBoot测试方案</strong></p><p>引入依赖</p><pre><code>        &lt;dependency&gt;            &lt;groupId&gt;net.oschina.zcx7878&lt;/groupId&gt;            &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt;            &lt;version&gt;1.27.0.0&lt;/version&gt;        &lt;/dependency&gt;</code></pre><pre><code>@SpringBootTest@RunWith(SpringRunner.class)public class TestFastDFS {    @Test    public void upload() throws IOException, MyException {        //加载fastdfs-client.properties配置文件        ClientGlobal.initByProperties(&quot;config/fastdfs-client.properties&quot;);        //定义TrackerClient,用于请求TrackerClient        TrackerClient trackerClient = new TrackerClient();        //创建TrackerServer        TrackerServer trackerServer = trackerClient.getConnection();        //通过TrackerServer获取storeServer        StorageServer storeServer = trackerClient.getStoreStorage(trackerServer);        //通过TrackerServer and storeServer 创建storageClient1        StorageClient1 storageClient1 = new StorageClient1(trackerServer, storeServer);        //fileId group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log        String fileId = storageClient1.upload_file1(&quot;C:\\Users\\tiger\\Pictures\\Feedback\\{A687785D-19C3-4B2E-A00A-2667141271EB}\\Capture001.png&quot;, &quot;.png&quot;, null);        System.out.println(fileId);        //获取tracker客户端    }    @Test    public void download() throws IOException, MyException {        //加载fastdfs-client.properties配置文件        ClientGlobal.initByProperties(&quot;config/fastdfs-client.properties&quot;);        //定义TrackerClient,用于请求TrackerClient        TrackerClient trackerClient = new TrackerClient();        //创建TrackerServer        TrackerServer trackerServer = trackerClient.getConnection();        //通过TrackerServer获取storeServer        StorageServer storeServer = trackerClient.getStoreStorage(trackerServer);        //通过TrackerServer and storeServer 创建storageClient1        StorageClient1 storageClient1 = new StorageClient1(trackerServer, storeServer);        //fileId group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log        byte[] bytes = storageClient1.download_file1(&quot;group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log&quot;);        FileOutputStream fos = new FileOutputStream(new File(&quot;hello&quot;));        fos.write(bytes);    }}</code></pre><p>config/fastdfs-client.properties</p><pre><code>fastdfs.connect_timeout_in_seconds = 5fastdfs.network_timeout_in_seconds = 30fastdfs.charset = UTF-8fastdfs.tracker_servers = 192.168.1.21:22122</code></pre><p>运行upload得到路径</p><pre><code>group1/M00/00/00/wKgBGF4HUZiAOKLgAB7xNcvo_Vw00..png根据自己配置的路径可以得到访问的http协议路径为:http://192.168.1.21/group1/M00/00/00/wKgBGF4HUZiAOKLgAB7xNcvo_Vw00..png</code></pre><p>效果如下</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577538377340.png" alt="1577538377340"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>FastDFS相对于HDFS等分布式文件的优势在于它不切分文件,所以下载文件的时候没有拼装文件的过程,而且可以锁定一台机器进行网络I/O,所以速度很快.不过正所谓这也是它的缺点,这导致它不能用于存储大文件.所以FastDFS适合存储大量图片小视频之类的文件.</strong></p><h3 id="安装过程遇到的一些问题"><a href="#安装过程遇到的一些问题" class="headerlink" title="安装过程遇到的一些问题"></a>安装过程遇到的一些问题</h3><p>①安装nginx No rule to make target “/usr/local/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c”, needed by objs/addon/src/ngx_http_fastdfs_module.o . Stop. 修改fastdfs-nginx-module/src/config文件中的路径,删除local(注意一共有三个)</p><p>②nginx安装cp: <code>conf/koi-win&#39; and</code>/usr/local/nginx/conf/koi-win’ are the same file 解决 将./configure –prefix=/usr/local/nginx 改为 ./configure –prefix=/usr/local/nginx –conf-path=/usr/local/nginx/nginx.conf</p><p>③nginx编码严格.直接复制会出现nginx: [emerg] unknown directive “ “ in /usr/local/nginx-1.12.0-storage/conf/nginx.conf:49）：所以需要手动输入nginx.conf</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>first</title>
      <link href="/2019/12/27/first/"/>
      <url>/2019/12/27/first/</url>
      
        <content type="html"><![CDATA[<p><img src="/2019/12/27/first/1577523021175.png" alt="1577523021175"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop集群搭建与简单使用</title>
      <link href="/2019/12/01/hadoop-ji-qun-da-jian-yu-jian-dan-shi-yong/"/>
      <url>/2019/12/01/hadoop-ji-qun-da-jian-yu-jian-dan-shi-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop集群搭建与简单使用"><a href="#Hadoop集群搭建与简单使用" class="headerlink" title="Hadoop集群搭建与简单使用"></a>Hadoop集群搭建与简单使用</h1><p>首先需要搭建一个linux的集群,可以参见我的博客<a href="https://tigerluhai.github.io/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/">linux集群搭建</a></p><blockquote><p>Hadoop的运行是基于java的,所以需要先安装JDK,而且JDK版本必须高于1.7</p></blockquote><h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><p>（1）查询是否安装Java软件：</p><pre><code> rpm -qa | grep java</code></pre><p>（2）如果安装的版本低于1.7，卸载该JDK：</p><pre><code>sudo rpm -e 软件包</code></pre><p>（3）查看JDK安装路径：</p><pre><code> which(or whereis) java</code></pre><p>（4）解压JDK：</p><pre><code>tar -zxvf 安装包名 -C 目标路径</code></pre><p>（5）配置JDK环境：</p><pre><code>vi /etc/profile在文件末尾加上#JAVA_HOMEexport JAVA_HOME=/opt/module/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/bin</code></pre><p><strong>修改后需要立即生效需要运行如下命令:</strong></p><pre><code>source /etc/profile</code></pre><p>（6）测试JDK安装是否成功：</p><pre><code>java -version</code></pre><h3 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h3><p>（1）解压hadoop安装包到指定位置</p><pre><code>tar -zxvf 安装包 -C 指定目录</code></pre><p>（2）添加环境变量</p><pre><code>vi /etc/profile在文件末尾加上#HADOOP_HOMEexport HADOOP_HOME=/opt/module/hadoop-3.1.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin</code></pre><p>(3)修改配置文件</p><ul><li>集群部署规划</li></ul><table><thead><tr><th></th><th>master</th><th>slave1</th><th>slave2</th><th>slave3</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNodeDataNode</td><td>SecondaryNameNode DataNode</td><td>DataNode</td><td>DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager</td><td>NodeManager</td><td>NodeManager</td></tr></tbody></table><ul><li>核心配置文件</li></ul><p>配置core-site.xml</p><pre><code>vi core-site.xml# 在该文件中编写如下配置&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;&lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/opt/module/hadoop-3.1.2/data/tmp&lt;/value&gt;&lt;/property&gt;</code></pre><ul><li>HDFS配置文件</li></ul><p>配置hadoop-env.sh</p><pre><code> vi hadoop-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>配置hdfs-site.xml</p><pre><code>vi hdfs-site.xml&lt;!--配置副本数量--&gt;&lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;3&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;&lt;property&gt;      &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;      &lt;value&gt;slave1:50090&lt;/value&gt;&lt;/property&gt;</code></pre><p>注意:文件副本数量不只是dfs.replication决定,而是min(datanode节点数,dfs.replication)</p><ul><li>YARN配置文件</li></ul><p>配置yarn-env.sh</p><pre><code> vi yarn-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><ul><li>配置yarn-site.xml</li></ul><pre><code> vi yarn-site.xml&lt;!-- Reducer获取数据的方式 --&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定YARN的ResourceManager的地址 --&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;    &lt;value&gt;slave2&lt;/value&gt;&lt;/property&gt;</code></pre><ul><li>MapReduce配置文件</li></ul><pre><code>vi mapred-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p><strong>注意：hadoop3之前的版本,mapreduce会继承hadoop的配置,所以可以不用配置这一项,但是3以后的版本必须配置,否则运行mapreduce时会报环境出错。</strong></p><ul><li>配置mapred-site.xml</li></ul><pre><code>cp mapred-site.xml.template mapred-site.xmlvi mapred-site.xml&lt;!-- 指定MR运行在Yarn上 --&gt;&lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;</code></pre><p>（4）在集群上分发配置好的Hadoop配置文件</p><p>编写分发脚本</p><pre><code>vi /usr/local/bin/xsync#!/bin/bashpcount=$#if((pcount=0));thenecho no args;exit;fip1=$1fname=`basename $p1`echo fname=$fnamepdir=`cd -P $(dirname $p1);pwd`echo pdir=$pdiruser=`whoami`echo user=$userfor((host=1;host&lt;4;host++));doecho ------------salve$host-------------rsync -rvl $pdir/$fname $user@slave$host:$pdirdone</code></pre><pre><code>xsync /opt/module/hadoop-3.1.2/</code></pre><h3 id="集群单节点启动"><a href="#集群单节点启动" class="headerlink" title="集群单节点启动"></a>集群单节点启动</h3><p>（1）如果集群是第一次启动，需要<strong>格式化NameNode</strong></p><pre><code>hadoop namenode -format</code></pre><p>（2）在master上启动NameNode</p><pre><code>hadoop-daemon.sh start namenode</code></pre><p>查看节点启动状态</p><pre><code> jps</code></pre><p><strong>注意:jps用于查看java进程,namenode和datanode都是java进程</strong></p><p>（3）在master,slave1,slave2以及slave3上分别启动DataNode</p><pre><code>hadoop-daemon.sh start datanode</code></pre><pre><code> jps3461 NameNode3608 Jps3561 DataNode</code></pre><p>思考：每次都一个一个节点启动，如果节点数太多怎么办？</p><h3 id="群起集群"><a href="#群起集群" class="headerlink" title="群起集群"></a>群起集群</h3><ol><li>配置slaves</li></ol><pre><code>vi /opt/module/hadoop-3.1.2/etc/hadoop/slaves在该文件中增加如下内容：masterslave1slave2slave3</code></pre><p><strong>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</strong></p><p>同步所有节点配置文件</p><pre><code> xsync slaves</code></pre><ol start="2"><li>启动集群</li></ol><p>（1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）</p><pre><code>hdfs namenode -format</code></pre><p>（2）启动HDFS</p><pre><code>start-dfs.sh</code></pre><p>（3）启动YARN</p><pre><code>start-yarn.sh</code></pre><p><strong>注意：NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。</strong></p><h3 id="集群基本操作"><a href="#集群基本操作" class="headerlink" title="集群基本操作"></a>集群基本操作</h3><ul><li>-ls: 显示目录信息</li></ul><pre><code>hadoop fs -ls /</code></pre><ul><li>mkdir：在HDFS上创建目录</li></ul><pre><code> hadoop fs -mkdir -p /parent/test</code></pre><ul><li>moveFromLocal：从本地剪切粘贴到HDFS</li></ul><pre><code>hadoop fs  -moveFromLocal  ./kongming.txt  /parent/test</code></pre><ul><li>appendToFile：追加一个文件到已经存在的文件末尾</li></ul><pre><code> hadoop fs -appendToFile liubei.txt /parent/test/kongming.txt</code></pre><ul><li>cat：显示文件内容</li></ul><pre><code>hadoop fs -cat /parent/test/kongming.txt</code></pre><ul><li>chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</li><li>copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</li></ul><pre><code> hadoop fs -copyFromLocal README.txt /</code></pre><ul><li>copyToLocal：从HDFS拷贝到本地</li></ul><pre><code> hadoop fs -copyToLocal /parent/test/kongming.txt ./</code></pre><ul><li>cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</li></ul><pre><code>hadoop fs -cp /parent/test/kongming.txt  /zhuge.txt</code></pre><ul><li>mv：在HDFS目录中移动文件</li></ul><pre><code>hadoop fs -mv /zhuge.txt /parent/test/</code></pre><ul><li>get：等同于copyToLocal，就是从HDFS下载文件到本地</li></ul><pre><code>hadoop fs -get /parent/test/kongming.txt ./</code></pre><ul><li>getmerge：合并下载多个文件，比如HDFS的目录 /parent/test//test下有多个文件:log.1, log.2,log.3,…</li></ul><pre><code>hadoop fs -getmerge /parent/test/test/* ./zaiyiqi.txt</code></pre><ul><li>put：等同于copyFromLocal</li></ul><pre><code> hadoop fs -put ./zaiyiqi.txt /</code></pre><ul><li>tail：显示一个文件的末尾</li></ul><ul><li>rm：删除文件或文件夹</li></ul><ul><li>rmdir：删除空目录</li></ul><ul><li>du统计文件夹的大小信息</li></ul><h3 id="JAVA代码操作HDFS"><a href="#JAVA代码操作HDFS" class="headerlink" title="JAVA代码操作HDFS"></a>JAVA代码操作HDFS</h3><pre><code>    Logger logger = LoggerFactory.getLogger(HdfsClient.class);    FileSystem fileSystem;    Configuration configuration;    @Test    /**     * 测试环境正常     */    public void HDFS_ENV() throws IOException {        Logger logger = LoggerFactory.getLogger(HdfsClient.class);        //1.获取hdfs客户端对象        Configuration configuration = new Configuration();        configuration.set(&quot;fs.defaultFS&quot;,&quot;hdfs://master:9000&quot;);        FileSystem fileSystem = FileSystem.get(configuration);        //2.在hdfs上执行相关操作        boolean mkdirs = fileSystem.mkdirs(new Path(&quot;/client_test_environment&quot;));        //3.关闭资源        fileSystem.close();        System.out.println(mkdirs);    }    @Before    /**     * 创建fileSystem对象     */    public void createFileSystem() throws URISyntaxException, IOException, InterruptedException {        //1.获取fs对象        configuration = new Configuration();        fileSystem = FileSystem.get(new URI(&quot;hdfs://master:9000&quot;), configuration, &quot;root&quot;);    }    @Test    public void copyFromLocalFile() throws IOException{        //执行上传操作        fileSystem.copyFromLocalFile(new Path(&quot;D:\\logs\\xc.2019-04-29.log&quot;),new Path(&quot;/client_test_environment/&quot;));        //关闭资源        fileSystem.close();    }    @Test    public void copyToLocalFile() throws IOException{        //执行上传操作        fileSystem.copyToLocalFile(true,new Path(&quot;/client_test_environment/xc.2019-04-29.log&quot;),new Path(&quot;D:\\logs\\xc.2019-04-29-back.log&quot;),false);        //关闭资源        fileSystem.close();    }    @Test    public void listFiles() throws IOException {        //查看文件信息        RemoteIterator&lt;LocatedFileStatus&gt; iterator = fileSystem.listFiles(new Path(&quot;/&quot;), true);        while (iterator.hasNext()){            LocatedFileStatus fileStatus = iterator.next();            //获取文件名称，文件权限，文件长度，块信息            logger.info(fileStatus.getPath().getName());            logger.info(fileStatus.getLen()+&quot;&quot;);            logger.info(fileStatus.getPermission()+&quot;&quot;);            BlockLocation[] blockLocations = fileStatus.getBlockLocations();            for (BlockLocation blockLocation : blockLocations) {                logger.info(blockLocation.toString());            }            logger.info(&quot;----------------                    ----------------------&quot;);        }    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
