<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>JVM必须知道的基础</title>
      <link href="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/"/>
      <url>/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/</url>
      
        <content type="html"><![CDATA[<h2 id="运行时数据区域"><a href="#运行时数据区域" class="headerlink" title="运行时数据区域"></a>运行时数据区域</h2><p>网上有很多描述JVM内存区的图,我觉得这张能表述内容较多</p><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C1.png" alt="img"></p><h4 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h4><pre><code> 程序计数器(Program Counter Register)存储当前线程执行的字节码行号，占用内存较小。字节码解释器就是通过这个计数器的值来选择下一条需要执行的字节码指令。执行Java方法时计数器指向正在执行的虚拟字节码指令的地址，执行Native方法时指向空。</code></pre><h4 id="java虚拟机栈"><a href="#java虚拟机栈" class="headerlink" title="java虚拟机栈"></a>java虚拟机栈</h4><pre><code>java虚拟机栈（Java Virtual Machine Stack）与程序计数器一样，也是线程私有的，生命周期与线程相同。java虚拟机栈描述的是java方法执行的内存模型,每个方法执行的时候都会创建一个栈帧,用于存储局部变量表、操作数栈、动态链接、方法出口等信息。方法的调用和结束分别对应栈帧的入栈和出栈。</code></pre><h4 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h4><pre><code>本地方法栈（Native Method Stack）与java虚拟机栈作用相似,java虚拟机栈是为java方法服务,本地方法栈是为Native方法服务,甚至有些虚拟机实现时直接将两者合而为一(如:HotSpot).</code></pre><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><pre><code>Java堆(Java Heap)是虚拟机管理的内存中最大的一块，该内存区域的唯一目的就是存放对象实例。java堆是垃圾收集区域管理的主要区域。从回收的角度看，可以细分为新生代和老年代；再细致一点就是Eden空间、From Survivor空间、To Survivor空间。线程共享的java堆能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB）。</code></pre><h4 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h4><pre><code>方法区（Method Area）与java堆一样，是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码数据等。这个区域的垃圾回收主要是针对常量池的回收和对类型的卸载。</code></pre><h5 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h5><pre><code>运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件的常量池(Constant Pool Table)将在类加载后进入方法区的运行时常量池存放。除此之外，还会将翻译出来的直接引用也存放在运行时常量池。运行期间也可以将新的常量放入运行时常量池。</code></pre><h4 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h4><pre><code>直接内存(Direct Memory)并不是java虚拟机运行时数据区的一部分。在JDK1.4中新加入了NIO（New Input/Output）类,引入了一种基于通道(channel)和缓冲区(Buffer)的I/O方式.他可以使用Native函数库直接分配对外内存.然后通过一个内存在java堆中的DirectByteBuffer对象作为这块内存的引用进行操作.</code></pre><h2 id="垃圾收集"><a href="#垃圾收集" class="headerlink" title="垃圾收集"></a>垃圾收集</h2><h3 id="判断一个对象是否可被回收"><a href="#判断一个对象是否可被回收" class="headerlink" title="判断一个对象是否可被回收"></a>判断一个对象是否可被回收</h3><h4 id="引用计数算法"><a href="#引用计数算法" class="headerlink" title="引用计数算法"></a>引用计数算法</h4><p>为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。</p><p>在两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。正是因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。</p><h4 id="可达性分析算"><a href="#可达性分析算" class="headerlink" title="可达性分析算"></a>可达性分析算</h4><p>以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收。</p><p>Java 虚拟机使用该算法来判断对象是否可被回收，GC Roots 一般包含以下内容：</p><ul><li>虚拟机栈中局部变量表中引用的对象</li><li>本地方法栈中 JNI 中引用的对象</li><li>方法区中类静态属性引用的对象</li><li>方法区中的常量引用的对象</li></ul><h4 id="方法区的回收"><a href="#方法区的回收" class="headerlink" title="方法区的回收"></a>方法区的回收</h4><p>因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，所以在方法区上进行回收性价比不高。</p><p>主要是对常量池的回收和对类的卸载。</p><p>为了避免内存溢出，在大量使用反射和动态代理的场景都需要虚拟机具备类卸载功能。</p><p>类的卸载条件很多，需要满足以下三个条件，并且满足了条件也不一定会被卸载：</p><ul><li>该类所有的实例都已经被回收，此时堆中不存在该类的任何实例。</li><li>加载该类的 ClassLoader 已经被回收。</li><li>该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。</li></ul><h4 id="finalize"><a href="#finalize" class="headerlink" title="finalize()"></a>finalize()</h4><p>当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能在该方法中让对象重新被引用，从而实现自救。自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会再调用该方法。</p><h3 id="引用类型"><a href="#引用类型" class="headerlink" title="引用类型"></a>引用类型</h3><p>无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。</p><p>Java 提供了四种强度不同的引用类型。</p><h4 id="强引用"><a href="#强引用" class="headerlink" title="强引用"></a>强引用</h4><p>被强引用关联的对象不会被回收。</p><p>使用 new 一个新对象的方式来创建强引用。</p><pre><code>Object obj = new Object();</code></pre><h4 id="软引用"><a href="#软引用" class="headerlink" title="软引用"></a>软引用</h4><p>被软引用关联的对象只有在内存不够的情况下才会被回收。</p><p>使用 SoftReference 类来创建软引用。</p><pre><code>Object obj = new Object();SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null;  // 使对象只被软引用关联</code></pre><h4 id="弱引用"><a href="#弱引用" class="headerlink" title="弱引用"></a>弱引用</h4><p>被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。</p><p>使用 WeakReference 类来创建弱引用。</p><pre><code>Object obj = new Object();WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);obj = null;</code></pre><h4 id="虚引用"><a href="#虚引用" class="headerlink" title="虚引用"></a>虚引用</h4><p>又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。</p><p>为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。</p><p>使用 PhantomReference 来创建虚引用。</p><pre><code>Object obj = new Object();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj, null);obj = null;</code></pre><h3 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h3><h4 id="1-标记-清除"><a href="#1-标记-清除" class="headerlink" title="1. 标记 - 清除"></a>1. 标记 - 清除</h4><p>顾名思义，标记-清除算法分为两个阶段，标记(mark)和清除(sweep).</p><p>在标记阶段，collector从mutator根对象开始进行遍历，对从mutator根对象可以访问到的对象都打上一个标识，一般是在对象的header中，将其记录为可达对象。</p><p>而在清除阶段，collector对堆内存(heap memory)从头到尾进行线性的遍历，如果发现某个对象没有标记为可达对象-通过读取对象的header信息，则就将其回收。</p><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C2.png" alt="img"></p><p>从上图我们可以看到，在Mark阶段，从根对象1可以访问到B对象，从B对象又可以访问到E对象，所以B,E对象都是可达的。同理，F,G,J,K也都是可达对象。到了Sweep阶段，所有非可达对象都会被collector回收。同时，Collector在进行标记和清除阶段时会将整个应用程序暂停(mutator)，等待标记清除结束后才会恢复应用程序的运行。</p><ul><li><p><strong>优点</strong>：</p><p>实现简单，不需要进行对象进行移动。</p></li><li><p><strong>缺点</strong>：</p><p>标记、清除过程效率低，产生大量不连续的内存碎片，提高了垃圾回收的频率。</p></li></ul><h4 id="2-标记-整理"><a href="#2-标记-整理" class="headerlink" title="2. 标记 - 整理"></a>2. 标记 - 整理</h4><p>其中标记阶段跟标记-清除算法中的标记阶段是一样的，而对于整理阶段，它的工作就是移动所有的可达对象到堆内存的同一个区域中，使他们紧凑的排列在一起，从而将所有 <strong>非可达对象释放出来的空闲内存</strong> 都集中在一起，通过这样的方式来达到减少内存碎片的目的。</p><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C3.png" alt="3"></p><ul><li><p><strong>优点</strong>：</p><p>解决了标记-清理算法存在的内存碎片问题。</p></li><li><p><strong>缺点</strong>：</p><p>仍需要进行局部对象移动，一定程度上降低了效率。</p></li></ul><h4 id="3-复制"><a href="#3-复制" class="headerlink" title="3. 复制"></a>3. 复制</h4><p>这种收集算法解决了标记清除算法存在的效率问题。它将内存区域划分成相同的两个<strong>内存块</strong>。每次仅使用一半的空间，<code>JVM</code>生成的新对象放在一半空间中。当一半空间用完时进行<code>GC</code>，把可到达对象复制到另一半空间，然后把使用过的内存空间一次清理掉。</p><ul><li><p><strong>优点</strong>：</p><p>按顺序分配内存即可，实现简单、运行高效，不用考虑内存碎片。</p></li><li><p><strong>缺点</strong>：</p><p>可用的内存大小缩小为原来的一半，对象存活率高时会频繁进行复制。</p></li></ul><h4 id="4-分代收集"><a href="#4-分代收集" class="headerlink" title="4. 分代收集"></a>4. 分代收集</h4><p>现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。</p><p>一般将堆分为新生代和老年代。</p><ul><li>对于<strong>新生代</strong>，每次<code>GC</code>时都有<strong>大量</strong>的对象死亡，只有<strong>少量</strong>对象存活。考虑到复制成本低，适合采用<strong>复制算法</strong>。因此有了<code>From Survivor</code>和<code>To Survivor</code>区域。</li><li>对于<strong>老年代</strong>，因为对象<strong>存活率高</strong>，没有额外的内存空间对它进行担保。因而适合采用<strong>标记-清理算法</strong>和<strong>标记-整理算法</strong>进行回收。</li></ul><h3 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h3><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/JVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C4.png" alt="img"></p><p>以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。</p><ul><li>单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程；</li><li>串行与并行：串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并行指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。</li></ul><h4 id="1-Serial-收集器"><a href="#1-Serial-收集器" class="headerlink" title="1. Serial 收集器"></a>1. Serial 收集器</h4><p><img src="/2020/01/07/jvm-bi-xu-zhi-dao-de-ji-chu/D:%5CMyBlot%5Cbolt%5Csource_posts%5CJVM%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E5%9F%BA%E7%A1%80%5C5.png" alt="img"></p><p>Serial 翻译为串行，也就是说它以串行的方式执行。</p><p>它是单线程的收集器，只会使用一个线程进行垃圾收集工作。</p><p>它的优点是简单高效，在单个 CPU 环境下，由于没有线程交互的开销，因此拥有最高的单线程收集效率。</p><p>它是 Client 场景下的默认新生代收集器，因为在该场景下内存一般来说不会很大。它收集一两百兆垃圾的停顿时间可以控制在一百多毫秒以内，只要不是太频繁，这点停顿时间是可以接受的。</p><h4 id="2-ParNew-收集器"><a href="#2-ParNew-收集器" class="headerlink" title="2. ParNew 收集器"></a>2. ParNew 收集器</h4><p><a href="https://camo.githubusercontent.com/573a3abc71931daef42e0b42b1876cbe4f940cdc/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f38313533386364352d316263662d346533312d383665352d6531393864663165303133622e6a7067" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/573a3abc71931daef42e0b42b1876cbe4f940cdc/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f38313533386364352d316263662d346533312d383665352d6531393864663165303133622e6a7067" alt="img"></a></p><p>它是 Serial 收集器的多线程版本。</p><p>它是 Server 场景下默认的新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合使用。</p><h4 id="3-Parallel-Scavenge-收集器"><a href="#3-Parallel-Scavenge-收集器" class="headerlink" title="3. Parallel Scavenge 收集器"></a>3. Parallel Scavenge 收集器</h4><p>与 ParNew 一样是多线程收集器。</p><p>其它收集器目标是尽可能缩短垃圾收集时用户线程的停顿时间，而它的目标是达到一个可控制的吞吐量，因此它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户程序的时间占总时间的比值。</p><p>停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。</p><p>缩短停顿时间是以牺牲吞吐量和新生代空间来换取的：新生代空间变小，垃圾回收变得频繁，导致吞吐量下降。</p><p>可以通过一个开关参数打开 GC 自适应的调节策略（GC Ergonomics），就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 区的比例、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。</p><h4 id="4-Serial-Old-收集器"><a href="#4-Serial-Old-收集器" class="headerlink" title="4. Serial Old 收集器"></a>4. Serial Old 收集器</h4><p><a href="https://camo.githubusercontent.com/c21c58ff8ccbed6141c22c072cc175e77e7ce2e4/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30386633326664332d663733362d346136372d383163612d3239356232613739373266322e6a7067" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/c21c58ff8ccbed6141c22c072cc175e77e7ce2e4/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30386633326664332d663733362d346136372d383163612d3239356232613739373266322e6a7067" alt="img"></a></p><p>是 Serial 收集器的老年代版本，也是给 Client 场景下的虚拟机使用。如果用在 Server 场景下，它有两大用途：</p><ul><li>在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用。</li><li>作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。</li></ul><h4 id="5-Parallel-Old-收集器"><a href="#5-Parallel-Old-收集器" class="headerlink" title="5. Parallel Old 收集器"></a>5. Parallel Old 收集器</h4><p><a href="https://camo.githubusercontent.com/eca25fb0710e175458e0474e115fbb75b424fc9b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32373866653433312d616638382d346139352d613839352d3963336238303131376465332e6a7067" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/eca25fb0710e175458e0474e115fbb75b424fc9b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32373866653433312d616638382d346139352d613839352d3963336238303131376465332e6a7067" alt="img"></a></p><p>是 Parallel Scavenge 收集器的老年代版本。</p><p>在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。</p><h4 id="6-CMS-收集器"><a href="#6-CMS-收集器" class="headerlink" title="6. CMS 收集器"></a>6. CMS 收集器</h4><p><a href="https://camo.githubusercontent.com/2eb375354cc7b06ee58cbc8a1aa7b18907208d91/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f36326537373939372d363935372d346236382d386431322d6266643630396262326336382e6a7067" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/2eb375354cc7b06ee58cbc8a1aa7b18907208d91/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f36326537373939372d363935372d346236382d386431322d6266643630396262326336382e6a7067" alt="img"></a></p><p>CMS（Concurrent Mark Sweep），Mark Sweep 指的是标记 - 清除算法。</p><p>分为以下四个流程：</p><ul><li>初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。</li><li>并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。</li><li>重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。</li><li>并发清除：不需要停顿。</li></ul><p>在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。</p><p>具有以下缺点：</p><ul><li>吞吐量低：低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。</li><li>无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。</li><li>标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。</li></ul><h4 id="7-G1-收集器"><a href="#7-G1-收集器" class="headerlink" title="7. G1 收集器"></a>7. G1 收集器</h4><p>G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。</p><p>堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。</p><p><a href="https://camo.githubusercontent.com/fda0e7aec026e802533ddad8d0a6798bf77acc48/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34636637313161382d376162322d343135322d623835632d6435633232363733333830372e706e67" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/fda0e7aec026e802533ddad8d0a6798bf77acc48/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34636637313161382d376162322d343135322d623835632d6435633232363733333830372e706e67" alt="img"></a></p><p>G1 把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。</p><p><a href="https://camo.githubusercontent.com/5049da1b34969b272be2bffc6c6de0206b33253c/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f39626264646565622d653933392d343166302d386538652d3262316130616137653061372e706e67" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/5049da1b34969b272be2bffc6c6de0206b33253c/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f39626264646565622d653933392d343166302d386538652d3262316130616137653061372e706e67" alt="img"></a></p><p>通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。</p><p>每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。</p><p><a href="https://camo.githubusercontent.com/5bd72d589ead80c22547e3288a9a406241a1fb6b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f66393965653737312d633536662d343766622d393134382d6330303336363935623566652e6a7067" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/5bd72d589ead80c22547e3288a9a406241a1fb6b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f66393965653737312d633536662d343766622d393134382d6330303336363935623566652e6a7067" alt="img"></a></p><p>如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤：</p><ul><li>初始标记</li><li>并发标记</li><li>最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。</li><li>筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。</li></ul><p>具备如下特点：</p><ul><li>空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。</li><li>可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。</li></ul><h2 id="内存分配与回收策略"><a href="#内存分配与回收策略" class="headerlink" title="内存分配与回收策略"></a>内存分配与回收策略</h2><h3 id="Minor-GC-和-Full-GC"><a href="#Minor-GC-和-Full-GC" class="headerlink" title="Minor GC 和 Full GC"></a>Minor GC 和 Full GC</h3><ul><li>Minor GC：回收新生代，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。</li><li>Full GC：回收老年代和新生代，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。</li></ul><h3 id="内存分配策略"><a href="#内存分配策略" class="headerlink" title="内存分配策略"></a>内存分配策略</h3><h4 id="1-对象优先在-Eden-分配"><a href="#1-对象优先在-Eden-分配" class="headerlink" title="1. 对象优先在 Eden 分配"></a>1. 对象优先在 Eden 分配</h4><p>大多数情况下，对象在新生代 Eden 上分配，当 Eden 空间不够时，发起 Minor GC。</p><h4 id="2-大对象直接进入老年代"><a href="#2-大对象直接进入老年代" class="headerlink" title="2. 大对象直接进入老年代"></a>2. 大对象直接进入老年代</h4><p>大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。</p><p>经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。</p><p>-XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 和 Survivor 之间的大量内存复制。</p><h4 id="3-长期存活的对象进入老年代"><a href="#3-长期存活的对象进入老年代" class="headerlink" title="3. 长期存活的对象进入老年代"></a>3. 长期存活的对象进入老年代</h4><p>为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。</p><p>-XX:MaxTenuringThreshold 用来定义年龄的阈值。</p><h4 id="4-动态对象年龄判定"><a href="#4-动态对象年龄判定" class="headerlink" title="4. 动态对象年龄判定"></a>4. 动态对象年龄判定</h4><p>虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。</p><h4 id="5-空间分配担保"><a href="#5-空间分配担保" class="headerlink" title="5. 空间分配担保"></a>5. 空间分配担保</h4><p>在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。</p><p>如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。</p><h3 id="Full-GC-的触发条件"><a href="#Full-GC-的触发条件" class="headerlink" title="Full GC 的触发条件"></a>Full GC 的触发条件</h3><p>对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件：</p><h4 id="1-调用-System-gc"><a href="#1-调用-System-gc" class="headerlink" title="1. 调用 System.gc()"></a>1. 调用 System.gc()</h4><p>只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。</p><h4 id="2-老年代空间不足"><a href="#2-老年代空间不足" class="headerlink" title="2. 老年代空间不足"></a>2. 老年代空间不足</h4><p>老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。</p><p>为了避免以上原因引起的 Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。</p><h4 id="3-空间分配担保失败"><a href="#3-空间分配担保失败" class="headerlink" title="3. 空间分配担保失败"></a>3. 空间分配担保失败</h4><p>使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。具体内容请参考上面的第 5 小节。</p><h4 id="4-JDK-1-7-及以前的永久代空间不足"><a href="#4-JDK-1-7-及以前的永久代空间不足" class="headerlink" title="4. JDK 1.7 及以前的永久代空间不足"></a>4. JDK 1.7 及以前的永久代空间不足</h4><p>在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据。</p><p>当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError。</p><p>为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。</p><h4 id="5-Concurrent-Mode-Failure"><a href="#5-Concurrent-Mode-Failure" class="headerlink" title="5. Concurrent Mode Failure"></a>5. Concurrent Mode Failure</h4><p>执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>动态代理的实现方式与区别</title>
      <link href="/2020/01/06/dong-tai-dai-li-de-shi-xian-fang-shi-yu-qu-bie/"/>
      <url>/2020/01/06/dong-tai-dai-li-de-shi-xian-fang-shi-yu-qu-bie/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>java异常</title>
      <link href="/2020/01/05/java-yi-chang/"/>
      <url>/2020/01/05/java-yi-chang/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>javaWeb三大核心组件之servlet</title>
      <link href="/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/"/>
      <url>/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/</url>
      
        <content type="html"><![CDATA[<h1 id="javaWeb三大核心组件之Servlet"><a href="#javaWeb三大核心组件之Servlet" class="headerlink" title="javaWeb三大核心组件之Servlet"></a>javaWeb三大核心组件之Servlet</h1><h3 id="什么是Servlet"><a href="#什么是Servlet" class="headerlink" title="什么是Servlet"></a>什么是Servlet</h3><p>Java Servlet 是运行在 Web 服务器或应用服务器上的程序，它是作为来自 Web 浏览器或其他 HTTP 客户端的请求和 HTTP 服务器上的数据库或应用程序之间的中间层。</p><p>使用 Servlet，您可以收集来自网页表单的用户输入，呈现来自数据库或者其他源的记录，还可以动态创建网页。</p><p>Java Servlet 通常情况下与使用 CGI（Common Gateway Interface，公共网关接口）实现的程序可以达到异曲同工的效果。但是相比于 CGI，Servlet 有以下几点优势：</p><p>性能明显更好。</p><p>Servlet 在 Web 服务器的地址空间内执行。这样它就没有必要再创建一个单独的进程来处理每个客户端请求。</p><p>Servlet 是独立于平台的，因为它们是用 Java 编写的。</p><p>服务器上的 Java 安全管理器执行了一系列限制，以保护服务器计算机上的资源。因此，Servlet 是可信的。</p><p>Java 类库的全部功能对 Servlet 来说都是可用的。它可以通过 sockets 和 RMI 机制与 applets、数据库或其他软件进行交互。</p><h3 id="Tomcat与Servlet的关系"><a href="#Tomcat与Servlet的关系" class="headerlink" title="Tomcat与Servlet的关系"></a>Tomcat与Servlet的关系</h3><p>Tomcat 是Web应用服务器,是一个Servlet/JSP容器. Tomcat 作为Servlet容器,负责处理客户请求,把请求传送给Servlet,并将Servlet的响应传送回给客户.而Servlet是一种运行在支持Java语言的服务器上的组件.。</p><p>Servlet最常见的用途是扩展Java Web服务器功能,提供非常安全的,可移植的,易于使用的CGI替代品。从http协议中的请求和响应可以得知，浏览器发出的请求是一个请求文本，而浏览器接收到的也应该是一个响应文本。</p><p><img src="/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/D:%5CMyBlot%5Cbolt%5Csource_posts%5CjavaWeb%E4%B8%89%E5%A4%A7%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E4%B9%8Bservlet%5C1" alt="image"></p><ol><li>Tomcat将http请求文本接收并解析，然后封装成HttpServletRequest类型的request对象，所有的HTTP头数据读可以通过request对象调用对应的方法查询到。</li><li>Tomcat同时会要响应的信息封装为HttpServletResponse类型的response对象，通过设置response属性就可以控制要输出到浏览器的内容，然后将response交给tomcat，tomcat就会将其变成响应文本的格式发送给浏览器。</li></ol><p>Java Servlet API 是Servlet容器(tomcat)和servlet之间的接口，它定义了serlvet的各种方法，还定义了Servlet容器传送给Servlet的对象类，其中最重要的就是ServletRequest和ServletResponse。所以说我们在编写servlet时，需要实现Servlet接口，按照其规范进行操作。</p><h3 id="Servlet执行过程"><a href="#Servlet执行过程" class="headerlink" title="Servlet执行过程"></a>Servlet执行过程</h3><p> 在浏览器的地址栏输入：<a href="http://ip" target="_blank" rel="noopener">http://ip</a>:port/appNames/servlet</p><p>  1）通过浏览器和ip：port和这个服务器建立连接。<br>  2） 浏览器会生成一个请求数据包（路径appNames/servlet）向服务器发送请求。<br>  3） 服务器收到请求数据包，分析请求资源路径做精准定位，通过请求的appName查找webapps文件下面的appName做匹配，匹配上了需要获取web.xml中的servlet(mapping)。 <br>  4） 服务器创建两个对象：<br>    第一个对象：请求对象，该对象实现了HttpServletRequest接口，服务器会将请求数据包中的数据解析出来,存储在该对象里。这样做的好处是没有必要理解http协议，只需要读取request。<br>    第二个对象：响应对象，实现了HttpServletResponse接口，作用是servlet处理完成后的结果可以存放到该对象上，然后服务器依据该对象的数据生成响应数据包。<br>  5） servlet在执行servlet()方法时，可以通过request获取请求数据，也可以将处理结果存放到response上。然后服务器与响应对象直接形成一个默契，生成一个响应数据包给浏览器。<br>  6）浏览器解析服务器返回的响应数据包，生成响应的结果。</p><p>  </p><p><img src="/2020/01/04/javaweb-san-da-he-xin-zu-jian-zhi-servlet/D:%5CMyBlot%5Cbolt%5Csource_posts%5CjavaWeb%E4%B8%89%E5%A4%A7%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E4%B9%8Bservlet%5C2.png" alt="image"></p><p>Servlet访问的过程：<br>Http请求—-&gt;web.xml——–&gt;  url -pattern—–&gt;servlet-name—–&gt;servlet-class—–&gt;   QuickStratServlet(对应的Class文件)</p><h3 id="Servlet生命周期"><a href="#Servlet生命周期" class="headerlink" title="Servlet生命周期"></a>Servlet生命周期</h3><p>SpringMVC是基于servlet，控制器基于方法级别的拦截，处理器设计为单实例，所以应该了解一下Servlet的生命周期。</p><p>Servlet 加载—&gt;实例化—&gt;服务—&gt;销毁。</p><p><strong>init</strong>（）：</p><p>在Servlet的生命周期中，仅执行一次init()方法。它是在服务器装入Servlet时执行的，负责初始化Servlet对象。可以配置服务器，以在启动服务器或客户机首次访问Servlet时装入Servlet。无论有多少客户机访问Servlet，都不会重复执行init（）。</p><p><strong>service</strong>（）：</p><p>它是Servlet的核心，负责响应客户的请求。每当一个客户请求一个HttpServlet对象，该对象的Service()方法就要调用，而且传递给这个方法一个“请求”（ServletRequest）对象和一个“响应”（ServletResponse）对象作为参数。在HttpServlet中已存在Service()方法。默认的服务功能是调用与HTTP请求的方法相应的do功能。</p><p><strong>destroy</strong>（）：</p><p>仅执行一次，在服务器端停止且卸载Servlet时执行该方法。当Servlet对象退出生命周期时，负责释放占用的资源。一个Servlet在运行service()方法时可能会产生其他的线程，因此需要确认在调用destroy()方法时，这些线程已经终止或完成。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>SpringMVC原理</title>
      <link href="/2020/01/04/springmvc-yuan-li/"/>
      <url>/2020/01/04/springmvc-yuan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><a href="http://lib.csdn.net/base/javaee" target="_blank" rel="noopener">spring</a> MVC主要由DispatcherServlet、处理器映射、处理器(控制器)、视图解析器、视图组成。他的两个核心是两个核心：</p><p><strong>处理器映射：</strong> 选择使用哪个控制器来处理请求。<br><strong>视图解析器：</strong> 选择结果应该如何渲染。</p><h2 id="运行原理"><a href="#运行原理" class="headerlink" title="运行原理"></a>运行原理</h2><p>下图是在Spring官网开发手册上找到的，它清晰的诠释了Spring MVC的运行原理</p><p><img src="/2020/01/04/springmvc-yuan-li/D:%5CMyBlot%5Cbolt%5Csource_posts%5CSpringMVC%E5%8E%9F%E7%90%86%5C16b5eb3870589ac4.png" alt="16b5eb3870589ac4"></p><p>①客户端的所有请求都交给前端控制器DispatcherServlet来处理，它会负责调用系统的其他模块来真正处理用户的请求。</p><p>② DispatcherServlet收到请求后，将根据请求的信息（包括URL、HTTP协议方法、请求头、请求参数、Cookie等）以及HandlerMapping的配置找到处理该请求的Handler（任何一个对象都可以作为请求的Handler）。</p><p>③在这个地方Spring会通过HandlerAdapter对该处理器进行封装。</p><p>④ HandlerAdapter是一个适配器，它用统一的接口对各种Handler中的方法进行调用。</p><p>⑤ Handler完成对用户请求的处理后，会返回一个ModelAndView对象给DispatcherServlet，ModelAndView顾名思义，包含了数据模型以及相应的视图的信息。</p><p>⑥ ModelAndView的视图是逻辑视图，DispatcherServlet还要借助ViewResolver完成从逻辑视图到真实视图对象的解析工作。⑦ 当得到真正的视图对象后，DispatcherServlet会利用视图对象对模型数据进行渲染。</p><p>⑧ 客户端得到响应，可能是一个普通的HTML页面，也可以是XML或JSON字符串，还可以是一张图片或者一个PDF文件。</p><p><img src="/2020/01/04/springmvc-yuan-li/D:%5CMyBlot%5Cbolt%5Csource_posts%5CSpringMVC%E5%8E%9F%E7%90%86%5C16b5eb3870589ac4.png" alt="16b5eb3870589ac4"></p><h2 id="接口的解释"><a href="#接口的解释" class="headerlink" title="接口的解释"></a>接口的解释</h2><table><thead><tr><th>接口名称</th><th>功能</th></tr></thead><tbody><tr><td>DispatcherServlet</td><td>Spring提供的前端控制器，客户端的所有请求都由DispatcherServlet负责分发，当然在DispatcherServlet分发之前，还需要一个匹配请求的过程，这个由HandlerMapping来完成。</td></tr><tr><td>HandlerMapping</td><td>完成客户端请求到Controller映射的工作</td></tr><tr><td>Controller</td><td>用于处理用户请求，返回处理结果</td></tr><tr><td>ViewResolver</td><td>Web应用中查找View对象，从而将相应结果渲染给客户端</td></tr></tbody></table><h2 id="DispatcherServlet："><a href="#DispatcherServlet：" class="headerlink" title="DispatcherServlet："></a>DispatcherServlet：</h2><p>是整个Spring MVC的核心。它负责接收HTTP请求组织协调Spring MVC的各个组成部分。</p><p>其主要工作有以下三项：</p><ol><li>截获符合特定格式的URL请求。</li><li>初始化DispatcherServlet上下文对应WebApplicationContext，并将其与业务层、持久化层的WebApplicationContext建立关联。</li><li>初始化Spring MVC的各个组成组件，并装配到DispatcherServlet中。</li></ol><h2 id="一个比较好理解的Spring-mvc原理图"><a href="#一个比较好理解的Spring-mvc原理图" class="headerlink" title="一个比较好理解的Spring mvc原理图"></a>一个比较好理解的Spring mvc原理图</h2><p><img src="/2020/01/04/springmvc-yuan-li/D:%5CMyBlot%5Cbolt%5Csource_posts%5CSpringMVC%E5%8E%9F%E7%90%86%5Cb856096cf065baaaabe5884deb4ecfa3.png" alt="b856096cf065baaaabe5884deb4ecfa3"></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>回头再看spring</title>
      <link href="/2020/01/04/hui-tou-zai-kan-spring/"/>
      <url>/2020/01/04/hui-tou-zai-kan-spring/</url>
      
        <content type="html"><![CDATA[<h2 id="回头再看Spring"><a href="#回头再看Spring" class="headerlink" title="回头再看Spring"></a>回头再看Spring</h2><h3 id="什么是Spring"><a href="#什么是Spring" class="headerlink" title="什么是Spring"></a>什么是Spring</h3><p>Spring是个包含一系列功能的合集，如快速构建微服务的Spring Boot，管理一系列微服务的Spring Cloud，支持认证与鉴权的Spring Security，基于MVC的Web框架Spring MVC。但IOC与AOP依然是核心。</p><h3 id="Spring-Bean"><a href="#Spring-Bean" class="headerlink" title="Spring Bean"></a>Spring Bean</h3><p><strong>IOC的底层原理：文档解析xml文件，反射动态创建对象，然后保存name和Object，然后对每个对象属性进行属性注入</strong></p><h5 id="加载Bean的主要逻辑"><a href="#加载Bean的主要逻辑" class="headerlink" title="加载Bean的主要逻辑"></a>加载Bean的主要逻辑</h5><p>​    1.获取配置文件资源</p><p>​    2.对获取的xml资源进行一定的处理检验</p><p>​    3.处理包装资源</p><p>​    4.解析处理包装过后的资源</p><p>​    5.加载提取bean并注册(添加到beanDefinitionMap中</p><h5 id="Bean的生命周期"><a href="#Bean的生命周期" class="headerlink" title="Bean的生命周期"></a>Bean的生命周期</h5><ul><li>Bean的建立，由BeanFactory读取Bean定义文件，并创建Bean实例；</li><li>执行Bean的属性注入,Setter注入；</li><li>如果Bean类实现了org.springframework.beans.factory.BeanNameAware接口,则执行其setBeanName方法；</li><li>如果Bean类实现了org.springframework.beans.factory.BeanFactoryAware接口,则执行其setBeanFactory方法；</li><li>如果容器中有实现org.springframework.beans.factory.BeanPostProcessors接口的实例，则任何Bean在初始化之前都会执行这个实例的processBeforeInitialization()方法；</li><li>如果Bean类实现了org.springframework.beans.factory.InitializingBean接口，则执行其afterPropertiesSet()方法；</li><li>调用Bean的初始化方法”init-method” (！！注意，init-method方法没有参数)；</li><li>如果容器中有实现org.springframework.beans.factory.BeanPostProcessors接口的实例，则任何Bean在初始化之后都会执行这个实例的processAfterInitialization()方法；</li><li>使用Bean做一些业务逻辑….</li><li>使用完，容器关闭，如果Bean类实现了org.springframework.beans.factory.DisposableBean接口，则执行它的destroy()方法；</li><li>在容器关闭时，可以在Bean定义文件中使用“destory-method”定义的方法，销毁Bean (！！注意，destory-method方法没有参数)；</li></ul><h5 id="Bean的作用域"><a href="#Bean的作用域" class="headerlink" title="Bean的作用域"></a>Bean的作用域</h5><ul><li>Singleton: 这是默认的作用域，这种范围确保不管接受多少个请求，每个容器中只有一个bean的实例，单例模式有BeanFactory自身维护；</li><li>Prototype: 原形范围与单例范围相反，为每一个bean请求提供一个实例；</li></ul><ul><li>Request: 在请求bean范围内会为每一个来自客户端的网络请求创建一个实例，在请求完成以后，bean会失效并被垃圾回收器回收；</li><li>Session: 与请求范围类似，确保每个session中有一个bean的实例，在session过期后，bean会随之失效；</li><li>global-session: global-session和Portlet应用相关。当你的应用部署在Portlet容器中工作时，它包含很多portlet。如果你想要声明让所有的portlet共用全局的存储变量的话，那么这全局变量需要存储在global-session中。</li></ul><h3 id="Spring-IOC"><a href="#Spring-IOC" class="headerlink" title="Spring IOC"></a>Spring IOC</h3><p>IOC(控制反转):本质就是自己的信息(全类名等)配置在文件中或者加上注解,让容器可以通过反射的方式来创建对象,从而接管对象,代替了自己通过new创建对象.其实就是讲对象的管理创建交给了容器来做.</p><p>依赖注入:在运行过程中,会在需要这个对象的位置坐上一个标记,容器会负责创建对象实例并注入其中;</p><h4 id="Spring-IOC容器的初始化过程"><a href="#Spring-IOC容器的初始化过程" class="headerlink" title="Spring IOC容器的初始化过程"></a>Spring IOC容器的初始化过程</h4><p>IoC容器的初始化就是含有BeanDefinition信息的Resource的定位、载入、解析、注册四个过程，最终我们配置的bean，以beanDefinition的数据结构存在于IoC容器即内存中。</p><h5 id="Resource定位过程"><a href="#Resource定位过程" class="headerlink" title="Resource定位过程"></a>Resource定位过程</h5><p>这个Resource定位指的是BeanDefinition的资源定位，它由ResourceLoader通过统一的Resource接口来完成，这个Resource对各种形式的BeanDefinition的使用提供了统一接口。</p><h5 id="BeanDefinition的载入"><a href="#BeanDefinition的载入" class="headerlink" title="BeanDefinition的载入"></a>BeanDefinition的载入</h5><p>该载入过程把用户定义好的Bean表示成IoC容器内部的数据结构，而这个容器内部的数据结构就BeanDefinition.</p><h5 id="向IoC容器注册这些BeanDefinition"><a href="#向IoC容器注册这些BeanDefinition" class="headerlink" title="向IoC容器注册这些BeanDefinition"></a>向IoC容器注册这些BeanDefinition</h5><p>这个过程是通过调用BeanDefinitionRegistry接口的实现来完成的，这个注册过程把载入过程中解析得到的BeanDefinition向IoC容器进行注册,在IoC容器内部将BeanDefinition注入到一个HashMap中去，Ioc容器是通过这个HashMap来持有这些BeanDefinition数据的。</p><p>容器的初始化是通过AbstractApplicationContext的refresh()实现的。</p><pre><code></code></pre><p>整个过程如下图:</p><p><img src="/2020/01/04/hui-tou-zai-kan-spring/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E5%9B%9E%E5%A4%B4%E5%86%8D%E7%9C%8Bspring%5C1.png" alt="img"></p><h3 id="Spring-AOP"><a href="#Spring-AOP" class="headerlink" title="Spring AOP"></a>Spring AOP</h3><p>面向切面的编程，是一种编程技术，<strong>是OOP（面向对象编程）的补充和完善</strong>。OOP的执行是一种从上往下的流程，并没有从左到右的关系。因此在OOP编程中，会有大量的重复代码。而<strong>AOP则是将这些与业务无关的重复代码抽取出来，然后再嵌入到业务代码当中</strong>。常见的应用有：权限管理、日志、事务管理等。</p><p>AOP有三种植入切面的方法：其一是编译期织入，这要求使用特殊的Java编译器，AspectJ是其中的代表者；其二是类装载期织入，而这要求使用特殊的类装载器，AspectJ和AspectWerkz是其中的代表者；其三为动态代理织入，在运行期为目标类添加增强生成子类的方式，<strong>Spring AOP采用动态代理织入切面</strong>。</p><p>AspectJ是静态代理的增强，所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强。</p><p>它会在<strong>编译阶段</strong>将Aspect织入Java字节码中， 运行的时候就是经过增强之后的AOP对象。</p><p>AspectJ在编译时就增强了目标对象，Spring AOP的动态代理则是在每次运行时动态的增强，生成AOP代理对象，区别在于生成AOP代理对象的时机不同，相对来说<strong>AspectJ的静态代理方式具有更好的性能</strong>，但是AspectJ<strong>需要特定的编译器</strong>进行处理，而Spring AOP则无需特定的编译器处理。</p><p>Spring AOP中的动态代理主要有两种方式，<strong>JDK动态代理</strong>和<strong>CGLIB动态代理</strong>。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。<strong>JDK动态代理的核心是InvocationHandler接口和Proxy类</strong>。</p><p>如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态地生成某个类的子类，注意，<strong>CGLIB是通过继承的方式做的动态代理</strong>，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的</p><h4 id="jDK代理"><a href="#jDK代理" class="headerlink" title="jDK代理"></a>jDK代理</h4><p> JDK的动态代理主要涉及到java.lang.reflect包中的两个类：Proxy和InvocationHandler。其中 InvocationHandler是一个接口就是拦截器的接口。，可以通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态将横切逻辑和业务逻辑编织在一起。</p><h5 id="InvocationHandler的作用"><a href="#InvocationHandler的作用" class="headerlink" title="InvocationHandler的作用"></a>InvocationHandler的作用</h5><p>在动态代理中InvocationHandler是核心，每个代理实例都具有一个关联的调用处理程序(InvocationHandler)。对代理实例调用方法时，将对方法调用进行编码并将其指派到它的调用处理程序(InvocationHandler)的 invoke 方法。所以对代理方法的调用都是通InvocationHadler的invoke来实现中，而invoke方法根据传入的代理对象，方法和参数来决定调用代理的哪个方法</p><h5 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h5><p>使用代理模式必须要让代理类和目标类实现相同的接口，客户端通过代理类来调用目标方法，代理类会将所有的方法调用分派到目标对象上反射执行，还可以在分派过程中添加”前置通知”和后置处理（如在调用目标方法前校验权限，在调用完目标方法后打印日志等）等功能。</p><p>具体有如下四步骤：</p><p>1.通过实现 InvocationHandler 接口创建自己的调用处理器；</p><p>2.通过为 Proxy 类指定 ClassLoader 对象和一组 interface 来创建动态代理类；</p><p>3.通过反射机制获得动态代理类的构造函数，其唯一参数类型是调用处理器接口类型；</p><p>4.通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数被传入。</p><p><img src="/2020/01/04/hui-tou-zai-kan-spring/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E5%9B%9E%E5%A4%B4%E5%86%8D%E7%9C%8Bspring%5Cclipboard.png" alt="clipboard"></p><h4 id="利用cglib代理实现AOP"><a href="#利用cglib代理实现AOP" class="headerlink" title="利用cglib代理实现AOP"></a>利用cglib代理实现AOP</h4><p>CGlib是一个强大的,高性能,高质量的Code生成类库。cglib封装了asm，可以在运行期动态生成新的class，它可以在运行期扩展Java类与实现Java接口。 CGLIB是<strong>针对类实现代理</strong>的，主要对指定的类生成一个子类，并覆盖其中的方法， 因为是继承，所以不能使用final来修饰类或方法。和jdk代理实现不同的是，cglib不要求类实现接口。</p><p>JDK动态代理和CGLIB字节码生成的区别？</p><p>CGLib所创建的动态代理对象的性能比JDK的高大概10倍，但CGLib在创建代理对象的时间比JDK大概多8倍，所以对于singleton的代理对象或者具有实例池的代理，因为无需重复的创建代理对象，所以比较适合CGLib动态代理技术，反之选择JDK代理</p><ul><li><p>JDK动态代理只能对实现了接口的类生成代理，而不能针对类</p></li><li><p>CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法</p><p>因为是继承，所以该类或方法最好不要声明成final </p></li></ul><p>1、如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP</p><p>2、如果目标对象实现了接口，可以强制使用CGLIB实现AOP</p><p>3、如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>理解KMP回溯</title>
      <link href="/2020/01/03/li-jie-kmp-hui-su/"/>
      <url>/2020/01/03/li-jie-kmp-hui-su/</url>
      
        <content type="html"><![CDATA[<h4 id="理解KMP回溯"><a href="#理解KMP回溯" class="headerlink" title="理解KMP回溯"></a>理解KMP回溯</h4><p>相信大家都看过KMP算法，但是对于它的回溯确是难以理解。我们先来看一下KMP中的next数组生成代码：</p><pre><code>    //用于生成next数组    private static int[] get_next(String target){        int[] next = new int[target.length()];        next[0] = -1;        int i = 0, j = -1;        while(i &lt; target.length() - 1){            if (j == -1 || target.charAt(i) == target.charAt(j)) {                ++i;                ++j;                next[i] = j;            } else {                j = next[j];            }        }        return next;    }</code></pre><ul><li>其中数组的next中的值计算方式是：</li></ul><p>next[j] = Max{k | 1&lt;k&lt;j,且‘p1p2…pk’=‘p(j-k)…p(j - 1)’}</p><ul><li><h5 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h5></li></ul><p><em>简单来说next[j]表示的就是两个相等的字符串的长度，这两个字符串分别是从头开始记的长度为next[j]的和以next[j]的前一个字符结尾的长度为next[j]。</em></p><ul><li><h5 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h5></li></ul><p>例如：字符串”ababaaaba” next = [-1,0,0,1,2,3,1,1,2]<br>其中的回溯环节就是从next[5] = 3 到 next[6] = 1;</p><p>其中next[5]时：是”ababa”中前缀”aba”与后缀”aba”的长度，当i = 6时，”ababaa”中”a”不等于”b”,所以回溯到j = next[j],其中j为现在next[5]的值。</p><ul><li><h5 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h5></li></ul><p><strong>我开始也是很不明白为什么就可以直接回到j = next[next[5]] = 0处开始向后比较，后来仔细研究发现原因是，通过前面的比较它已经排除了所有的前缀字符串等于后缀字符串的长度大于回溯到当前j的可能 。</strong><br>就拿上面的“ababa”到“ababaa”举例：<br>其实我们想不通的无非就是它是怎么排除“aba”!=”baa”转而直接去判断前缀“ab”是否等于后缀“aa”,后来我仔细分析才发现因为如果前面的“aba” = “baa”要成立，必须有“前缀ab”等于后缀“ba”,而得到next[5]=3的时候已经隐式的得到的第一个“ba”等于第二个“ba”(当时是“aba” = “aba”)<br>从而有“aba”中三个值都应该相等，与前面矛盾。可能你早就看不懂我在说什么了，来一点数学表达式比较实际：</p><ul><li><h5 id="数学证明"><a href="#数学证明" class="headerlink" title="数学证明"></a>数学证明</h5></li></ul><p>②开始有p1p2….pj = pi - j ….pi-1，可以得出pj = pj-1  j = 1,2,…<br>假设 next[j] = k 就有 p1p2…pk = pj-k …pj-1    k = 1,2…<br>若加入pi != pj + 1,则需要回溯到判断pk 是否等于pj;<br>首先证明：pi-j+1…pi ！= p1p2…pj,反证：假设：pi-j+1…pi = p1p2…p，又p1p2….pj = pi - j ….pi-1<br>所以有pi - j ….pi-1 =pi-j+1…pi ,得到pi-j=pi-j+1=…=pi;与前面矛盾，所以有pi-j+1…pi ！= p1p2…pj<br>同理可以得出pi-j+2…pi ！= p1p2…pj-1  。。。。。pi-j+k…pi ！= p1p2…pj-k+1  。。。。。<br>所以可以直接回溯到j = next[j]继续向后判断</p><p>KMP完整代码</p><pre><code>    private static int[] get_next(String target){        int[] next = new int[target.length()];        next[0] = -1;        int i = 0, j = -1;        while(i &lt; target.length() - 1){            if (j == -1 || target.charAt(i) == target.charAt(j)) {                ++i;                ++j;                next[i] = j;            } else {                j = next[j];            }        }        return next;    }    int kmp(String s, String pattern) {        int i = 0,j = 0;        int slen = s.length(), plen = pattern.length();        int[] next = get_next(pattern);        while (i &lt; slen &amp;&amp; j &lt; plen) {            if (s.charAt(i) == pattern.charAt(j)) {                i++;                j++;            } else {                if (next[j] == -1) {                    i++;                    j = 0;                } else {                    j = next[j];                }            }            if (j == plen) {                return i - j;            }        }        return -1;    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>使用VMware安装linux虚拟机</title>
      <link href="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/"/>
      <url>/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=552192975&auto=0&height=66"></iframe></div><h1 id="使用VMware安装linux虚拟机"><a href="#使用VMware安装linux虚拟机" class="headerlink" title="使用VMware安装linux虚拟机"></a>使用VMware安装linux虚拟机</h1><h3 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h3><p><em>Linux是一种自由和开放源码的操作系统，存在着许多不同的Linux发行版本，但它们都使用了Linux内核。现在的服务器基本都是使用linux,其中CentOS使用广泛,还有ubuntu也是linux中的佼佼者.业内也说,凡是<strong>java开发,不懂linux均是扯淡.</strong>本文主要为后面搭建基于Hadoop集群的大数据大数据平台打下基础。</em></p><h4 id="linux具有如下优点"><a href="#linux具有如下优点" class="headerlink" title="linux具有如下优点"></a>linux具有如下优点</h4><ul><li>开源</li><li>多用户，多任务，丰富的网络功能，可靠的系统安全，良好的可移植性，具有标准兼容性</li><li>良好的用户界面，出色的速度性能</li><li>服务器不使用图形化界面(图形界面占用资源)</li><li>机房部署方便，无需配置操作界面</li></ul><p><strong>下载地址</strong><a href="http://www.centos.org/" target="_blank" rel="noopener">:http://www.centos.org/</a></p><h3 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h3><ul><li>Windows10</li><li>VMware Workstation12</li><li>CentOS7</li></ul><h4 id="VMware-Workstation12安装"><a href="#VMware-Workstation12安装" class="headerlink" title="VMware Workstation12安装"></a>VMware Workstation12安装</h4><p>①双击VMware-workstation-full-版本号.exe</p><p>②点击next</p><p>③选择Typical(你要是想自己配置也可以选custom 不推荐)</p><p>④选择安装目录</p><p>⑤想检查升级就勾上(check for product updates on startup),否则直接下一步</p><p>⑥选择创建快捷方式的位置,然后下一步</p><p>⑦点击continue完成</p><p>⑧Finish完成</p><p><strong>注意:如果你不熟悉就按部就班来,不要有什么骚操作,我记得我开始安装的时候禁用了哪两个网卡,后来哪两个网卡找不到了,我就把这个卸载了重新装,还是不行,这个问题的解决还是因为我一个月后重装了电脑</strong></p><h4 id="CentOS7安装"><a href="#CentOS7安装" class="headerlink" title="CentOS7安装"></a>CentOS7安装</h4><p>①安装VMware Workstation</p><p>②打开VM,点击创建新的虚拟机</p><p>③选择 典型（推荐）→ 下一步 </p><p>④选择稍后安装操作系统再点击下一步</p><p>⑤选择操作系统和版本(linux 64)</p><p>⑥输入虚拟机名称和安装路径</p><p>⑦设置磁盘大小并选中将虚拟磁盘拆成多个文件</p><p>⑧自定义硬件</p><p>⑨选择CentOS安装镜像文件</p><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577631145598.png" alt="1577631145598"></p><p>⑩开机启动后选择Install CentOS 7并enter</p><ul><li>弹出如下图形化的安装界面：</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat.png" alt="img"></p><ul><li>日期和时间：</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat1.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat2.png" alt="img"></p><ul><li>如果你安装的是英文版，需要将时区改为上海。</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat3.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat4.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126014938900.png" alt="img"></p><ul><li><strong>网络和主机名</strong></li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126015037602.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126015051216.png" alt="img"></p><ul><li>然后选择开始安装**</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat7.png" alt="img">基本的系统就安装好了</p><h3 id="配置网络"><a href="#配置网络" class="headerlink" title="配置网络"></a>配置网络</h3><ul><li>linu有三种网络模式,分别是Host-Only、NAT、桥接。一般安装好以后会默认选择NAT。</li></ul><ul><li>进入之后修改ip地址信息</li></ul><pre><code>vi /etc/ sysconfig/network-scripts/ifcfg-eth0DEVICE=eth0 #网卡名称HWADDR=08:00:27:8E:9D:25 #MAC地址TYPE=Ethernet #网络类型,这里是以太网UUID=5f2d815e-bd3b-4995-9009-823542e77304ONBOOT=yes NM_CONTROLLED=yesBOOTPROTO=staticSTATIC=trueIPADDR=192.168.1.21 #ip地址NETMASK=255.255.255.0 #子网掩码GATEWAY=192.168.1.1 #网管DNS1=202.202.0.33 #域名解析地址DNS2=114.114.114.114DNS3=8.8.8.8</code></pre><ul><li>配置好以后重启网络服务</li></ul><pre><code>services network restart</code></pre><ul><li>ifconfig查看IP地址</li></ul><pre><code>ifconfigeth0      Link encap:Ethernet  HWaddr 08:00:27:8E:9D:25            inet addr:192.168.1.21  Bcast:192.168.1.255  Mask:255.255.255.0          inet6 addr: fe80::a00:27ff:fe8e:9d25/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:1756623 errors:0 dropped:0 overruns:0 frame:0          TX packets:1952463 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000           RX bytes:1445482120 (1.3 GiB)  TX bytes:1626059931 (1.5 GiB)lo        Link encap:Local Loopback            inet addr:127.0.0.1  Mask:255.0.0.0          inet6 addr: ::1/128 Scope:Host          UP LOOPBACK RUNNING  MTU:65536  Metric:1          RX packets:2258 errors:0 dropped:0 overruns:0 frame:0          TX packets:2258 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0           RX bytes:590708 (576.8 KiB)  TX bytes:590708 (576.8 KiB)</code></pre><ul><li>ping ip地址测试网络是否配置好</li></ul><pre><code>ping www.baidu.com</code></pre><p><strong>按照以上操作完成安装以后可以直接克隆改虚拟机，然后修改配置就可以生成多台</strong></p><p><strong>在每个主机的/etc/hosts文件设置上每个主机的ip和名字的映射关系</strong></p><pre><code>vi /etc/hosts192.168.1.21 master192.168.1.23 slave1192.168.1.24 slave2192.168.1.25 slave3</code></pre><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577691474359.png" alt="1577691474359"></p><h4 id="配置免密登录"><a href="#配置免密登录" class="headerlink" title="配置免密登录"></a>配置免密登录</h4><ul><li>主要用于两个机器之间相互登录不需要验证</li></ul><p>①在第一台机器使用命令ssh-keygen -t rsa生成私钥和秘钥</p><pre><code>ssh-keygen -t rsa</code></pre><p>②复制到另一台机器</p><pre><code>ssh-copy-id root@slave1</code></pre><p><strong>如此就可以实现slave登录master免密,按照这个做法,每两台机器都配置上。</strong></p><h5 id="科普：免密登录原理"><a href="#科普：免密登录原理" class="headerlink" title="科普：免密登录原理"></a>科普：免密登录原理</h5><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577692561419.png" alt="1577692561419"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>hexo博文包含图片的坑</title>
      <link href="/2019/12/29/hexo-bo-wen-bao-han-tu-pian-de-keng/"/>
      <url>/2019/12/29/hexo-bo-wen-bao-han-tu-pian-de-keng/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=414414&auto=0&height=66"></iframe></div><h1 id="hexo博文包含图片的坑"><a href="#hexo博文包含图片的坑" class="headerlink" title="hexo博文包含图片的坑"></a>hexo博文包含图片的坑</h1><h3 id="网上有很多关于这个的教程-主要的总结如下"><a href="#网上有很多关于这个的教程-主要的总结如下" class="headerlink" title="网上有很多关于这个的教程,主要的总结如下"></a>网上有很多关于这个的教程,主要的总结如下</h3><ul><li>①修改博客目录下的_config_yml的post_asset_folder为true</li></ul><pre class="line-numbers language-java"><code class="language-java">post_asset_folder<span class="token operator">:</span> <span class="token boolean">true</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>②安装hexo-asset-image插件</li></ul><pre><code>npm install hexo-asset-image --save</code></pre><ul><li>③hexo new  file_name 时会在source/_post/下生成file_name的文件夹,将需要使用的图片放置在里面,然后使用相对路径引入</li></ul><pre><code>![用于图片加载失败时显示的内容](/file_name/image_name)</code></pre><ul><li>如此博客中的图片最后会和.md文件一起生成到public\2019\12\27\file_name中,这样在hexe g 时,可以看到命令窗口会打印修改后的路径,如下</li></ul><pre><code>Start processingupdate link as:--&gt;/2019/12/27/first/1577523021175.pngupdate link as:--&gt;/2019/12/27/first/1577523021175.png</code></pre><h3 id="我遇到的问题"><a href="#我遇到的问题" class="headerlink" title="我遇到的问题"></a>我遇到的问题</h3><pre><code>Start processingupdate link as:--&gt;.io//2019/12/27/first/1577523021175.pngupdate link as:--&gt;.io//2019/12/27/first/1577523021175.png</code></pre><ul><li>经过一番搜寻,发现hexo-asset-image会将图片的地址修改,具体的源码信息可见\node_modules\hexo-asset-image\index.js,打开后内容如下:</li></ul><pre><code>&#39;use strict&#39;;var cheerio = require(&#39;cheerio&#39;);function getPosition(str, m, i) {  return str.split(m, i).join(m).length;}hexo.extend.filter.register(&#39;after_post_render&#39;, function(data){  var config = hexo.config;  if(config.post_asset_folder){    var link = data.permalink;    var beginPos = getPosition(link, &#39;/&#39;, 3) + 1;    var appendLink = &#39;&#39;;    // In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;.    // if not with index.html endpos = link.lastIndexOf(&#39;.&#39;) + 1 support hexo-abbrlink    if(/.*\/index\.html$/.test(link)) {      // when permalink is end with index.html, for example 2019/02/20/xxtitle/index.html      // image in xxtitle/ will go to xxtitle/index/      appendLink = &#39;index/&#39;;      var endPos = link.lastIndexOf(&#39;/&#39;);    }    else {      var endPos = link.lastIndexOf(&#39;.&#39;) ;    }    link = link.substring(beginPos, endPos) + &#39;/&#39; + appendLink;    var toprocess = [&#39;excerpt&#39;, &#39;more&#39;, &#39;content&#39;];    for(var i = 0; i &lt; toprocess.length; i++){      var key = toprocess[i];      var $ = cheerio.load(data[key], {        ignoreWhitespace: false,        xmlMode: false,        lowerCaseTags: false,        decodeEntities: false      });      $(&#39;img&#39;).each(function(){        if ($(this).attr(&#39;src&#39;)){          // For windows style path, we replace &#39;\&#39; to &#39;/&#39;.          var src = $(this).attr(&#39;src&#39;).replace(&#39;\\&#39;, &#39;/&#39;);          if(!(/http[s]*.*|\/\/.*/.test(src)            || /^\s+\//.test(src)            || /^\s*\/uploads|images\//.test(src))) {            // For &quot;about&quot; page, the first part of &quot;src&quot; can&#39;t be removed.            // In addition, to support multi-level local directory.            var linkArray = link.split(&#39;/&#39;).filter(function(elem){              return elem != &#39;&#39;;            });            var srcArray = src.split(&#39;/&#39;).filter(function(elem){              return elem != &#39;&#39; &amp;&amp; elem != &#39;.&#39;;            });            if(srcArray.length &gt; 1)            srcArray.shift();            src = srcArray.join(&#39;/&#39;);            $(this).attr(&#39;src&#39;, config.root + link + src);            console.info&amp;&amp;console.info(&quot;update link as:--&gt;&quot;+config.root + link + src);          }        }else{          console.info&amp;&amp;console.info(&quot;no src attr, skipped...&quot;);          console.info&amp;&amp;console.info($(this));        }      });      data[key] = $.html();    }  }});</code></pre><ul><li>通过查看源码发现里面有对生成博客图片的地址修改:</li></ul><pre><code>link = link.substring(beginPos, endPos) + &#39;/&#39; + appendLink;</code></pre><ul><li>通过排查发现图片的路径的endPos为:</li></ul><pre><code>var endPos = link.lastIndexOf(&#39;.&#39;) ;</code></pre><ul><li>我打印data.permalink得到</li></ul><pre><code>http://tigerLuHai.github.io/2019/12/27/first/</code></pre><p>如此在截取字符串的时候就会多出四个字符  <strong>.io/</strong></p><p>最后发现这段代码的作用就是要将data.permalink中路径的<a href="https://tigerLuhai.gituhub.io/去掉,因为在后面部署到github时使用相对路径访问会重新加上这个前缀,如果这里有就会重复,导致地址为https://tigerLuhai.gituhub.io/http://tigerLuHai.github.io/2019/12/27/first/的现象" target="_blank" rel="noopener">https://tigerLuhai.gituhub.io/去掉,因为在后面部署到github时使用相对路径访问会重新加上这个前缀,如果这里有就会重复,导致地址为https://tigerLuhai.gituhub.io/http://tigerLuHai.github.io/2019/12/27/first/的现象</a>.</p><p>明白了需求就可以修改代码为</p><pre><code>var endPos = link.lastIndexOf(&#39;/&#39;) ;</code></pre><p>这样就可以正常部署了.</p>]]></content>
      
      
      <categories>
          
          <category> tool </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>FastDFS分布式文件系统安装使用教程</title>
      <link href="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/"/>
      <url>/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=479553545&auto=1&height=66"></iframe></div><h1 id="FastDFS分布式文件系统安装使用教程"><a href="#FastDFS分布式文件系统安装使用教程" class="headerlink" title="FastDFS分布式文件系统安装使用教程"></a>FastDFS分布式文件系统安装使用教程</h1><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><p>分布式文件系统用于<strong>海量</strong>文件存储及传输访问的瓶颈问题，对海量视频的管理、对<strong>海量</strong>图片的管理等,FastDFS与其他分布式文件系统相比的一个显著优点就是特别<strong>适合大量小文件(图片等)的存储,因为它在存储时没有对文件切片分割.</strong></p><h3 id="主流的分布式文件系统"><a href="#主流的分布式文件系统" class="headerlink" title="主流的分布式文件系统"></a>主流的分布式文件系统</h3><h4 id="①NFS"><a href="#①NFS" class="headerlink" title="①NFS"></a>①NFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523021175.png" alt="1577523021175"></p><h4 id="②GFS"><a href="#②GFS" class="headerlink" title="②GFS"></a>②GFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523108700.png" alt="1577523108700"></p><h4 id="③HDFS"><a href="#③HDFS" class="headerlink" title="③HDFS"></a>③HDFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523192987.png" alt="1577523192987"></p><h4 id="④FastDFS"><a href="#④FastDFS" class="headerlink" title="④FastDFS"></a>④FastDFS</h4><p>FastDFS是用c语言编写的一款开源的分布式文件系统，它是由淘宝资深架构师余庆编写并开源。FastDFS专为互联 网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很 容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。</p><p><strong>FastDFS架构包括 Tracker server和Storageserver。客户端请求Tracker server进行文件上传、下载，通过Tracker server调度最终由Storage server完成文件上传和下载。</strong> </p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="服务器环境"><a href="#服务器环境" class="headerlink" title="服务器环境"></a>服务器环境</h4><ul><li>CentOS6.9(CenttOS安装过程一致)</li></ul><ul><li>IP: 192.168.1.21,192.168.1.23,192.168.1.24,192.168.1.25</li></ul><h4 id="安装Linux基本环境"><a href="#安装Linux基本环境" class="headerlink" title="安装Linux基本环境"></a>安装Linux基本环境</h4><p>参见Hadoop的安装使用教程中Linux环境搭建</p><h4 id="安装gcc环境-FastDFS是由c语言编写"><a href="#安装gcc环境-FastDFS是由c语言编写" class="headerlink" title="安装gcc环境(FastDFS是由c语言编写)"></a>安装gcc环境(FastDFS是由c语言编写)</h4><pre class="line-numbers language-linux"><code class="language-linux">yum install gcc-c++<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="安装-libevent"><a href="#安装-libevent" class="headerlink" title="安装 libevent"></a>安装 libevent</h4><pre class="line-numbers language-yum"><code class="language-yum">yum -y install libevent<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="安装-libfastcommon"><a href="#安装-libfastcommon" class="headerlink" title="安装 libfastcommon"></a>安装 libfastcommon</h4><pre><code>将 libfastcommonV1.0.7.tar.gz 拷贝至/usr/local/下cd /usr/localtar -zxvf libfastcommonV1.0.7.tar.gzcd libfastcommon-1.0.7./make.sh./make.sh install</code></pre><p>注意：<strong>libfastcommon 安装好后会自动将库文件拷贝至/usr/lib64 下，由于 FastDFS 程序引用 usr/lib 目录所以需要将/usr/lib64 下的库文件拷贝至/usr/lib 下。</strong></p><p>需要拷贝的文件</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577524769079.png" alt="1577524769079"></p><h4 id="tracker-编译安装"><a href="#tracker-编译安装" class="headerlink" title="tracker 编译安装"></a>tracker 编译安装</h4><pre class="line-numbers language-将"><code class="language-将">将 FastDFS_v5.05.tar.gz 拷贝至/usr/local/下tar -zxvf FastDFS_v5.05.tar.gzcd FastDFS./make.sh 编译./make.sh install 安装<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>安装成功将安装目录下的 conf 下的文件拷贝到/etc/fdfs/下。</p><pre><code>cp -r /usr/local/FastDFS/conf/ /etc/fdfs/</code></pre><h5 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h5><p>安装成功后进入/etc/fdfs目录</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577525471795.png" alt="1577525471795"></p><p>拷贝一份新的 tracker 配置文件：</p><pre><code>cp tracker.conf.sample tracker.conf</code></pre><p>修改 tracker.conf</p><pre><code>vi tracker.confbase_path=/home/yuqing/FastDFS #数据(日志等)存储路径,自己设置http.server_port=80 #配置 http 端口：</code></pre><h5 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h5><pre><code>/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</code></pre><p>查看端口</p><pre><code>netstat -nltp</code></pre><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577535905825.png" alt="1577535905825"></p><h4 id="storage-安装"><a href="#storage-安装" class="headerlink" title="storage 安装"></a>storage 安装</h4><ul><li>安装 libevent</li><li>安装 libfastcommon</li><li>编译安装(与tracker相同)</li></ul><h5 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h5><pre><code>vi storage.confgroup_name=group1 #分组,同一分组为设置冗余防止宕机不可用base_path=/home/yuqing/FastDFS #数据存储路径,自己设置store_path0=/home/yuqing/FastDFS #文件存储路径,自己设置tracker_server=192.168.101.3:22122 #配置 tracker 服务器:IPtracker_server=192.168.1.21:22122 #如果有多个则配置多个 trackerhttp.server_port=80</code></pre><h5 id="启动-1"><a href="#启动-1" class="headerlink" title="启动"></a>启动</h5><pre><code>/usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</code></pre><h5 id="分发配置"><a href="#分发配置" class="headerlink" title="分发配置"></a>分发配置</h5><p>将FastDFS分发到各个节点,并修改配置,分发脚本如下</p><pre><code>#!/bin/bashpcount=$#if((pcount=0));thenecho no args;exit;fip1=$1fname=`basename $p1`echo fname=$fnamepdir=`cd -P $(dirname $p1);pwd`echo pdir=$pdiruser=`whoami`echo user=$userfor((host=1;host&lt;4;host++));doecho ------------salve$host-------------rsync -rvl $pdir/$fname $user@slave$host:$pdirdone</code></pre><h3 id="利用可通过-usr-bin-fdfs-test-程序测试"><a href="#利用可通过-usr-bin-fdfs-test-程序测试" class="headerlink" title="利用可通过/usr/bin/fdfs_test 程序测试"></a>利用可通过/usr/bin/fdfs_test 程序测试</h3><p>修改/etc/fdfs/client.conf</p><p>tracker_server 根据自己部署虚拟机的情况配置</p><pre><code>base_path = /home/yuqing/fastdfstracker-server=192.168.1.21:22122</code></pre><p>使用格式：</p><pre><code>/usr/bin/fdfs_test 客户端配置文件地址 upload 上传文件</code></pre><p>比如将/home 下的图片上传到 FastDFS 中：</p><pre><code>/usr/bin/fdfs_test /etc/fdfs/client.conf upload /home/tomcat.png</code></pre><p>打印日志如下:</p><pre><code>This is FastDFS client test program v5.05Copyright (C) 2008, Happy Fish / YuQingFastDFS may be copied only under the terms of the GNU GeneralPublic License V3, which may be found in the FastDFS source kit.Please visit the FastDFS Home Page http://www.csource.org/ for more detail.[2019-12-28 20:13:02] DEBUG - base_path=/home/fastdfs, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0tracker_query_storage_store_list_without_group:         server 1. group_name=, ip_addr=192.168.1.24, port=23000group_name=group1, ip_addr=192.168.1.24, port=23000storage_upload_by_filenamegroup_name=group1, remote_filename=M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.pngsource ip address: 192.168.1.24file timestamp=2019-12-28 20:13:02file size=138735file crc32=2977689730example file url: http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.pngstorage_upload_slave_by_filenamegroup_name=group1, remote_filename=M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587_big.pngsource ip address: 192.168.1.24file timestamp=2019-12-28 20:13:02file size=138735file crc32=2977689730</code></pre><p><a href="http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png" target="_blank" rel="noopener">http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png</a><br>就是文件的下载路径。对应服务器的base_path/fdfs_storage/data/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png文件</p><p>现在还没有和 nginx 整合无法使用 http 下载。</p><h3 id="Nginx整合FastDFS"><a href="#Nginx整合FastDFS" class="headerlink" title="Nginx整合FastDFS"></a>Nginx整合FastDFS</h3><h4 id="FastDFS-nginx-module"><a href="#FastDFS-nginx-module" class="headerlink" title="FastDFS-nginx-module"></a>FastDFS-nginx-module</h4><p>将 FastDFS-nginx-module_v1.16.tar.gz 传 至 fastDFS 的 storage 服 务 器 的</p><p>/usr/local/下，执行如下命令：</p><pre><code>cd /usr/localtar -zxvf FastDFS-nginx-module_v1.16.tar.gzcd FastDFS-nginx-module/srcvi config</code></pre><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577536510714.png" alt="1577536510714"></p><p>将/usr/local修改为/usr，注意这里有三场，不要改漏了。</p><p>将 FastDFS-nginx-module/src 下的 mod_FastDFS.conf 拷贝至/etc/fdfs/下</p><pre><code>cp mod_FastDFS.conf /etc/fdfs/vi /etc/fdfs/mod_FastDFS.confbase_path=/home/FastDFS # 保持和之前安装时一致tracker_server=192.168.1.21:22122url_have_group_name=true #url 中包含 group 名称store_path0=/home/fastdfs/fdfs_storage #指定文件存储路径,和之前一致</code></pre><p>将 libfdfsclient.so 拷贝至/usr/lib 下</p><pre><code>cp /usr/lib64/libfdfsclient.so /usr/lib/</code></pre><p>创建 nginx/client 目录</p><pre><code>mkdir -p /var/temp/nginx/client</code></pre><h4 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h4><p>详细教程可见nginx使用感悟</p><p>将 nginx-1.8.0.tar.gz 拷贝到/usr/local 下</p><p>解压 nginx-1.8.0.tar.gz</p><p>进入 nginx-1.8.0 目录，执行如下配置命令：</p><pre><code>./configure --add-module=/usr/local/FastDFS-nginx-module/srcmake make install</code></pre><p>在nginx中增加如下虚拟机配置:</p><p>storage配置:</p><pre><code>server { listen 80; server_name 192.168.1.23; 本机ip location /group1/M00/{ root /home/FastDFS/fdfs_storage/data;  #以自己配置的地址为准 ngx_FastDFS_module; } }</code></pre><p>tracker配置:</p><pre><code>#storage 群 group1 组upstream storage_server_group1{ server 192.168.1.23:80 weight=10;server 192.168.1.24:80 weight=10; } #storage 群 group2 组upstream storage_server_group2{ server 192.168.1.25:80 weight=10; } server {listen 80;server_name ccc.test.com;location /group1{proxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://storage_server_group1;}location /group2{proxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://storage_server_group2; } }</code></pre><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>使用浏览器 http 访问文件，这里访问上传图片测试的文件：</p><p>访问 storage：<a href="http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png" target="_blank" rel="noopener">http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png</a></p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577537632508.png" alt="1577537632508"></p><p>ip 地址改为 192.168.1.24也可以访问到文件，因为同一个分组的 storage 文件互相同步。</p><h3 id="编写java代码上传下载文件"><a href="#编写java代码上传下载文件" class="headerlink" title="编写java代码上传下载文件"></a>编写java代码上传下载文件</h3><p><strong>SpringBoot测试方案</strong></p><p>引入依赖</p><pre><code>        &lt;dependency&gt;            &lt;groupId&gt;net.oschina.zcx7878&lt;/groupId&gt;            &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt;            &lt;version&gt;1.27.0.0&lt;/version&gt;        &lt;/dependency&gt;</code></pre><pre><code>@SpringBootTest@RunWith(SpringRunner.class)public class TestFastDFS {    @Test    public void upload() throws IOException, MyException {        //加载fastdfs-client.properties配置文件        ClientGlobal.initByProperties(&quot;config/fastdfs-client.properties&quot;);        //定义TrackerClient,用于请求TrackerClient        TrackerClient trackerClient = new TrackerClient();        //创建TrackerServer        TrackerServer trackerServer = trackerClient.getConnection();        //通过TrackerServer获取storeServer        StorageServer storeServer = trackerClient.getStoreStorage(trackerServer);        //通过TrackerServer and storeServer 创建storageClient1        StorageClient1 storageClient1 = new StorageClient1(trackerServer, storeServer);        //fileId group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log        String fileId = storageClient1.upload_file1(&quot;C:\\Users\\tiger\\Pictures\\Feedback\\{A687785D-19C3-4B2E-A00A-2667141271EB}\\Capture001.png&quot;, &quot;.png&quot;, null);        System.out.println(fileId);        //获取tracker客户端    }    @Test    public void download() throws IOException, MyException {        //加载fastdfs-client.properties配置文件        ClientGlobal.initByProperties(&quot;config/fastdfs-client.properties&quot;);        //定义TrackerClient,用于请求TrackerClient        TrackerClient trackerClient = new TrackerClient();        //创建TrackerServer        TrackerServer trackerServer = trackerClient.getConnection();        //通过TrackerServer获取storeServer        StorageServer storeServer = trackerClient.getStoreStorage(trackerServer);        //通过TrackerServer and storeServer 创建storageClient1        StorageClient1 storageClient1 = new StorageClient1(trackerServer, storeServer);        //fileId group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log        byte[] bytes = storageClient1.download_file1(&quot;group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log&quot;);        FileOutputStream fos = new FileOutputStream(new File(&quot;hello&quot;));        fos.write(bytes);    }}</code></pre><p>config/fastdfs-client.properties</p><pre><code>fastdfs.connect_timeout_in_seconds = 5fastdfs.network_timeout_in_seconds = 30fastdfs.charset = UTF-8fastdfs.tracker_servers = 192.168.1.21:22122</code></pre><p>运行upload得到路径</p><pre><code>group1/M00/00/00/wKgBGF4HUZiAOKLgAB7xNcvo_Vw00..png根据自己配置的路径可以得到访问的http协议路径为:http://192.168.1.21/group1/M00/00/00/wKgBGF4HUZiAOKLgAB7xNcvo_Vw00..png</code></pre><p>效果如下</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577538377340.png" alt="1577538377340"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>FastDFS相对于HDFS等分布式文件的优势在于它不切分文件,所以下载文件的时候没有拼装文件的过程,而且可以锁定一台机器进行网络I/O,所以速度很快.不过正所谓这也是它的缺点,这导致它不能用于存储大文件.所以FastDFS适合存储大量图片小视频之类的文件.</strong></p><h3 id="安装过程遇到的一些问题"><a href="#安装过程遇到的一些问题" class="headerlink" title="安装过程遇到的一些问题"></a>安装过程遇到的一些问题</h3><p>①安装nginx No rule to make target “/usr/local/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c”, needed by objs/addon/src/ngx_http_fastdfs_module.o . Stop. 修改fastdfs-nginx-module/src/config文件中的路径,删除local(注意一共有三个)</p><p>②nginx安装cp: <code>conf/koi-win&#39; and</code>/usr/local/nginx/conf/koi-win’ are the same file 解决 将./configure –prefix=/usr/local/nginx 改为 ./configure –prefix=/usr/local/nginx –conf-path=/usr/local/nginx/nginx.conf</p><p>③nginx编码严格.直接复制会出现nginx: [emerg] unknown directive “ “ in /usr/local/nginx-1.12.0-storage/conf/nginx.conf:49）：所以需要手动输入nginx.conf</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>first</title>
      <link href="/2019/12/27/first/"/>
      <url>/2019/12/27/first/</url>
      
        <content type="html"><![CDATA[<p><img src="/2019/12/27/first/1577523021175.png" alt="1577523021175"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop集群搭建与简单使用</title>
      <link href="/2019/12/01/hadoop-ji-qun-da-jian-yu-jian-dan-shi-yong/"/>
      <url>/2019/12/01/hadoop-ji-qun-da-jian-yu-jian-dan-shi-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop集群搭建与简单使用"><a href="#Hadoop集群搭建与简单使用" class="headerlink" title="Hadoop集群搭建与简单使用"></a>Hadoop集群搭建与简单使用</h1><p>首先需要搭建一个linux的集群,可以参见我的博客<a href="https://tigerluhai.github.io/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/">linux集群搭建</a></p><blockquote><p>Hadoop的运行是基于java的,所以需要先安装JDK,而且JDK版本必须高于1.7</p></blockquote><h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><p>（1）查询是否安装Java软件：</p><pre><code> rpm -qa | grep java</code></pre><p>（2）如果安装的版本低于1.7，卸载该JDK：</p><pre><code>sudo rpm -e 软件包</code></pre><p>（3）查看JDK安装路径：</p><pre><code> which(or whereis) java</code></pre><p>（4）解压JDK：</p><pre><code>tar -zxvf 安装包名 -C 目标路径</code></pre><p>（5）配置JDK环境：</p><pre><code>vi /etc/profile在文件末尾加上#JAVA_HOMEexport JAVA_HOME=/opt/module/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/bin</code></pre><p><strong>修改后需要立即生效需要运行如下命令:</strong></p><pre><code>source /etc/profile</code></pre><p>（6）测试JDK安装是否成功：</p><pre><code>java -version</code></pre><h3 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h3><p>（1）解压hadoop安装包到指定位置</p><pre><code>tar -zxvf 安装包 -C 指定目录</code></pre><p>（2）添加环境变量</p><pre><code>vi /etc/profile在文件末尾加上#HADOOP_HOMEexport HADOOP_HOME=/opt/module/hadoop-3.1.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin</code></pre><p>(3)修改配置文件</p><ul><li>集群部署规划</li></ul><table><thead><tr><th></th><th>master</th><th>slave1</th><th>slave2</th><th>slave3</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNodeDataNode</td><td>SecondaryNameNode DataNode</td><td>DataNode</td><td>DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager</td><td>NodeManager</td><td>NodeManager</td></tr></tbody></table><ul><li>核心配置文件</li></ul><p>配置core-site.xml</p><pre><code>vi core-site.xml# 在该文件中编写如下配置&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;&lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/opt/module/hadoop-3.1.2/data/tmp&lt;/value&gt;&lt;/property&gt;</code></pre><ul><li>HDFS配置文件</li></ul><p>配置hadoop-env.sh</p><pre><code> vi hadoop-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>配置hdfs-site.xml</p><pre><code>vi hdfs-site.xml&lt;!--配置副本数量--&gt;&lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;3&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;&lt;property&gt;      &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;      &lt;value&gt;slave1:50090&lt;/value&gt;&lt;/property&gt;</code></pre><p>注意:文件副本数量不只是dfs.replication决定,而是min(datanode节点数,dfs.replication)</p><ul><li>YARN配置文件</li></ul><p>配置yarn-env.sh</p><pre><code> vi yarn-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><ul><li>配置yarn-site.xml</li></ul><pre><code> vi yarn-site.xml&lt;!-- Reducer获取数据的方式 --&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定YARN的ResourceManager的地址 --&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;    &lt;value&gt;slave2&lt;/value&gt;&lt;/property&gt;</code></pre><ul><li>MapReduce配置文件</li></ul><pre><code>vi mapred-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p><strong>注意：hadoop3之前的版本,mapreduce会继承hadoop的配置,所以可以不用配置这一项,但是3以后的版本必须配置,否则运行mapreduce时会报环境出错。</strong></p><ul><li>配置mapred-site.xml</li></ul><pre><code>cp mapred-site.xml.template mapred-site.xmlvi mapred-site.xml&lt;!-- 指定MR运行在Yarn上 --&gt;&lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;</code></pre><p>（4）在集群上分发配置好的Hadoop配置文件</p><p>编写分发脚本</p><pre><code>vi /usr/local/bin/xsync#!/bin/bashpcount=$#if((pcount=0));thenecho no args;exit;fip1=$1fname=`basename $p1`echo fname=$fnamepdir=`cd -P $(dirname $p1);pwd`echo pdir=$pdiruser=`whoami`echo user=$userfor((host=1;host&lt;4;host++));doecho ------------salve$host-------------rsync -rvl $pdir/$fname $user@slave$host:$pdirdone</code></pre><pre><code>xsync /opt/module/hadoop-3.1.2/</code></pre><h3 id="集群单节点启动"><a href="#集群单节点启动" class="headerlink" title="集群单节点启动"></a>集群单节点启动</h3><p>（1）如果集群是第一次启动，需要<strong>格式化NameNode</strong></p><pre><code>hadoop namenode -format</code></pre><p>（2）在master上启动NameNode</p><pre><code>hadoop-daemon.sh start namenode</code></pre><p>查看节点启动状态</p><pre><code> jps</code></pre><p><strong>注意:jps用于查看java进程,namenode和datanode都是java进程</strong></p><p>（3）在master,slave1,slave2以及slave3上分别启动DataNode</p><pre><code>hadoop-daemon.sh start datanode</code></pre><pre><code> jps3461 NameNode3608 Jps3561 DataNode</code></pre><p>思考：每次都一个一个节点启动，如果节点数太多怎么办？</p><h3 id="群起集群"><a href="#群起集群" class="headerlink" title="群起集群"></a>群起集群</h3><ol><li>配置slaves</li></ol><pre><code>vi /opt/module/hadoop-3.1.2/etc/hadoop/slaves在该文件中增加如下内容：masterslave1slave2slave3</code></pre><p><strong>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</strong></p><p>同步所有节点配置文件</p><pre><code> xsync slaves</code></pre><ol start="2"><li>启动集群</li></ol><p>（1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）</p><pre><code>hdfs namenode -format</code></pre><p>（2）启动HDFS</p><pre><code>start-dfs.sh</code></pre><p>（3）启动YARN</p><pre><code>start-yarn.sh</code></pre><p><strong>注意：NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。</strong></p><h3 id="集群基本操作"><a href="#集群基本操作" class="headerlink" title="集群基本操作"></a>集群基本操作</h3><ul><li>-ls: 显示目录信息</li></ul><pre><code>hadoop fs -ls /</code></pre><ul><li>mkdir：在HDFS上创建目录</li></ul><pre><code> hadoop fs -mkdir -p /parent/test</code></pre><ul><li>moveFromLocal：从本地剪切粘贴到HDFS</li></ul><pre><code>hadoop fs  -moveFromLocal  ./kongming.txt  /parent/test</code></pre><ul><li>appendToFile：追加一个文件到已经存在的文件末尾</li></ul><pre><code> hadoop fs -appendToFile liubei.txt /parent/test/kongming.txt</code></pre><ul><li>cat：显示文件内容</li></ul><pre><code>hadoop fs -cat /parent/test/kongming.txt</code></pre><ul><li>chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</li><li>copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</li></ul><pre><code> hadoop fs -copyFromLocal README.txt /</code></pre><ul><li>copyToLocal：从HDFS拷贝到本地</li></ul><pre><code> hadoop fs -copyToLocal /parent/test/kongming.txt ./</code></pre><ul><li>cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</li></ul><pre><code>hadoop fs -cp /parent/test/kongming.txt  /zhuge.txt</code></pre><ul><li>mv：在HDFS目录中移动文件</li></ul><pre><code>hadoop fs -mv /zhuge.txt /parent/test/</code></pre><ul><li>get：等同于copyToLocal，就是从HDFS下载文件到本地</li></ul><pre><code>hadoop fs -get /parent/test/kongming.txt ./</code></pre><ul><li>getmerge：合并下载多个文件，比如HDFS的目录 /parent/test//test下有多个文件:log.1, log.2,log.3,…</li></ul><pre><code>hadoop fs -getmerge /parent/test/test/* ./zaiyiqi.txt</code></pre><ul><li>put：等同于copyFromLocal</li></ul><pre><code> hadoop fs -put ./zaiyiqi.txt /</code></pre><ul><li>tail：显示一个文件的末尾</li></ul><ul><li>rm：删除文件或文件夹</li></ul><ul><li>rmdir：删除空目录</li></ul><ul><li>du统计文件夹的大小信息</li></ul><h3 id="JAVA代码操作HDFS"><a href="#JAVA代码操作HDFS" class="headerlink" title="JAVA代码操作HDFS"></a>JAVA代码操作HDFS</h3><pre><code>    Logger logger = LoggerFactory.getLogger(HdfsClient.class);    FileSystem fileSystem;    Configuration configuration;    @Test    /**     * 测试环境正常     */    public void HDFS_ENV() throws IOException {        Logger logger = LoggerFactory.getLogger(HdfsClient.class);        //1.获取hdfs客户端对象        Configuration configuration = new Configuration();        configuration.set(&quot;fs.defaultFS&quot;,&quot;hdfs://master:9000&quot;);        FileSystem fileSystem = FileSystem.get(configuration);        //2.在hdfs上执行相关操作        boolean mkdirs = fileSystem.mkdirs(new Path(&quot;/client_test_environment&quot;));        //3.关闭资源        fileSystem.close();        System.out.println(mkdirs);    }    @Before    /**     * 创建fileSystem对象     */    public void createFileSystem() throws URISyntaxException, IOException, InterruptedException {        //1.获取fs对象        configuration = new Configuration();        fileSystem = FileSystem.get(new URI(&quot;hdfs://master:9000&quot;), configuration, &quot;root&quot;);    }    @Test    public void copyFromLocalFile() throws IOException{        //执行上传操作        fileSystem.copyFromLocalFile(new Path(&quot;D:\\logs\\xc.2019-04-29.log&quot;),new Path(&quot;/client_test_environment/&quot;));        //关闭资源        fileSystem.close();    }    @Test    public void copyToLocalFile() throws IOException{        //执行上传操作        fileSystem.copyToLocalFile(true,new Path(&quot;/client_test_environment/xc.2019-04-29.log&quot;),new Path(&quot;D:\\logs\\xc.2019-04-29-back.log&quot;),false);        //关闭资源        fileSystem.close();    }    @Test    public void listFiles() throws IOException {        //查看文件信息        RemoteIterator&lt;LocatedFileStatus&gt; iterator = fileSystem.listFiles(new Path(&quot;/&quot;), true);        while (iterator.hasNext()){            LocatedFileStatus fileStatus = iterator.next();            //获取文件名称，文件权限，文件长度，块信息            logger.info(fileStatus.getPath().getName());            logger.info(fileStatus.getLen()+&quot;&quot;);            logger.info(fileStatus.getPermission()+&quot;&quot;);            BlockLocation[] blockLocations = fileStatus.getBlockLocations();            for (BlockLocation blockLocation : blockLocations) {                logger.info(blockLocation.toString());            }            logger.info(&quot;----------------                    ----------------------&quot;);        }    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
