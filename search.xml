<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2020/01/01/hadoop-ji-qun-da-jian-yu-jian-dan-shi-yong/"/>
      <url>/2020/01/01/hadoop-ji-qun-da-jian-yu-jian-dan-shi-yong/</url>
      
        <content type="html"><![CDATA[<p>title: Hadoop集群搭建与简单使用<br>top: false<br>cover: false<br>toc: true<br>mathjax: true<br>date: 2020-01-01 14:13:08<br>password:<br>summary:<br>tags:<br>categories:大数据</p><h1 id="Hadoop集群搭建与简单使用"><a href="#Hadoop集群搭建与简单使用" class="headerlink" title="Hadoop集群搭建与简单使用"></a>Hadoop集群搭建与简单使用</h1><p>首先需要搭建一个linux的集群,可以参见我的博客<a href="https://tigerluhai.github.io/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/">linux集群搭建</a></p><blockquote><p>Hadoop的运行是基于java的,所以需要先安装JDK,而且JDK版本必须高于1.7</p></blockquote><h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><p>（1）查询是否安装Java软件：</p><pre><code> rpm -qa | grep java</code></pre><p>（2）如果安装的版本低于1.7，卸载该JDK：</p><pre><code>sudo rpm -e 软件包</code></pre><p>（3）查看JDK安装路径：</p><pre><code> which(or whereis) java</code></pre><p>（4）解压JDK：</p><pre><code>tar -zxvf 安装包名 -C 目标路径</code></pre><p>（5）配置JDK环境：</p><pre><code>vi /etc/profile在文件末尾加上#JAVA_HOMEexport JAVA_HOME=/opt/module/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/bin</code></pre><p><strong>修改后需要立即生效需要运行如下命令:</strong></p><pre><code>source /etc/profile</code></pre><p>（6）测试JDK安装是否成功：</p><pre><code>java -version</code></pre><h3 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h3><p>（1）解压hadoop安装包到指定位置</p><pre><code>tar -zxvf 安装包 -C 指定目录</code></pre><p>（2）添加环境变量</p><pre><code>vi /etc/profile在文件末尾加上#HADOOP_HOMEexport HADOOP_HOME=/opt/module/hadoop-3.1.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin</code></pre><p>(3)修改配置文件</p><ul><li>集群部署规划</li></ul><table><thead><tr><th></th><th>master</th><th>slave1</th><th>slave2</th><th>slave3</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNodeDataNode</td><td>SecondaryNameNode DataNode</td><td>DataNode</td><td>DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager</td><td>NodeManager</td><td>NodeManager</td></tr></tbody></table><ul><li>核心配置文件</li></ul><p>配置core-site.xml</p><pre><code>vi core-site.xml# 在该文件中编写如下配置&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;&lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/opt/module/hadoop-3.1.2/data/tmp&lt;/value&gt;&lt;/property&gt;</code></pre><ul><li>HDFS配置文件</li></ul><p>配置hadoop-env.sh</p><pre><code> vi hadoop-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>配置hdfs-site.xml</p><pre><code>vi hdfs-site.xml&lt;!--配置副本数量--&gt;&lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;3&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;&lt;property&gt;      &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;      &lt;value&gt;slave1:50090&lt;/value&gt;&lt;/property&gt;</code></pre><p>注意:文件副本数量不只是dfs.replication决定,而是min(datanode节点数,dfs.replication)</p><ul><li>YARN配置文件</li></ul><p>配置yarn-env.sh</p><pre><code> vi yarn-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><ul><li>配置yarn-site.xml</li></ul><pre><code> vi yarn-site.xml&lt;!-- Reducer获取数据的方式 --&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定YARN的ResourceManager的地址 --&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;    &lt;value&gt;slave2&lt;/value&gt;&lt;/property&gt;</code></pre><ul><li>MapReduce配置文件</li></ul><pre><code>vi mapred-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p><strong>注意：hadoop3之前的版本,mapreduce会继承hadoop的配置,所以可以不用配置这一项,但是3以后的版本必须配置,否则运行mapreduce时会报环境出错。</strong></p><ul><li>配置mapred-site.xml</li></ul><pre><code>cp mapred-site.xml.template mapred-site.xmlvi mapred-site.xml&lt;!-- 指定MR运行在Yarn上 --&gt;&lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;</code></pre><p>（4）在集群上分发配置好的Hadoop配置文件</p><p>编写分发脚本</p><pre><code>vi /usr/local/bin/xsync#!/bin/bashpcount=$#if((pcount=0));thenecho no args;exit;fip1=$1fname=`basename $p1`echo fname=$fnamepdir=`cd -P $(dirname $p1);pwd`echo pdir=$pdiruser=`whoami`echo user=$userfor((host=1;host&lt;4;host++));doecho ------------salve$host-------------rsync -rvl $pdir/$fname $user@slave$host:$pdirdone</code></pre><pre><code>xsync /opt/module/hadoop-3.1.2/</code></pre><h3 id="集群单节点启动"><a href="#集群单节点启动" class="headerlink" title="集群单节点启动"></a>集群单节点启动</h3><p>（1）如果集群是第一次启动，需要<strong>格式化NameNode</strong></p><pre><code>hadoop namenode -format</code></pre><p>（2）在master上启动NameNode</p><pre><code>hadoop-daemon.sh start namenode</code></pre><p>查看节点启动状态</p><pre><code> jps</code></pre><p><strong>注意:jps用于查看java进程,namenode和datanode都是java进程</strong></p><p>（3）在master,slave1,slave2以及slave3上分别启动DataNode</p><pre><code>hadoop-daemon.sh start datanode</code></pre><pre><code> jps3461 NameNode3608 Jps3561 DataNode</code></pre><p>思考：每次都一个一个节点启动，如果节点数太多怎么办？</p><h3 id="群起集群"><a href="#群起集群" class="headerlink" title="群起集群"></a>群起集群</h3><ol><li>配置slaves</li></ol><pre><code>vi /opt/module/hadoop-3.1.2/etc/hadoop/slaves在该文件中增加如下内容：masterslave1slave2slave3</code></pre><p><strong>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</strong></p><p>同步所有节点配置文件</p><pre><code> xsync slaves</code></pre><ol start="2"><li>启动集群</li></ol><p>（1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）</p><pre><code>hdfs namenode -format</code></pre><p>（2）启动HDFS</p><pre><code>start-dfs.sh</code></pre><p>（3）启动YARN</p><pre><code>start-yarn.sh</code></pre><p><strong>注意：NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。</strong></p><h3 id="集群基本操作"><a href="#集群基本操作" class="headerlink" title="集群基本操作"></a>集群基本操作</h3><ul><li>-ls: 显示目录信息</li></ul><pre><code>hadoop fs -ls /</code></pre><ul><li>mkdir：在HDFS上创建目录</li></ul><pre><code> hadoop fs -mkdir -p /parent/test</code></pre><ul><li>moveFromLocal：从本地剪切粘贴到HDFS</li></ul><pre><code>hadoop fs  -moveFromLocal  ./kongming.txt  /parent/test</code></pre><ul><li>appendToFile：追加一个文件到已经存在的文件末尾</li></ul><pre><code> hadoop fs -appendToFile liubei.txt /parent/test/kongming.txt</code></pre><ul><li>cat：显示文件内容</li></ul><pre><code>hadoop fs -cat /parent/test/kongming.txt</code></pre><ul><li>chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</li><li>copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</li></ul><pre><code> hadoop fs -copyFromLocal README.txt /</code></pre><ul><li>copyToLocal：从HDFS拷贝到本地</li></ul><pre><code> hadoop fs -copyToLocal /parent/test/kongming.txt ./</code></pre><ul><li>cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</li></ul><pre><code>hadoop fs -cp /parent/test/kongming.txt  /zhuge.txt</code></pre><ul><li>mv：在HDFS目录中移动文件</li></ul><pre><code>hadoop fs -mv /zhuge.txt /parent/test/</code></pre><ul><li>get：等同于copyToLocal，就是从HDFS下载文件到本地</li></ul><pre><code>hadoop fs -get /parent/test/kongming.txt ./</code></pre><ul><li>getmerge：合并下载多个文件，比如HDFS的目录 /parent/test//test下有多个文件:log.1, log.2,log.3,…</li></ul><pre><code>hadoop fs -getmerge /parent/test/test/* ./zaiyiqi.txt</code></pre><ul><li>put：等同于copyFromLocal</li></ul><pre><code> hadoop fs -put ./zaiyiqi.txt /</code></pre><ul><li>tail：显示一个文件的末尾</li></ul><ul><li>rm：删除文件或文件夹</li></ul><ul><li>rmdir：删除空目录</li></ul><ul><li>du统计文件夹的大小信息</li></ul><h3 id="JAVA代码操作HDFS"><a href="#JAVA代码操作HDFS" class="headerlink" title="JAVA代码操作HDFS"></a>JAVA代码操作HDFS</h3><pre><code>    Logger logger = LoggerFactory.getLogger(HdfsClient.class);    FileSystem fileSystem;    Configuration configuration;    @Test    /**     * 测试环境正常     */    public void HDFS_ENV() throws IOException {        Logger logger = LoggerFactory.getLogger(HdfsClient.class);        //1.获取hdfs客户端对象        Configuration configuration = new Configuration();        configuration.set(&quot;fs.defaultFS&quot;,&quot;hdfs://master:9000&quot;);        FileSystem fileSystem = FileSystem.get(configuration);        //2.在hdfs上执行相关操作        boolean mkdirs = fileSystem.mkdirs(new Path(&quot;/client_test_environment&quot;));        //3.关闭资源        fileSystem.close();        System.out.println(mkdirs);    }    @Before    /**     * 创建fileSystem对象     */    public void createFileSystem() throws URISyntaxException, IOException, InterruptedException {        //1.获取fs对象        configuration = new Configuration();        fileSystem = FileSystem.get(new URI(&quot;hdfs://master:9000&quot;), configuration, &quot;root&quot;);    }    @Test    public void copyFromLocalFile() throws IOException{        //执行上传操作        fileSystem.copyFromLocalFile(new Path(&quot;D:\\logs\\xc.2019-04-29.log&quot;),new Path(&quot;/client_test_environment/&quot;));        //关闭资源        fileSystem.close();    }    @Test    public void copyToLocalFile() throws IOException{        //执行上传操作        fileSystem.copyToLocalFile(true,new Path(&quot;/client_test_environment/xc.2019-04-29.log&quot;),new Path(&quot;D:\\logs\\xc.2019-04-29-back.log&quot;),false);        //关闭资源        fileSystem.close();    }    @Test    public void listFiles() throws IOException {        //查看文件信息        RemoteIterator&lt;LocatedFileStatus&gt; iterator = fileSystem.listFiles(new Path(&quot;/&quot;), true);        while (iterator.hasNext()){            LocatedFileStatus fileStatus = iterator.next();            //获取文件名称，文件权限，文件长度，块信息            logger.info(fileStatus.getPath().getName());            logger.info(fileStatus.getLen()+&quot;&quot;);            logger.info(fileStatus.getPermission()+&quot;&quot;);            BlockLocation[] blockLocations = fileStatus.getBlockLocations();            for (BlockLocation blockLocation : blockLocations) {                logger.info(blockLocation.toString());            }            logger.info(&quot;----------------                    ----------------------&quot;);        }    }</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>使用VMware安装linux虚拟机</title>
      <link href="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/"/>
      <url>/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=552192975&auto=0&height=66"></iframe></div><h1 id="使用VMware安装linux虚拟机"><a href="#使用VMware安装linux虚拟机" class="headerlink" title="使用VMware安装linux虚拟机"></a>使用VMware安装linux虚拟机</h1><h3 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h3><p><em>Linux是一种自由和开放源码的操作系统，存在着许多不同的Linux发行版本，但它们都使用了Linux内核。现在的服务器基本都是使用linux,其中CentOS使用广泛,还有ubuntu也是linux中的佼佼者.业内也说,凡是<strong>java开发,不懂linux均是扯淡.</strong>本文主要为后面搭建基于Hadoop集群的大数据大数据平台打下基础。</em></p><h4 id="linux具有如下优点"><a href="#linux具有如下优点" class="headerlink" title="linux具有如下优点"></a>linux具有如下优点</h4><ul><li>开源</li><li>多用户，多任务，丰富的网络功能，可靠的系统安全，良好的可移植性，具有标准兼容性</li><li>良好的用户界面，出色的速度性能</li><li>服务器不使用图形化界面(图形界面占用资源)</li><li>机房部署方便，无需配置操作界面</li></ul><p><strong>下载地址</strong><a href="http://www.centos.org/" target="_blank" rel="noopener">:http://www.centos.org/</a></p><h3 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h3><ul><li>Windows10</li><li>VMware Workstation12</li><li>CentOS7</li></ul><h4 id="VMware-Workstation12安装"><a href="#VMware-Workstation12安装" class="headerlink" title="VMware Workstation12安装"></a>VMware Workstation12安装</h4><p>①双击VMware-workstation-full-版本号.exe</p><p>②点击next</p><p>③选择Typical(你要是想自己配置也可以选custom 不推荐)</p><p>④选择安装目录</p><p>⑤想检查升级就勾上(check for product updates on startup),否则直接下一步</p><p>⑥选择创建快捷方式的位置,然后下一步</p><p>⑦点击continue完成</p><p>⑧Finish完成</p><p><strong>注意:如果你不熟悉就按部就班来,不要有什么骚操作,我记得我开始安装的时候禁用了哪两个网卡,后来哪两个网卡找不到了,我就把这个卸载了重新装,还是不行,这个问题的解决还是因为我一个月后重装了电脑</strong></p><h4 id="CentOS7安装"><a href="#CentOS7安装" class="headerlink" title="CentOS7安装"></a>CentOS7安装</h4><p>①安装VMware Workstation</p><p>②打开VM,点击创建新的虚拟机</p><p>③选择 典型（推荐）→ 下一步 </p><p>④选择稍后安装操作系统再点击下一步</p><p>⑤选择操作系统和版本(linux 64)</p><p>⑥输入虚拟机名称和安装路径</p><p>⑦设置磁盘大小并选中将虚拟磁盘拆成多个文件</p><p>⑧自定义硬件</p><p>⑨选择CentOS安装镜像文件</p><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577631145598.png" alt="1577631145598"></p><p>⑩开机启动后选择Install CentOS 7并enter</p><ul><li>弹出如下图形化的安装界面：</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat.png" alt="img"></p><ul><li>日期和时间：</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat1.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat2.png" alt="img"></p><ul><li>如果你安装的是英文版，需要将时区改为上海。</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat3.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat4.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126014938900.png" alt="img"></p><ul><li><strong>网络和主机名</strong></li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126015037602.png" alt="img"><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C20171126015051216.png" alt="img"></p><ul><li>然后选择开始安装**</li></ul><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5Cformat7.png" alt="img">基本的系统就安装好了</p><h3 id="配置网络"><a href="#配置网络" class="headerlink" title="配置网络"></a>配置网络</h3><ul><li>linu有三种网络模式,分别是Host-Only、NAT、桥接。一般安装好以后会默认选择NAT。</li></ul><ul><li>进入之后修改ip地址信息</li></ul><pre><code>vi /etc/ sysconfig/network-scripts/ifcfg-eth0DEVICE=eth0 #网卡名称HWADDR=08:00:27:8E:9D:25 #MAC地址TYPE=Ethernet #网络类型,这里是以太网UUID=5f2d815e-bd3b-4995-9009-823542e77304ONBOOT=yes NM_CONTROLLED=yesBOOTPROTO=staticSTATIC=trueIPADDR=192.168.1.21 #ip地址NETMASK=255.255.255.0 #子网掩码GATEWAY=192.168.1.1 #网管DNS1=202.202.0.33 #域名解析地址DNS2=114.114.114.114DNS3=8.8.8.8</code></pre><ul><li>配置好以后重启网络服务</li></ul><pre><code>services network restart</code></pre><ul><li>ifconfig查看IP地址</li></ul><pre><code>ifconfigeth0      Link encap:Ethernet  HWaddr 08:00:27:8E:9D:25            inet addr:192.168.1.21  Bcast:192.168.1.255  Mask:255.255.255.0          inet6 addr: fe80::a00:27ff:fe8e:9d25/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:1756623 errors:0 dropped:0 overruns:0 frame:0          TX packets:1952463 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000           RX bytes:1445482120 (1.3 GiB)  TX bytes:1626059931 (1.5 GiB)lo        Link encap:Local Loopback            inet addr:127.0.0.1  Mask:255.0.0.0          inet6 addr: ::1/128 Scope:Host          UP LOOPBACK RUNNING  MTU:65536  Metric:1          RX packets:2258 errors:0 dropped:0 overruns:0 frame:0          TX packets:2258 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0           RX bytes:590708 (576.8 KiB)  TX bytes:590708 (576.8 KiB)</code></pre><ul><li>ping ip地址测试网络是否配置好</li></ul><pre><code>ping www.baidu.com</code></pre><p><strong>按照以上操作完成安装以后可以直接克隆改虚拟机，然后修改配置就可以生成多台</strong></p><p><strong>在每个主机的/etc/hosts文件设置上每个主机的ip和名字的映射关系</strong></p><pre><code>vi /etc/hosts192.168.1.21 master192.168.1.23 slave1192.168.1.24 slave2192.168.1.25 slave3</code></pre><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577691474359.png" alt="1577691474359"></p><h4 id="配置免密登录"><a href="#配置免密登录" class="headerlink" title="配置免密登录"></a>配置免密登录</h4><ul><li>主要用于两个机器之间相互登录不需要验证</li></ul><p>①在第一台机器使用命令ssh-keygen -t rsa生成私钥和秘钥</p><pre><code>ssh-keygen -t rsa</code></pre><p>②复制到另一台机器</p><pre><code>ssh-copy-id root@slave1</code></pre><p><strong>如此就可以实现slave登录master免密,按照这个做法,每两台机器都配置上。</strong></p><h5 id="科普：免密登录原理"><a href="#科普：免密登录原理" class="headerlink" title="科普：免密登录原理"></a>科普：免密登录原理</h5><p><img src="/2019/12/29/shi-yong-vmware-an-zhuang-linux-xu-ni-ji/D:%5CMyBlot%5Cbolt%5Csource_posts%5C%E4%BD%BF%E7%94%A8VMware%E5%AE%89%E8%A3%85linux%E8%99%9A%E6%8B%9F%E6%9C%BA%5C1577692561419.png" alt="1577692561419"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>hexo博文包含图片的坑</title>
      <link href="/2019/12/29/hexo-bo-wen-bao-han-tu-pian-de-keng/"/>
      <url>/2019/12/29/hexo-bo-wen-bao-han-tu-pian-de-keng/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=414414&auto=0&height=66"></iframe></div><h1 id="hexo博文包含图片的坑"><a href="#hexo博文包含图片的坑" class="headerlink" title="hexo博文包含图片的坑"></a>hexo博文包含图片的坑</h1><h3 id="网上有很多关于这个的教程-主要的总结如下"><a href="#网上有很多关于这个的教程-主要的总结如下" class="headerlink" title="网上有很多关于这个的教程,主要的总结如下"></a>网上有很多关于这个的教程,主要的总结如下</h3><ul><li>①修改博客目录下的_config_yml的post_asset_folder为true</li></ul><pre class="line-numbers language-java"><code class="language-java">post_asset_folder<span class="token operator">:</span> <span class="token boolean">true</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>②安装hexo-asset-image插件</li></ul><pre><code>npm install hexo-asset-image --save</code></pre><ul><li>③hexo new  file_name 时会在source/_post/下生成file_name的文件夹,将需要使用的图片放置在里面,然后使用相对路径引入</li></ul><pre><code>![用于图片加载失败时显示的内容](/file_name/image_name)</code></pre><ul><li>如此博客中的图片最后会和.md文件一起生成到public\2019\12\27\file_name中,这样在hexe g 时,可以看到命令窗口会打印修改后的路径,如下</li></ul><pre><code>Start processingupdate link as:--&gt;/2019/12/27/first/1577523021175.pngupdate link as:--&gt;/2019/12/27/first/1577523021175.png</code></pre><h3 id="我遇到的问题"><a href="#我遇到的问题" class="headerlink" title="我遇到的问题"></a>我遇到的问题</h3><pre><code>Start processingupdate link as:--&gt;.io//2019/12/27/first/1577523021175.pngupdate link as:--&gt;.io//2019/12/27/first/1577523021175.png</code></pre><ul><li>经过一番搜寻,发现hexo-asset-image会将图片的地址修改,具体的源码信息可见\node_modules\hexo-asset-image\index.js,打开后内容如下:</li></ul><pre><code>&#39;use strict&#39;;var cheerio = require(&#39;cheerio&#39;);function getPosition(str, m, i) {  return str.split(m, i).join(m).length;}hexo.extend.filter.register(&#39;after_post_render&#39;, function(data){  var config = hexo.config;  if(config.post_asset_folder){    var link = data.permalink;    var beginPos = getPosition(link, &#39;/&#39;, 3) + 1;    var appendLink = &#39;&#39;;    // In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;.    // if not with index.html endpos = link.lastIndexOf(&#39;.&#39;) + 1 support hexo-abbrlink    if(/.*\/index\.html$/.test(link)) {      // when permalink is end with index.html, for example 2019/02/20/xxtitle/index.html      // image in xxtitle/ will go to xxtitle/index/      appendLink = &#39;index/&#39;;      var endPos = link.lastIndexOf(&#39;/&#39;);    }    else {      var endPos = link.lastIndexOf(&#39;.&#39;) ;    }    link = link.substring(beginPos, endPos) + &#39;/&#39; + appendLink;    var toprocess = [&#39;excerpt&#39;, &#39;more&#39;, &#39;content&#39;];    for(var i = 0; i &lt; toprocess.length; i++){      var key = toprocess[i];      var $ = cheerio.load(data[key], {        ignoreWhitespace: false,        xmlMode: false,        lowerCaseTags: false,        decodeEntities: false      });      $(&#39;img&#39;).each(function(){        if ($(this).attr(&#39;src&#39;)){          // For windows style path, we replace &#39;\&#39; to &#39;/&#39;.          var src = $(this).attr(&#39;src&#39;).replace(&#39;\\&#39;, &#39;/&#39;);          if(!(/http[s]*.*|\/\/.*/.test(src)            || /^\s+\//.test(src)            || /^\s*\/uploads|images\//.test(src))) {            // For &quot;about&quot; page, the first part of &quot;src&quot; can&#39;t be removed.            // In addition, to support multi-level local directory.            var linkArray = link.split(&#39;/&#39;).filter(function(elem){              return elem != &#39;&#39;;            });            var srcArray = src.split(&#39;/&#39;).filter(function(elem){              return elem != &#39;&#39; &amp;&amp; elem != &#39;.&#39;;            });            if(srcArray.length &gt; 1)            srcArray.shift();            src = srcArray.join(&#39;/&#39;);            $(this).attr(&#39;src&#39;, config.root + link + src);            console.info&amp;&amp;console.info(&quot;update link as:--&gt;&quot;+config.root + link + src);          }        }else{          console.info&amp;&amp;console.info(&quot;no src attr, skipped...&quot;);          console.info&amp;&amp;console.info($(this));        }      });      data[key] = $.html();    }  }});</code></pre><ul><li>通过查看源码发现里面有对生成博客图片的地址修改:</li></ul><pre><code>link = link.substring(beginPos, endPos) + &#39;/&#39; + appendLink;</code></pre><ul><li>通过排查发现图片的路径的endPos为:</li></ul><pre><code>var endPos = link.lastIndexOf(&#39;.&#39;) ;</code></pre><ul><li>我打印data.permalink得到</li></ul><pre><code>http://tigerLuHai.github.io/2019/12/27/first/</code></pre><p>如此在截取字符串的时候就会多出四个字符  <strong>.io/</strong></p><p>最后发现这段代码的作用就是要将data.permalink中路径的<a href="https://tigerLuhai.gituhub.io/去掉,因为在后面部署到github时使用相对路径访问会重新加上这个前缀,如果这里有就会重复,导致地址为https://tigerLuhai.gituhub.io/http://tigerLuHai.github.io/2019/12/27/first/的现象" target="_blank" rel="noopener">https://tigerLuhai.gituhub.io/去掉,因为在后面部署到github时使用相对路径访问会重新加上这个前缀,如果这里有就会重复,导致地址为https://tigerLuhai.gituhub.io/http://tigerLuHai.github.io/2019/12/27/first/的现象</a>.</p><p>明白了需求就可以修改代码为</p><pre><code>var endPos = link.lastIndexOf(&#39;/&#39;) ;</code></pre><p>这样就可以正常部署了.</p>]]></content>
      
      
      <categories>
          
          <category> tool </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>FastDFS分布式文件系统安装使用教程</title>
      <link href="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/"/>
      <url>/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<div align="middle"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=479553545&auto=1&height=66"></iframe></div><h1 id="FastDFS分布式文件系统安装使用教程"><a href="#FastDFS分布式文件系统安装使用教程" class="headerlink" title="FastDFS分布式文件系统安装使用教程"></a>FastDFS分布式文件系统安装使用教程</h1><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><p>分布式文件系统用于<strong>海量</strong>文件存储及传输访问的瓶颈问题，对海量视频的管理、对<strong>海量</strong>图片的管理等,FastDFS与其他分布式文件系统相比的一个显著优点就是特别<strong>适合大量小文件(图片等)的存储,因为它在存储时没有对文件切片分割.</strong></p><h3 id="主流的分布式文件系统"><a href="#主流的分布式文件系统" class="headerlink" title="主流的分布式文件系统"></a>主流的分布式文件系统</h3><h4 id="①NFS"><a href="#①NFS" class="headerlink" title="①NFS"></a>①NFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523021175.png" alt="1577523021175"></p><h4 id="②GFS"><a href="#②GFS" class="headerlink" title="②GFS"></a>②GFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523108700.png" alt="1577523108700"></p><h4 id="③HDFS"><a href="#③HDFS" class="headerlink" title="③HDFS"></a>③HDFS</h4><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/1577523192987.png" alt="1577523192987"></p><h4 id="④FastDFS"><a href="#④FastDFS" class="headerlink" title="④FastDFS"></a>④FastDFS</h4><p>FastDFS是用c语言编写的一款开源的分布式文件系统，它是由淘宝资深架构师余庆编写并开源。FastDFS专为互联 网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很 容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。</p><p><strong>FastDFS架构包括 Tracker server和Storageserver。客户端请求Tracker server进行文件上传、下载，通过Tracker server调度最终由Storage server完成文件上传和下载。</strong> </p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="服务器环境"><a href="#服务器环境" class="headerlink" title="服务器环境"></a>服务器环境</h4><ul><li>CentOS6.9(CenttOS安装过程一致)</li></ul><ul><li>IP: 192.168.1.21,192.168.1.23,192.168.1.24,192.168.1.25</li></ul><h4 id="安装Linux基本环境"><a href="#安装Linux基本环境" class="headerlink" title="安装Linux基本环境"></a>安装Linux基本环境</h4><p>参见Hadoop的安装使用教程中Linux环境搭建</p><h4 id="安装gcc环境-FastDFS是由c语言编写"><a href="#安装gcc环境-FastDFS是由c语言编写" class="headerlink" title="安装gcc环境(FastDFS是由c语言编写)"></a>安装gcc环境(FastDFS是由c语言编写)</h4><pre class="line-numbers language-linux"><code class="language-linux">yum install gcc-c++<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="安装-libevent"><a href="#安装-libevent" class="headerlink" title="安装 libevent"></a>安装 libevent</h4><pre class="line-numbers language-yum"><code class="language-yum">yum -y install libevent<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="安装-libfastcommon"><a href="#安装-libfastcommon" class="headerlink" title="安装 libfastcommon"></a>安装 libfastcommon</h4><pre><code>将 libfastcommonV1.0.7.tar.gz 拷贝至/usr/local/下cd /usr/localtar -zxvf libfastcommonV1.0.7.tar.gzcd libfastcommon-1.0.7./make.sh./make.sh install</code></pre><p>注意：<strong>libfastcommon 安装好后会自动将库文件拷贝至/usr/lib64 下，由于 FastDFS 程序引用 usr/lib 目录所以需要将/usr/lib64 下的库文件拷贝至/usr/lib 下。</strong></p><p>需要拷贝的文件</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577524769079.png" alt="1577524769079"></p><h4 id="tracker-编译安装"><a href="#tracker-编译安装" class="headerlink" title="tracker 编译安装"></a>tracker 编译安装</h4><pre class="line-numbers language-将"><code class="language-将">将 FastDFS_v5.05.tar.gz 拷贝至/usr/local/下tar -zxvf FastDFS_v5.05.tar.gzcd FastDFS./make.sh 编译./make.sh install 安装<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>安装成功将安装目录下的 conf 下的文件拷贝到/etc/fdfs/下。</p><pre><code>cp -r /usr/local/FastDFS/conf/ /etc/fdfs/</code></pre><h5 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h5><p>安装成功后进入/etc/fdfs目录</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577525471795.png" alt="1577525471795"></p><p>拷贝一份新的 tracker 配置文件：</p><pre><code>cp tracker.conf.sample tracker.conf</code></pre><p>修改 tracker.conf</p><pre><code>vi tracker.confbase_path=/home/yuqing/FastDFS #数据(日志等)存储路径,自己设置http.server_port=80 #配置 http 端口：</code></pre><h5 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h5><pre><code>/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</code></pre><p>查看端口</p><pre><code>netstat -nltp</code></pre><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577535905825.png" alt="1577535905825"></p><h4 id="storage-安装"><a href="#storage-安装" class="headerlink" title="storage 安装"></a>storage 安装</h4><ul><li>安装 libevent</li><li>安装 libfastcommon</li><li>编译安装(与tracker相同)</li></ul><h5 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h5><pre><code>vi storage.confgroup_name=group1 #分组,同一分组为设置冗余防止宕机不可用base_path=/home/yuqing/FastDFS #数据存储路径,自己设置store_path0=/home/yuqing/FastDFS #文件存储路径,自己设置tracker_server=192.168.101.3:22122 #配置 tracker 服务器:IPtracker_server=192.168.1.21:22122 #如果有多个则配置多个 trackerhttp.server_port=80</code></pre><h5 id="启动-1"><a href="#启动-1" class="headerlink" title="启动"></a>启动</h5><pre><code>/usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</code></pre><h5 id="分发配置"><a href="#分发配置" class="headerlink" title="分发配置"></a>分发配置</h5><p>将FastDFS分发到各个节点,并修改配置,分发脚本如下</p><pre><code>#!/bin/bashpcount=$#if((pcount=0));thenecho no args;exit;fip1=$1fname=`basename $p1`echo fname=$fnamepdir=`cd -P $(dirname $p1);pwd`echo pdir=$pdiruser=`whoami`echo user=$userfor((host=1;host&lt;4;host++));doecho ------------salve$host-------------rsync -rvl $pdir/$fname $user@slave$host:$pdirdone</code></pre><h3 id="利用可通过-usr-bin-fdfs-test-程序测试"><a href="#利用可通过-usr-bin-fdfs-test-程序测试" class="headerlink" title="利用可通过/usr/bin/fdfs_test 程序测试"></a>利用可通过/usr/bin/fdfs_test 程序测试</h3><p>修改/etc/fdfs/client.conf</p><p>tracker_server 根据自己部署虚拟机的情况配置</p><pre><code>base_path = /home/yuqing/fastdfstracker-server=192.168.1.21:22122</code></pre><p>使用格式：</p><pre><code>/usr/bin/fdfs_test 客户端配置文件地址 upload 上传文件</code></pre><p>比如将/home 下的图片上传到 FastDFS 中：</p><pre><code>/usr/bin/fdfs_test /etc/fdfs/client.conf upload /home/tomcat.png</code></pre><p>打印日志如下:</p><pre><code>This is FastDFS client test program v5.05Copyright (C) 2008, Happy Fish / YuQingFastDFS may be copied only under the terms of the GNU GeneralPublic License V3, which may be found in the FastDFS source kit.Please visit the FastDFS Home Page http://www.csource.org/ for more detail.[2019-12-28 20:13:02] DEBUG - base_path=/home/fastdfs, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0tracker_query_storage_store_list_without_group:         server 1. group_name=, ip_addr=192.168.1.24, port=23000group_name=group1, ip_addr=192.168.1.24, port=23000storage_upload_by_filenamegroup_name=group1, remote_filename=M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.pngsource ip address: 192.168.1.24file timestamp=2019-12-28 20:13:02file size=138735file crc32=2977689730example file url: http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.pngstorage_upload_slave_by_filenamegroup_name=group1, remote_filename=M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587_big.pngsource ip address: 192.168.1.24file timestamp=2019-12-28 20:13:02file size=138735file crc32=2977689730</code></pre><p><a href="http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png" target="_blank" rel="noopener">http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png</a><br>就是文件的下载路径。对应服务器的base_path/fdfs_storage/data/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png文件</p><p>现在还没有和 nginx 整合无法使用 http 下载。</p><h3 id="Nginx整合FastDFS"><a href="#Nginx整合FastDFS" class="headerlink" title="Nginx整合FastDFS"></a>Nginx整合FastDFS</h3><h4 id="FastDFS-nginx-module"><a href="#FastDFS-nginx-module" class="headerlink" title="FastDFS-nginx-module"></a>FastDFS-nginx-module</h4><p>将 FastDFS-nginx-module_v1.16.tar.gz 传 至 fastDFS 的 storage 服 务 器 的</p><p>/usr/local/下，执行如下命令：</p><pre><code>cd /usr/localtar -zxvf FastDFS-nginx-module_v1.16.tar.gzcd FastDFS-nginx-module/srcvi config</code></pre><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577536510714.png" alt="1577536510714"></p><p>将/usr/local修改为/usr，注意这里有三场，不要改漏了。</p><p>将 FastDFS-nginx-module/src 下的 mod_FastDFS.conf 拷贝至/etc/fdfs/下</p><pre><code>cp mod_FastDFS.conf /etc/fdfs/vi /etc/fdfs/mod_FastDFS.confbase_path=/home/FastDFS # 保持和之前安装时一致tracker_server=192.168.1.21:22122url_have_group_name=true #url 中包含 group 名称store_path0=/home/fastdfs/fdfs_storage #指定文件存储路径,和之前一致</code></pre><p>将 libfdfsclient.so 拷贝至/usr/lib 下</p><pre><code>cp /usr/lib64/libfdfsclient.so /usr/lib/</code></pre><p>创建 nginx/client 目录</p><pre><code>mkdir -p /var/temp/nginx/client</code></pre><h4 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h4><p>详细教程可见nginx使用感悟</p><p>将 nginx-1.8.0.tar.gz 拷贝到/usr/local 下</p><p>解压 nginx-1.8.0.tar.gz</p><p>进入 nginx-1.8.0 目录，执行如下配置命令：</p><pre><code>./configure --add-module=/usr/local/FastDFS-nginx-module/srcmake make install</code></pre><p>在nginx中增加如下虚拟机配置:</p><p>storage配置:</p><pre><code>server { listen 80; server_name 192.168.1.23; 本机ip location /group1/M00/{ root /home/FastDFS/fdfs_storage/data;  #以自己配置的地址为准 ngx_FastDFS_module; } }</code></pre><p>tracker配置:</p><pre><code>#storage 群 group1 组upstream storage_server_group1{ server 192.168.1.23:80 weight=10;server 192.168.1.24:80 weight=10; } #storage 群 group2 组upstream storage_server_group2{ server 192.168.1.25:80 weight=10; } server {listen 80;server_name ccc.test.com;location /group1{proxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://storage_server_group1;}location /group2{proxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://storage_server_group2; } }</code></pre><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>使用浏览器 http 访问文件，这里访问上传图片测试的文件：</p><p>访问 storage：<a href="http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png" target="_blank" rel="noopener">http://192.168.1.24/group1/M00/00/00/wKgBGF4HRs6AOwJJAAId77F78II587.png</a></p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577537632508.png" alt="1577537632508"></p><p>ip 地址改为 192.168.1.24也可以访问到文件，因为同一个分组的 storage 文件互相同步。</p><h3 id="编写java代码上传下载文件"><a href="#编写java代码上传下载文件" class="headerlink" title="编写java代码上传下载文件"></a>编写java代码上传下载文件</h3><p><strong>SpringBoot测试方案</strong></p><p>引入依赖</p><pre><code>        &lt;dependency&gt;            &lt;groupId&gt;net.oschina.zcx7878&lt;/groupId&gt;            &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt;            &lt;version&gt;1.27.0.0&lt;/version&gt;        &lt;/dependency&gt;</code></pre><pre><code>@SpringBootTest@RunWith(SpringRunner.class)public class TestFastDFS {    @Test    public void upload() throws IOException, MyException {        //加载fastdfs-client.properties配置文件        ClientGlobal.initByProperties(&quot;config/fastdfs-client.properties&quot;);        //定义TrackerClient,用于请求TrackerClient        TrackerClient trackerClient = new TrackerClient();        //创建TrackerServer        TrackerServer trackerServer = trackerClient.getConnection();        //通过TrackerServer获取storeServer        StorageServer storeServer = trackerClient.getStoreStorage(trackerServer);        //通过TrackerServer and storeServer 创建storageClient1        StorageClient1 storageClient1 = new StorageClient1(trackerServer, storeServer);        //fileId group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log        String fileId = storageClient1.upload_file1(&quot;C:\\Users\\tiger\\Pictures\\Feedback\\{A687785D-19C3-4B2E-A00A-2667141271EB}\\Capture001.png&quot;, &quot;.png&quot;, null);        System.out.println(fileId);        //获取tracker客户端    }    @Test    public void download() throws IOException, MyException {        //加载fastdfs-client.properties配置文件        ClientGlobal.initByProperties(&quot;config/fastdfs-client.properties&quot;);        //定义TrackerClient,用于请求TrackerClient        TrackerClient trackerClient = new TrackerClient();        //创建TrackerServer        TrackerServer trackerServer = trackerClient.getConnection();        //通过TrackerServer获取storeServer        StorageServer storeServer = trackerClient.getStoreStorage(trackerServer);        //通过TrackerServer and storeServer 创建storageClient1        StorageClient1 storageClient1 = new StorageClient1(trackerServer, storeServer);        //fileId group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log        byte[] bytes = storageClient1.download_file1(&quot;group1/M00/00/00/wKgBF13ebJuALXhqAAI6t5YoKLQ94..log&quot;);        FileOutputStream fos = new FileOutputStream(new File(&quot;hello&quot;));        fos.write(bytes);    }}</code></pre><p>config/fastdfs-client.properties</p><pre><code>fastdfs.connect_timeout_in_seconds = 5fastdfs.network_timeout_in_seconds = 30fastdfs.charset = UTF-8fastdfs.tracker_servers = 192.168.1.21:22122</code></pre><p>运行upload得到路径</p><pre><code>group1/M00/00/00/wKgBGF4HUZiAOKLgAB7xNcvo_Vw00..png根据自己配置的路径可以得到访问的http协议路径为:http://192.168.1.21/group1/M00/00/00/wKgBGF4HUZiAOKLgAB7xNcvo_Vw00..png</code></pre><p>效果如下</p><p><img src="/2019/12/28/fastdfs-fen-bu-shi-wen-jian-xi-tong-an-zhuang-shi-yong-jiao-cheng/FastDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%5C1577538377340.png" alt="1577538377340"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>FastDFS相对于HDFS等分布式文件的优势在于它不切分文件,所以下载文件的时候没有拼装文件的过程,而且可以锁定一台机器进行网络I/O,所以速度很快.不过正所谓这也是它的缺点,这导致它不能用于存储大文件.所以FastDFS适合存储大量图片小视频之类的文件.</strong></p><h3 id="安装过程遇到的一些问题"><a href="#安装过程遇到的一些问题" class="headerlink" title="安装过程遇到的一些问题"></a>安装过程遇到的一些问题</h3><p>①安装nginx No rule to make target “/usr/local/fastdfs-nginx-module/src/ngx_http_fastdfs_module.c”, needed by objs/addon/src/ngx_http_fastdfs_module.o . Stop. 修改fastdfs-nginx-module/src/config文件中的路径,删除local(注意一共有三个)</p><p>②nginx安装cp: <code>conf/koi-win&#39; and</code>/usr/local/nginx/conf/koi-win’ are the same file 解决 将./configure –prefix=/usr/local/nginx 改为 ./configure –prefix=/usr/local/nginx –conf-path=/usr/local/nginx/nginx.conf</p><p>③nginx编码严格.直接复制会出现nginx: [emerg] unknown directive “ “ in /usr/local/nginx-1.12.0-storage/conf/nginx.conf:49）：所以需要手动输入nginx.conf</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>first</title>
      <link href="/2019/12/27/first/"/>
      <url>/2019/12/27/first/</url>
      
        <content type="html"><![CDATA[<p><img src="/2019/12/27/first/1577523021175.png" alt="1577523021175"></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
